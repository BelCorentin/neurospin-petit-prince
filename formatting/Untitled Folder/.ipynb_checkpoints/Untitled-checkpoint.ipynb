{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d383c5",
   "metadata": {},
   "source": [
    "# Adding sentence id / constituent id to events.tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neuro\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "# ML/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Tools\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "from utils import match_list, add_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6801aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_modify_events(subject, run_id, events_return=False, modality=\"visual\"):\n",
    "    print(f\"Reading raw files for modality: {modality}\")\n",
    "    path = get_path(modality)\n",
    "    task_map = {\"auditory\": \"listen\", \"visual\": \"read\", \"fmri\": \"listen\"}\n",
    "    task = task_map[modality]\n",
    "    print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    # read events\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "    \n",
    "    base_meta = meta.copy()\n",
    "\n",
    "    meta[\"wlength\"] = meta.word.apply(len)\n",
    "    # Enriching the metadata with outside files:\n",
    "    # path_syntax = get_code_path() / \"data/syntax\"\n",
    "    path_syntax = get_code_path() / \"data\" / \"syntax_new_no_punct\"  # testing new syntax\n",
    "\n",
    "    # Send raw metadata\n",
    "    meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "\n",
    "    # add sentence and word positions\n",
    "    meta[\"sequence_id\"] = np.cumsum(meta.is_last_word.shift(1, fill_value=False))\n",
    "    for s, d in meta.groupby(\"sequence_id\"):\n",
    "        meta.loc[d.index, \"word_id\"] = range(len(d))\n",
    "\n",
    "    meta['word_onset'] = True\n",
    "    meta['word_stop'] = meta.start + meta.duration\n",
    "    meta['sentence_onset'] = meta.word_id == 0\n",
    "    meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "    meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "    meta['constituent_onset'].fillna(False, inplace=True)\n",
    "    meta.drop('prev_closing', axis=1, inplace=True)\n",
    "\n",
    "    # Adding the sentence stop info\n",
    "    meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "    for s, d in meta.groupby('sentence_id'):\n",
    "        meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "        meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "        meta.loc[d.index, 'sentence_stop'] = d.start.max()\n",
    "\n",
    "    # Adding the constituents stop info\n",
    "    meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "    for s, d in meta.groupby('constituent_id'):\n",
    "        meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "        meta.loc[d.index, 'constituent_stop'] = d.start.max()\n",
    "        meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "        \n",
    "    base_meta['sentence_id'] = meta.sentence_id\n",
    "    base_meta['constituent_id'] = meta.constituent_id\n",
    "    return base_meta, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b469c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(1,runs+1):\n",
    "        base_meta, meta = read_raw(subject, run, events_return = True, modality=modality)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
