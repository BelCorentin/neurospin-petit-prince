{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50807f31",
   "metadata": {},
   "source": [
    "# Testing LPP MEG data's validity\n",
    "\n",
    "\n",
    "## Purpose\n",
    "The purpose of this notebook is to investigate the correct epoching and trigger time matching for the MEG recordings of the LPP paradigm.\n",
    "\n",
    "## Methodology\n",
    "- For each subject, get the 9 epochs corresponding to the first trigger (start of audio).\n",
    "- Average the MEG channels to see if there's an evoked response to the first audio stimuli\n",
    "\n",
    "## WIP - improvements\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a671a43",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3bde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import mne\n",
    "import mne_bids\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "from joblib import Parallel, delayed\n",
    "matplotlib.use(\"Agg\")\n",
    "mne.set_log_level(False)\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c464674",
   "metadata": {},
   "source": [
    "# Parameter definition\n",
    "We set all relevant parameters for our notebook. By convention, parameters are uppercase, while all the \n",
    "other variables follow Python's guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fbaaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids = \"/home/is153802/workspace_LPP/data/MEG/LPP/derivatives/final_all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7978d3f",
   "metadata": {},
   "source": [
    "\n",
    "# Data import\n",
    "We retrieve all the required data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc943e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['180131' '180517' '181017' '190506' '190513' '190611' '190621' '190715'\n",
      " '190717' '220628' '220707']\n"
     ]
    }
   ],
   "source": [
    "subjects = pd.read_csv(bids + \"/participants.tsv\", sep=\"\\t\")\n",
    "subjects = subjects.participant_id.apply(lambda x: x.split(\"-\")[1]).values\n",
    "subjects = np.delete(subjects,subjects.shape[0]-1)\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7fee0",
   "metadata": {},
   "source": [
    "Rename the fif files that have been preprocessed to the BIDS standart (*_raw.fif to *_meg.fif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e69e2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done already for the current batch of filtered data by the MNE BIDS Pipeline\n",
    "\"\"\"\n",
    "for subject in subjects:\n",
    "    subj_path = os.path.join(bids,'sub-'+subject,'ses-01/meg')\n",
    "    for filename in os.listdir(subj_path):\n",
    "        infilename = os.path.join(subj_path,filename)\n",
    "        if not os.path.isfile(infilename): continue\n",
    "        oldbase = os.path.splitext(filename)\n",
    "        newname = infilename.replace('raw.fif', 'meg.fif')\n",
    "        output = os.rename(infilename, newname)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6087d9e",
   "metadata": {},
   "source": [
    "Add the needed files (events, headposition & co) to the newly generated post-processing folders (done manually; faster than doing a regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631be6c",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "\n",
    "## Trying to use the first trigger to see the evoked response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4486c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_epochs(subject):\n",
    "    print(\"entering getepochs\")\n",
    "    all_epochs = list()\n",
    "    for session in range(1,2):\n",
    "        for run in range(1,2):\n",
    "            task = 'rest'\n",
    "            print(\".\", end=\"\")\n",
    "            bids_path = mne_bids.BIDSPath(\n",
    "                subject=subject,\n",
    "                session='0'+str(session),\n",
    "                task=str(task),\n",
    "                datatype=\"meg\",\n",
    "                root=bids,\n",
    "                run = run,\n",
    "                processing = \"sss\"\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                print(bids_path)\n",
    "                raw = mne_bids.read_raw_bids(bids_path)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"missing, \\nsubject:{subject}\\nsession: {session}\\ntask: {task}\\nrun: {run}\")\n",
    "                continue\n",
    "            raw = raw.pick_types(\n",
    "                meg=True, misc=False, eeg=False, eog=False, ecg=False\n",
    "            )\n",
    "\n",
    "            raw.load_data().filter(0.5, 30.0, n_jobs=1)\n",
    "            \n",
    "            meta = list()\n",
    "            # print(f\"\\n\\n annot: {raw.annotations}\\n\\n\")\n",
    "            for annot in raw.annotations:\n",
    "                try:\n",
    "                    a = annot.pop(\"description\")\n",
    "                    d = eval(a)\n",
    "                except:\n",
    "                    print(f\"eval error: {a}\")\n",
    "                    continue\n",
    "                # print(f\"\\n\\n d: {d}\\n\\n\")\n",
    "                for k, v in annot.items():\n",
    "                    assert k not in d.keys()\n",
    "                    d[k] = v\n",
    "                meta.append(d)\n",
    "            meta = pd.DataFrame(meta)\n",
    "            meta[\"intercept\"] = 1.0\n",
    "\n",
    "            # segment on first event\n",
    "            events = np.c_[\n",
    "                meta.onset * raw.info[\"sfreq\"], np.ones((len(meta), 2))\n",
    "            ].astype(int)\n",
    "\n",
    "            epochs = mne.Epochs(\n",
    "                raw,\n",
    "                events,\n",
    "                tmin=-0.200,\n",
    "                tmax=0.6,\n",
    "                decim=10,\n",
    "                baseline=(-0.2, 0.0),\n",
    "                metadata=meta,\n",
    "                preload=True,\n",
    "                event_repeated=\"drop\",\n",
    "            )\n",
    "\n",
    "            # threshold\n",
    "            th = np.percentile(np.abs(epochs._data), 95)\n",
    "            epochs._data[:] = np.clip(epochs._data, -th, th)\n",
    "            epochs.apply_baseline()\n",
    "            th = np.percentile(np.abs(epochs._data), 95)\n",
    "            epochs._data[:] = np.clip(epochs._data, -th, th)\n",
    "            epochs.apply_baseline()\n",
    "\n",
    "            epochs.metadata[\"half\"] = np.round(\n",
    "                np.linspace(0, 1.0, len(epochs))\n",
    "            ).astype(int)\n",
    "            epochs.metadata[\"task\"] = task\n",
    "            epochs.metadata[\"session\"] = session\n",
    "\n",
    "            all_epochs.append(epochs)\n",
    "    if not len(all_epochs):\n",
    "        return\n",
    "    epochs = mne.concatenate_epochs(all_epochs)\n",
    "    m = epochs.metadata\n",
    "    label = (\n",
    "        \"t\"\n",
    "        + m.task.astype(str)\n",
    "        + \"_s\"\n",
    "        + m.session.astype(str)\n",
    "        + \"_h\"\n",
    "        + m.half.astype(str)\n",
    "    )\n",
    "    epochs.metadata[\"label\"] = label\n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23315d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering getepochs\n",
      "./home/is153802/workspace_LPP/data/MEG/LPP/derivatives/final_all/sub-190611/ses-01/meg/sub-190611_ses-01_task-rest_run-01_proc-sss_meg.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_352459/371846550.py:20: RuntimeWarning: The number of channels in the channels.tsv sidecar file (346) does not match the number of channels in the raw data file (309). Will not try to set channel names.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_352459/371846550.py:20: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: MISC003, MISC004, MISC005, MISC006, MISC007, MISC008, MISC201, MISC202, MISC203, MISC204, MISC205, MISC206, MISC301, MISC302, MISC303, MISC304, MISC305, MISC306, STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_352459/371846550.py:81: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(all_epochs)\n"
     ]
    }
   ],
   "source": [
    "epochs = _get_epochs(subjects[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93c01a",
   "metadata": {},
   "source": [
    "# References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe4628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b54f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
