{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1f3dcf",
   "metadata": {},
   "source": [
    "# Journal2Bord\n",
    "\n",
    "- 17.04: Retook on JR's pseudocode, in order to make it work with the dataset, and fix some misalignment issues (matchlist needed when re-epoching, index_resetting needed, and also the use of mne_events saves a lot of time)\n",
    "\n",
    "*Next: run it on Neurospin's workstation on a few more subjects, as it takes too much time on laptop.*\n",
    "\n",
    "- 18.04: Fixed more queries handling and general structure, and it runs on Neurospin Workstation.\n",
    "Pb: For one subject, one run, and decoding one feature (word embeddings), it takes around 1h...\n",
    "Added also the averaged on subject \n",
    "\n",
    "- 19.04: Fixed all the problems discussed during our weekly meeting (decim, meta handling, preload, etc..).\n",
    "\n",
    "Came up with a way to generate the plots for all conditions, added a better epochs window handling.\n",
    "\n",
    "- 20.04: Trying to reduce the RAM usage, by calculating the evos & scores directly, not keeping the epochs in memory.\n",
    "Created script for JeanZay, running jobs successfully now. \n",
    "Plot generated for different sliding windows, multiple subjects, all runs. \n",
    "\n",
    "- 21.04: Tried to adapt the newly parsed files for the syntax, adapted but the problem is that the parser has not been run on the correct LPP translation.. TODO contact the person in charge and rerun the parser\n",
    "\n",
    "Also, adapted script for Jean Zay: sent email for support to understand the memory faults.\n",
    "\n",
    "- 26.04: After iterating on Jean Zay: there is a problem with the way the offset of the different modalities is handled. The way it is currently done, there is a shift: the offset is the offset of the previous word/sent/const, instead of being the end of the one we care about. \n",
    "\n",
    "\n",
    "## TODO important\n",
    "\n",
    "- NEw parser: integrate only the correct closing nodes, and remove the rest\n",
    "- Redo the way the constituent id is calculated to handle cases where two consecutive n_closing is 2 2\n",
    "- Understand the problem with sentence decoding\n",
    "\n",
    "\n",
    "\n",
    "TODO another time:\n",
    "- investigate the events_repeated\n",
    "- train on subset for words, and decode on other modalities ?\n",
    "- If the script runs correctly on Jean Zay, add other decoding modalities, and run them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710b125",
   "metadata": {},
   "source": [
    "# Testing new syntactic parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12000c",
   "metadata": {},
   "source": [
    "### Removing regex punct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e887c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/co/code/data/syntax_new_no_punct/run1_v2_0.25_0.5-tokenized.syntax.txt\", \"r\") as file:\n",
    "        txt = file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21c5a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ans'] 4\n",
      "['vu'] 2\n",
      "['fois'] 2\n",
      "['image'] 2\n",
      "['vécues'] 6\n",
      "['Ça'] 2\n",
      "['représentait'] 2\n",
      "['fauve'] 4\n",
      "['Voilà'] 2\n",
      "['dessin'] 4\n",
      "['disait'] 2\n",
      "['livre'] 3\n",
      "['boas'] 2\n",
      "['avalent'] 2\n",
      "['proie'] 2\n",
      "['entière'] 2\n",
      "['mâcher'] 4\n",
      "['Ensuite'] 1\n",
      "['peuvent'] 2\n",
      "['plus'] 1\n",
      "['bouger'] 3\n",
      "['digestion'] 7\n",
      "['réfléchi'] 2\n",
      "['jungle'] 5\n",
      "['dessin'] 6\n",
      "['1'] 3\n",
      "['était'] 2\n",
      "['ça'] 3\n",
      "['montré'] 2\n",
      "['oeuvre'] 3\n",
      "['personnes'] 3\n",
      "['peur'] 6\n",
      "['répondu'] 2\n",
      "['pourquoi'] 1\n",
      "['chapeau'] 2\n",
      "['il'] 2\n",
      "['peur'] 2\n",
      "['dessin'] 2\n",
      "['représentait'] 2\n",
      "['pas'] 1\n",
      "['chapeau'] 2\n",
      "['représentait'] 2\n",
      "['éléphant'] 4\n",
      "['dessiné'] 2\n",
      "['boa'] 4\n",
      "['comprendre'] 5\n",
      "['ont'] 2\n",
      "['toujours'] 1\n",
      "['besoin'] 2\n",
      "['explications'] 3\n",
      "['2'] 3\n",
      "['était'] 2\n",
      "['ça'] 3\n",
      "['personnes'] 2\n",
      "['conseillé'] 2\n",
      "['grammaire'] 9\n",
      "['est'] 2\n",
      "['ainsi'] 1\n",
      "['peintre'] 5\n",
      "['découragé'] 2\n",
      "['2'] 8\n",
      "['personnes'] 2\n",
      "['comprennent'] 2\n",
      "['jamais'] 1\n",
      "['rien'] 2\n",
      "['seules'] 2\n",
      "['explications'] 6\n",
      "['dû'] 2\n",
      "['métier'] 3\n",
      "['avions'] 6\n",
      "['volé'] 2\n",
      "['monde'] 4\n",
      "['servi'] 4\n",
      "['savais'] 2\n",
      "['arizona'] 5\n",
      "['est'] 2\n",
      "['utile'] 2\n",
      "['nuit'] 5\n",
      "['eu'] 2\n",
      "['vie'] 3\n",
      "['sérieux'] 7\n",
      "['vécu'] 2\n",
      "['personnes'] 3\n",
      "['vues'] 2\n",
      "['près'] 3\n",
      "['Ça'] 2\n",
      "['amélioré'] 2\n",
      "['opinion'] 2\n",
      "['faisais'] 2\n",
      "['conservé'] 6\n",
      "['compréhensive'] 6\n",
      "['répondait'] 4\n",
      "['est'] 2\n",
      "['chapeau'] 2\n",
      "['Alors'] 1\n",
      "['parlais'] 2\n",
      "['boas'] 4\n",
      "['vierges'] 5\n",
      "['étoiles'] 4\n",
      "['mettais'] 2\n",
      "['portée'] 3\n",
      "['parlais'] 2\n",
      "['cravates'] 5\n",
      "['raisonnable'] 8\n",
      "['vécu'] 2\n",
      "['seul'] 2\n",
      "['véritablement'] 4\n",
      "['panne'] 3\n",
      "['sahara'] 5\n",
      "['ans'] 3\n",
      "['chose'] 2\n",
      "['cassé'] 2\n",
      "['moteur'] 3\n",
      "['difficile'] 9\n",
      "['était'] 2\n",
      "['moi'] 3\n",
      "['mort'] 6\n",
      "['avais'] 2\n",
      "['peine'] 2\n",
      "['boire'] 5\n",
      "['jours'] 3\n",
      "['soir'] 2\n",
      "['endormi'] 2\n",
      "['sable'] 3\n",
      "['habitée'] 6\n",
      "['étais'] 2\n",
      "['océan'] 5\n",
      "['Alors'] 1\n",
      "['imaginez'] 2\n",
      "['surprise'] 2\n",
      "['jour'] 4\n",
      "['réveillé'] 4\n",
      "['disait'] 2\n",
      "['plaît'] 4\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['hein'] 1\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['sauté'] 2\n",
      "['pieds'] 3\n",
      "['foudre'] 5\n",
      "['frotté'] 2\n",
      "['yeux'] 2\n",
      "['regardé'] 2\n",
      "['gravement'] 5\n",
      "['Voilà'] 2\n",
      "['réussi'] 4\n",
      "['modèle'] 6\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['faute'] 2\n",
      "['découragé'] 2\n",
      "['peintre'] 5\n",
      "['personnes'] 3\n",
      "['ans'] 5\n",
      "['ouverts'] 8\n",
      "['regardai'] 2\n",
      "['donc'] 1\n",
      "['apparition'] 2\n",
      "['étonnement'] 6\n",
      "['oubliez'] 2\n",
      "['pas'] 1\n",
      "['habitée'] 8\n",
      "['peur'] 7\n",
      "['avait'] 2\n",
      "['rien'] 2\n",
      "['habitée'] 10\n",
      "['dis'] 2\n",
      "[\"Qu'\"] 2\n",
      "['ce'] 2\n",
      "['là'] 2\n",
      "['Et'] 1\n",
      "['sérieuse'] 5\n",
      "['plaît'] 4\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['impressionnant'] 4\n",
      "['ose'] 2\n",
      "['pas'] 1\n",
      "['désobéir'] 3\n",
      "['mort'] 10\n",
      "['sortis'] 2\n",
      "['poche'] 3\n",
      "['stylographe'] 4\n",
      "['dessiner'] 8\n",
      "['répondit'] 2\n",
      "['ça'] 2\n",
      "['fait'] 2\n",
      "['rien'] 2\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['mouton'] 4\n",
      "['refis'] 2\n",
      "['lui'] 3\n",
      "['étais'] 6\n",
      "['fermé'] 3\n",
      "['répondre'] 7\n",
      "['non'] 1\n",
      "['Non'] 1\n",
      "['veux'] 2\n",
      "['pas'] 1\n",
      "['éléphant'] 3\n",
      "['boa'] 3\n",
      "['boa'] 2\n",
      "['est'] 2\n",
      "['dangereux'] 2\n",
      "['encombrant'] 3\n",
      "['moi'] 3\n",
      "['est'] 2\n",
      "['petit'] 2\n",
      "['besoin'] 3\n",
      "['mouton'] 3\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['Alors'] 1\n",
      "['dessiné'] 2\n",
      "['regarda'] 2\n",
      "['attentivement'] 1\n",
      "['non'] 1\n",
      "['là'] 3\n",
      "['est'] 2\n",
      "['malade'] 2\n",
      "['en'] 2\n",
      "['autre'] 2\n",
      "['Je'] 1\n",
      "['ami'] 2\n",
      "['sourit'] 2\n",
      "['gentiment'] 1\n",
      "['indulgence'] 3\n",
      "['vois'] 2\n",
      "['bien'] 1\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['mouton'] 2\n",
      "['bélier'] 3\n",
      "['a'] 2\n",
      "['cornes'] 2\n",
      "['refis'] 2\n",
      "['donc'] 1\n",
      "['encore'] 1\n",
      "['dessin'] 2\n",
      "['là'] 3\n",
      "['est'] 2\n",
      "['vieux'] 2\n",
      "['veux'] 2\n",
      "['longtemps'] 3\n",
      "['Alors'] 1\n",
      "['patience'] 3\n",
      "['moteur'] 8\n",
      "['griffonnai'] 2\n",
      "['lançai'] 3\n",
      "['ça'] 2\n",
      "['est'] 2\n",
      "['caisse'] 2\n",
      "['veux'] 4\n",
      "['est'] 2\n",
      "['dedans'] 1\n",
      "['juge'] 9\n",
      "['fait'] 3\n",
      "['ça'] 3\n",
      "['voulais'] 3\n",
      "['tu'] 2\n",
      "['mouton'] 5\n",
      "['pourquoi'] 1\n",
      "['petit'] 4\n",
      "['ça'] 2\n",
      "['suffira'] 2\n",
      "['sûrement'] 1\n",
      "['donné'] 2\n",
      "['mouton'] 2\n",
      "['pencha'] 2\n",
      "['tête'] 2\n",
      "['dessin'] 3\n",
      "['ça'] 4\n",
      "['Tiens'] 1\n",
      "['endormi'] 2\n",
      "['prince'] 6\n",
      "['fallut'] 2\n",
      "['longtemps'] 1\n",
      "['venait'] 5\n",
      "['questions'] 4\n",
      "['semblait'] 2\n",
      "['jamais'] 1\n",
      "['miennes'] 3\n",
      "['sont'] 2\n",
      "['révélé'] 4\n",
      "['Ainsi'] 1\n",
      "['avion'] 4\n",
      "['dessinerai'] 2\n",
      "['pas'] 1\n",
      "['avion'] 2\n",
      "['moi'] 6\n",
      "['demanda'] 2\n",
      "[\"qu'\"] 2\n",
      "['ce'] 2\n",
      "['là'] 4\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['chose'] 2\n",
      "['Ça'] 2\n",
      "['vole'] 2\n",
      "['est'] 2\n",
      "['avion'] 2\n",
      "['est'] 2\n",
      "['avion'] 2\n",
      "['volais'] 9\n",
      "['Alors'] 1\n",
      "['comment'] 1\n",
      "['tombé'] 2\n",
      "['ciel'] 3\n",
      "['oui'] 1\n",
      "['je'] 2\n",
      "['modestement'] 1\n",
      "['ah'] 1\n",
      "['Ça'] 2\n",
      "['est'] 2\n",
      "['drôle'] 2\n",
      "['beaucoup'] 5\n",
      "['désire'] 2\n",
      "['sérieux'] 5\n",
      "['ajouta'] 3\n",
      "['alors'] 1\n",
      "['aussi'] 2\n",
      "['viens'] 2\n",
      "['ciel'] 3\n",
      "['planète'] 3\n",
      "['tu'] 2\n",
      "['entrevis'] 2\n",
      "['aussitôt'] 1\n",
      "['lueur'] 2\n",
      "['présence'] 5\n",
      "['brusquement'] 3\n",
      "['viens'] 2\n",
      "['donc'] 1\n",
      "['planète'] 3\n",
      "['pas'] 3\n",
      "['hochait'] 2\n",
      "['tête'] 2\n",
      "['doucement'] 1\n",
      "['avion'] 4\n",
      "['est'] 2\n",
      "['vrai'] 2\n",
      "['loin'] 6\n",
      "['longtemps'] 5\n",
      "['trésor'] 7\n",
      "['imaginez'] 2\n",
      "['planètes'] 7\n",
      "['efforçai'] 2\n",
      "['donc'] 1\n",
      "['long'] 4\n",
      "['où'] 2\n",
      "['tu'] 2\n",
      "['bonhomme'] 2\n",
      "['Où'] 1\n",
      "['ce'] 2\n",
      "['toi'] 3\n",
      "['mouton'] 3\n",
      "['tu'] 2\n",
      "['répondit'] 2\n",
      "['méditatif'] 4\n",
      "['ce'] 1\n",
      "['bien'] 2\n",
      "['donnée'] 5\n",
      "['est'] 2\n",
      "['maison'] 5\n",
      "['sûr'] 2\n",
      "['jour'] 8\n",
      "['Et'] 1\n",
      "['piquet'] 2\n",
      "['proposition'] 2\n",
      "['parut'] 2\n",
      "['prince'] 3\n",
      "['attacher'] 3\n",
      "['idée'] 2\n",
      "['perdra'] 6\n",
      "['rire'] 5\n",
      "['aille'] 6\n",
      "['où'] 2\n",
      "['lui'] 4\n",
      "['Alors'] 1\n",
      "['prince'] 2\n",
      "['remarqua'] 2\n",
      "['gravement'] 1\n",
      "['ça'] 2\n",
      "['fait'] 2\n",
      "['rien'] 2\n",
      "['ajouta'] 4\n",
      "['soi'] 4\n",
      "['peut'] 2\n",
      "['pas'] 1\n",
      "['loin'] 3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for line in txt:\n",
    "    count = 0\n",
    "    for tok in line.split(' '):\n",
    "        if tok.__contains__('('):\n",
    "            count+=1*tok.count('(')\n",
    "            \n",
    "        elif tok.__contains__(')'):\n",
    "            count-=1*tok.count(')')\n",
    "        if count==1:\n",
    "            pattern = r'=(.*?)\\)'\n",
    "            matches = re.findall(pattern, tok)\n",
    "\n",
    "            sub_tok = matches\n",
    "            if sub_tok!=[]:\n",
    "                print(sub_tok,tok.count(')'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2fcd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(1,10):\n",
    "    \n",
    "    # Read the contents of the text file\n",
    "    with open(f\"/home/co/code/data/syntax_new_untested/run{i}_v2_0.25_0.5-tokenized.syntax.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Define the pattern to match substrings like (PONCT 3=,)\n",
    "    pattern = r'\\(PONCT\\s\\d+[^)]*\\)'\n",
    "    # Remove the substrings using re.sub()\n",
    "    clean_text = re.sub(pattern, '', text)\n",
    "\n",
    "    clean_text\n",
    "    # Write the cleaned text back to the file\n",
    "    with open(f\"/home/co/code/data/syntax_new_no_punct/run{i}_v2_0.25_0.5-tokenized.syntax.txt\", \"w\") as file:\n",
    "        file.write(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4454fd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoching for run 1, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 89000 ... 554999 =     89.000 ...   554.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Reading 0 ... 465999  =      0.000 ...   465.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "def mne_events(meta, raw, start, level):\n",
    "    if start=='onset':\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = meta.start * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "    elif start=='offset':\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = (meta.start+meta.duration) * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "        \n",
    "    else:\n",
    "        print('start should be either onset or offset')\n",
    "        return 0\n",
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 1\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "levels = ('word')\n",
    "starts = ('onset')\n",
    "            \n",
    "for subject in subjects[2:3]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max() # TO Verify!\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max() # TO Verify!\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe1796f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>constituent_id</th>\n",
       "      <th>n_closing</th>\n",
       "      <th>const_word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lorsque</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j'avais</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>six</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ans,</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j'ai</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vu,</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>une</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fois,</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>une</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>magnifique</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>image,</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dans</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>un</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>livre</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sur</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>la</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>forêt</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vierge</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qui</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s'appelait</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>histoires</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vécues.</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ça</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>représentait</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>un</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>serpent</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>boa</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>qui</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>avalait</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>un</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fauve.</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Voilà</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>la</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>copie</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>du</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dessin.</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>On</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>disait</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>dans</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>le</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>livre:</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>les</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>serpents</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>boas</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>avalent</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>leur</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>proie</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tout</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>entière,</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sans</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  constituent_id  n_closing  const_word_id\n",
       "0        Lorsque               0          1            0.0\n",
       "1        j'avais               0          2            1.0\n",
       "2            six               1          1            0.0\n",
       "3           ans,               1          4            1.0\n",
       "4           j'ai               2          1            0.0\n",
       "5            vu,               2          2            1.0\n",
       "6            une               3          1            0.0\n",
       "7          fois,               3          2            1.0\n",
       "8            une               4          1            0.0\n",
       "9     magnifique               4          1            1.0\n",
       "10        image,               4          2            2.0\n",
       "11          dans               5          1            0.0\n",
       "12            un               5          1            1.0\n",
       "13         livre               5          1            2.0\n",
       "14           sur               5          1            3.0\n",
       "15            la               5          1            4.0\n",
       "16         forêt               5          1            5.0\n",
       "17        vierge               5          4            6.0\n",
       "18           qui               5          2            7.0\n",
       "19    s'appelait               5          2            8.0\n",
       "20     histoires               6          1            0.0\n",
       "21       vécues.               6          7            1.0\n",
       "22            Ça               7          1            0.0\n",
       "23  représentait               7          2            1.0\n",
       "24            un               8          1            0.0\n",
       "25       serpent               8          1            1.0\n",
       "26           boa               8          1            2.0\n",
       "27           qui               8          2            3.0\n",
       "28       avalait               8          2            4.0\n",
       "29            un               9          1            0.0\n",
       "30        fauve.               9          5            1.0\n",
       "31         Voilà              10          1            0.0\n",
       "32            la              10          1            1.0\n",
       "33         copie              10          1            2.0\n",
       "34            du              10          1            3.0\n",
       "35       dessin.              10          5            4.0\n",
       "36            On              11          1            0.0\n",
       "37        disait              11          2            1.0\n",
       "38          dans              12          1            0.0\n",
       "39            le              12          1            1.0\n",
       "40        livre:              12          4            2.0\n",
       "41           les              13          1            0.0\n",
       "42      serpents              13          1            1.0\n",
       "43          boas              13          2            2.0\n",
       "44       avalent              13          2            3.0\n",
       "45          leur              14          1            0.0\n",
       "46         proie              14          2            1.0\n",
       "47          tout              15          1            0.0\n",
       "48      entière,              15          2            1.0\n",
       "49          sans              16          1            0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[['word', 'constituent_id','n_closing','const_word_id']][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799f565",
   "metadata": {},
   "source": [
    "# Initial Plotting for ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "465a561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SENT 1\n",
      "(Ssub-MOD 2\n",
      "(CS 3\n",
      "0=Lorsque) 2\n",
      "(Sint 3\n",
      "(VN 4\n",
      "(CLS-SUJ 5\n",
      "1=j') 4\n",
      "(V 5\n",
      "2=avais)) 3\n",
      "(NP-OBJ 4\n",
      "(DET 5\n",
      "3=six) 4\n",
      "(NC 5\n",
      "4=ans)))) 1\n",
      " 1\n",
      "(VN 2\n",
      "(CLS-SUJ 3\n",
      "6=j') 2\n",
      "(V 3\n",
      "7=ai) 2\n",
      "(VPP 3\n",
      "8=vu)) 1\n",
      " 1\n",
      "(NP-MOD 2\n",
      "(DET 3\n",
      "10=une) 2\n",
      "(NC 3\n",
      "11=fois)) 1\n",
      " 1\n",
      "(NP-OBJ 2\n",
      "(DET 3\n",
      "13=une) 2\n",
      "(ADJ 3\n",
      "14=magnifique) 2\n",
      "(NC 3\n",
      "15=image)) 1\n",
      " 1\n",
      "(PP-MOD 2\n",
      "(P 3\n",
      "17=dans) 2\n",
      "(NP 3\n",
      "(DET 4\n",
      "18=un) 3\n",
      "(NC 4\n",
      "19=livre) 3\n",
      "(PP 4\n",
      "(P 5\n",
      "20=sur) 4\n",
      "(NP 5\n",
      "(DET 6\n",
      "21=la) 5\n",
      "(NC 6\n",
      "22=forêt) 5\n",
      "(AP 6\n",
      "(ADJ 7\n",
      "23=vierge)))) 3\n",
      "(Srel 4\n",
      "(NP-SUJ 5\n",
      "(PROREL 6\n",
      "24=qui)) 4\n",
      "(VN 5\n",
      "(CLR 6\n",
      "25=s') 5\n",
      "(V 6\n",
      "26=appelait)) 4\n",
      "(NP-ATS 5\n",
      "(NC 6\n",
      "27=histoires) 5\n",
      "(VPpart 6\n",
      "(VPP 7\n",
      "28=vécues)))))) 1\n",
      ")\n",
      "(SENT 2\n",
      "(NP-SUJ 3\n",
      "(PRO 4\n",
      "0=Ça)) 2\n",
      "(VN 3\n",
      "(V 4\n",
      "1=représentait)) 2\n",
      "(NP-OBJ 3\n",
      "(DET 4\n",
      "2=un) 3\n",
      "(NC 4\n",
      "3=serpent) 3\n",
      "(NC 4\n",
      "4=boa) 3\n",
      "(Srel 4\n",
      "(NP-SUJ 5\n",
      "(PROREL 6\n",
      "5=qui)) 4\n",
      "(VN 5\n",
      "(V 6\n",
      "6=avalait)) 4\n",
      "(NP-OBJ 5\n",
      "(DET 6\n",
      "7=un) 5\n",
      "(NC 6\n",
      "8=fauve)))) 2\n",
      ")\n",
      "(SENT 3\n",
      "(VN 4\n",
      "(V 5\n",
      "0=Voilà)) 3\n",
      "(NP-OBJ 4\n",
      "(DET 5\n",
      "1=la) 4\n",
      "(NC 5\n",
      "2=copie) 4\n",
      "(PP 5\n",
      "(P+D 6\n",
      "3=du) 5\n",
      "(NP 6\n",
      "(NC 7\n",
      "4=dessin)))) 3\n",
      ")\n",
      "(SENT 4\n",
      "(VN 5\n",
      "(CLS-SUJ 6\n",
      "0=On) 5\n",
      "(V 6\n",
      "1=disait)) 4\n",
      "(PP-MOD 5\n",
      "(P 6\n",
      "2=dans) 5\n",
      "(NP 6\n",
      "(DET 7\n",
      "3=le) 6\n",
      "(NC 7\n",
      "4=livre))) 4\n",
      ")\n",
      "(SENT 5\n",
      "(NP-SUJ 6\n",
      "(DET 7\n",
      "0=les) 6\n",
      "(NC 7\n",
      "1=serpents) 6\n",
      "(ADJ 7\n",
      "2=boas)) 5\n",
      "(VN 6\n",
      "(V 7\n",
      "3=avalent)) 5\n",
      "(NP-OBJ 6\n",
      "(DET 7\n",
      "4=leur) 6\n",
      "(NC 7\n",
      "5=proie)) 5\n",
      "(AP-MOD 6\n",
      "(ADV 7\n",
      "6=tout) 6\n",
      "(ADJ 7\n",
      "7=entière)) 5\n",
      " 5\n",
      "(PP-MOD 6\n",
      "(P 7\n",
      "9=sans) 6\n",
      "(VPinf 7\n",
      "(VN 8\n",
      "(CLO-OBJ 9\n",
      "10=la) 8\n",
      "(VINF 9\n",
      "11=mâcher)))) 5\n",
      ")\n",
      "(SENT 6\n",
      "(ADV 7\n",
      "0=Ensuite) 6\n",
      "(VN 7\n",
      "(CLS-SUJ 8\n",
      "1=ils) 7\n",
      "(ADV 8\n",
      "2=ne) 7\n",
      "(V 8\n",
      "3=peuvent)) 6\n",
      "(ADV 7\n",
      "4=plus) 6\n",
      "(VPinf-OBJ 7\n",
      "(VN 8\n",
      "(VINF 9\n",
      "5=bouger))) 6\n",
      "(COORD 7\n",
      "(CC 8\n",
      "6=et) 7\n",
      "(Sint 8\n",
      "(VN 9\n",
      "(CLS-SUJ 10\n",
      "7=ils) 9\n",
      "(V 10\n",
      "8=dorment)) 8\n",
      "(PP-MOD 9\n",
      "(P 10\n",
      "9=pendant) 9\n",
      "(NP 10\n",
      "(DET 11\n",
      "10=les) 10\n",
      "(ADJ 11\n",
      "11=six) 10\n",
      "(NC 11\n",
      "12=mois) 10\n",
      "(PP 11\n",
      "(P 12\n",
      "13=de) 11\n",
      "(NP 12\n",
      "(DET 13\n",
      "14=leur) 12\n",
      "(NC 13\n",
      "15=digestion))))))) 6\n",
      ")\n",
      "(SENT 7\n",
      "(VN 8\n",
      "(CLS-SUJ 9\n",
      "0=J') 8\n",
      "(V 9\n",
      "1=ai) 8\n",
      "(ADV 9\n",
      "2=alors) 8\n",
      "(ADV 9\n",
      "3=beaucoup) 8\n",
      "(VPP 9\n",
      "4=réfléchi)) 7\n",
      "(PP-MOD 8\n",
      "(P 9\n",
      "5=sur) 8\n",
      "(NP 9\n",
      "(DET 10\n",
      "6=les) 9\n",
      "(NC 10\n",
      "7=aventures) 9\n",
      "(PP 10\n",
      "(P 11\n",
      "8=de) 10\n",
      "(NP 11\n",
      "(DET 12\n",
      "9=la) 11\n",
      "(NC 12\n",
      "10=jungle))))) 7\n",
      "(COORD 8\n",
      "(CC 9\n",
      "11=et) 8\n",
      "(Sint 9\n",
      " 9\n",
      "(ADV+ 10\n",
      "(P 11\n",
      "13=à) 10\n",
      "(DET 11\n",
      "14=mon) 10\n",
      "(NC 11\n",
      "15=tour)) 9\n",
      " 9\n",
      "(VN 10\n",
      "(CLS-SUJ 11\n",
      "17=j') 10\n",
      "(V 11\n",
      "18=ai) 10\n",
      "(VPP 11\n",
      "19=réussi)) 9\n",
      " 9\n",
      "(PP-MOD 10\n",
      "(P 11\n",
      "21=avec) 10\n",
      "(NP 11\n",
      "(DET 12\n",
      "22=un) 11\n",
      "(NC 12\n",
      "23=crayon) 11\n",
      "(PP 12\n",
      "(P 13\n",
      "24=de) 12\n",
      "(NP 13\n",
      "(NC 14\n",
      "25=couleur))))) 9\n",
      " 9\n",
      "(PP-OBJ 10\n",
      "(P 11\n",
      "27=à) 10\n",
      "(VPinf 11\n",
      "(VN 12\n",
      "(VINF 13\n",
      "28=tracer)) 11\n",
      "(NP-OBJ 12\n",
      "(DET 13\n",
      "29=mon) 12\n",
      "(ADJ 13\n",
      "30=premier) 12\n",
      "(NC 13\n",
      "31=dessin)))))) 7\n",
      ")\n",
      "(SENT 8\n",
      "(NP 9\n",
      "(NP 10\n",
      "(DET 11\n",
      "0=Mon) 10\n",
      "(NC 11\n",
      "1=dessin)) 9\n",
      "(NP 10\n",
      "(NC 11\n",
      "2=numéro) 10\n",
      "(ADJ 11\n",
      "3=1))) 8\n",
      ")\n",
      "(SENT 9\n",
      "(VN 10\n",
      "(CLS-SUJ 11\n",
      "0=Il) 10\n",
      "(V 11\n",
      "1=était)) 9\n",
      "(PP-ATS 10\n",
      "(P 11\n",
      "2=comme) 10\n",
      "(NP 11\n",
      "(PRO 12\n",
      "3=ça))) 9\n",
      ")\n",
      "(SENT 10\n",
      "(VN 11\n",
      "(CLS-SUJ 12\n",
      "0=j') 11\n",
      "(V 12\n",
      "1=ai) 11\n",
      "(VPP 12\n",
      "2=montré)) 10\n",
      "(NP-OBJ 11\n",
      "(DET 12\n",
      "3=mon) 11\n",
      "(NC+ 12\n",
      "(NC 13\n",
      "4=chef) 12\n",
      "(P 13\n",
      "5=d') 12\n",
      "(NC 13\n",
      "6=oeuvre))) 10\n",
      "(PP-A_OBJ 11\n",
      "(P+D 12\n",
      "7=aux) 11\n",
      "(NP 12\n",
      "(ADJ 13\n",
      "8=grandes) 12\n",
      "(NC 13\n",
      "9=personnes))) 10\n",
      "(COORD 11\n",
      "(CC 12\n",
      "10=et) 11\n",
      "(Sint 12\n",
      "(VN 13\n",
      "(CLS-SUJ 14\n",
      "11=je) 13\n",
      "(CLO-A_OBJ 14\n",
      "12=leur) 13\n",
      "(V 14\n",
      "13=ai) 13\n",
      "(VPP 14\n",
      "14=demandé)) 12\n",
      "(Ssub-OBJ 13\n",
      "(CS 14\n",
      "15=si) 13\n",
      "(Sint 14\n",
      "(NP-SUJ 15\n",
      "(DET 16\n",
      "16=mon) 15\n",
      "(NC 16\n",
      "17=dessin)) 14\n",
      "(VN 15\n",
      "(CLO-A_OBJ 16\n",
      "18=leur) 15\n",
      "(V 16\n",
      "19=faisait)) 14\n",
      "(NP-OBJ 15\n",
      "(NC 16\n",
      "20=peur)))))) 10\n",
      ")\n",
      "(SENT 11\n",
      "(VN 12\n",
      "(CLS-SUJ 13\n",
      "0=Elles) 12\n",
      "(CLO-A_OBJ 13\n",
      "1=m') 12\n",
      "(V 13\n",
      "2=ont) 12\n",
      "(VPP 13\n",
      "3=répondu)) 11\n",
      ")\n",
      "(SENT 12\n",
      "(ADVWH-MOD 13\n",
      "0=pourquoi) 12\n",
      "(NP-SUJ 13\n",
      "(DET 14\n",
      "1=un) 13\n",
      "(NC 14\n",
      "2=chapeau)) 12\n",
      "(VN 13\n",
      "(V 14\n",
      "3=ferait) 13\n",
      "(CLS-SUJ 14\n",
      "4=il)) 12\n",
      "(NP-OBJ 13\n",
      "(NC 14\n",
      "5=peur)) 12\n",
      ")\n",
      "(SENT 13\n",
      "(NP-SUJ 14\n",
      "(DET 15\n",
      "0=Mon) 14\n",
      "(NC 15\n",
      "1=dessin)) 13\n",
      "(VN 14\n",
      "(ADV 15\n",
      "2=ne) 14\n",
      "(V 15\n",
      "3=représentait)) 13\n",
      "(ADV 14\n",
      "4=pas) 13\n",
      "(NP-OBJ 14\n",
      "(DET 15\n",
      "5=un) 14\n",
      "(NC 15\n",
      "6=chapeau)) 13\n",
      ")\n",
      "(SENT 14\n",
      "(VN 15\n",
      "(CLS-SUJ 16\n",
      "0=Il) 15\n",
      "(V 16\n",
      "1=représentait)) 14\n",
      "(NP-OBJ 15\n",
      "(DET 16\n",
      "2=un) 15\n",
      "(NC 16\n",
      "3=serpent) 15\n",
      "(NC 16\n",
      "4=boa) 15\n",
      "(Srel 16\n",
      "(NP-SUJ 17\n",
      "(PROREL 18\n",
      "5=qui)) 16\n",
      "(VN 17\n",
      "(V 18\n",
      "6=digérait)) 16\n",
      "(NP-OBJ 17\n",
      "(DET 18\n",
      "7=un) 17\n",
      "(NC 18\n",
      "8=éléphant)))) 14\n",
      ")\n",
      "(SENT 15\n",
      "(VN 16\n",
      "(CLS-SUJ 17\n",
      "0=J') 16\n",
      "(V 17\n",
      "1=ai) 16\n",
      "(ADV 17\n",
      "2=alors) 16\n",
      "(VPP 17\n",
      "3=dessiné)) 15\n",
      "(NP-OBJ 16\n",
      "(DET 17\n",
      "4=l') 16\n",
      "(NC 17\n",
      "5=intérieur) 16\n",
      "(PP 17\n",
      "(P+D 18\n",
      "6=du) 17\n",
      "(NP 18\n",
      "(NC 19\n",
      "7=serpent) 18\n",
      "(NC 19\n",
      "8=boa)))) 15\n",
      " 15\n",
      "(Ssub-MOD 16\n",
      "(CS+ 17\n",
      "(P 18\n",
      "10=afin) 17\n",
      "(CS 18\n",
      "11=que)) 16\n",
      "(Sint 17\n",
      "(NP-SUJ 18\n",
      "(DET 19\n",
      "12=les) 18\n",
      "(ADJ 19\n",
      "13=grandes) 18\n",
      "(NC 19\n",
      "14=personnes)) 17\n",
      "(VN 18\n",
      "(VS 19\n",
      "15=puissent)) 17\n",
      "(VPinf-OBJ 18\n",
      "(VN 19\n",
      "(VINF 20\n",
      "16=comprendre))))) 15\n",
      ")\n",
      "(SENT 16\n",
      "(VN 17\n",
      "(CLS-SUJ 18\n",
      "0=Elles) 17\n",
      "(V 18\n",
      "1=ont)) 16\n",
      "(ADV 17\n",
      "2=toujours) 16\n",
      "(NP-OBJ 17\n",
      "(NC 18\n",
      "3=besoin)) 16\n",
      "(PP-DE_OBJ 17\n",
      "(P 18\n",
      "4=d') 17\n",
      "(NP 18\n",
      "(NC 19\n",
      "5=explications))) 16\n",
      ")\n",
      "(SENT 17\n",
      "(NP-SUJ 18\n",
      "(DET 19\n",
      "0=Mon) 18\n",
      "(NC 19\n",
      "1=dessin) 18\n",
      "(NP 19\n",
      "(NC 20\n",
      "2=numéro) 19\n",
      "(ADJ 20\n",
      "3=2))) 17\n",
      "(VN 18\n",
      "(V 19\n",
      "4=était)) 17\n",
      "(PP-ATS 18\n",
      "(P 19\n",
      "5=comme) 18\n",
      "(NP 19\n",
      "(PRO 20\n",
      "6=ça))) 17\n",
      ")\n",
      "(SENT 18\n",
      "(NP-SUJ 19\n",
      "(DET 20\n",
      "0=les) 19\n",
      "(ADJ 20\n",
      "1=grandes) 19\n",
      "(NC 20\n",
      "2=personnes)) 18\n",
      "(VN 19\n",
      "(CLO-A_OBJ 20\n",
      "3=m') 19\n",
      "(V 20\n",
      "4=ont) 19\n",
      "(VPP 20\n",
      "5=conseillé)) 18\n",
      "(PP-OBJ 19\n",
      "(P 20\n",
      "6=de) 19\n",
      "(VPinf 20\n",
      "(VN 21\n",
      "(VINF 22\n",
      "7=laisser)) 20\n",
      "(ADV+ 21\n",
      "(P 22\n",
      "8=de) 21\n",
      "(NP 22\n",
      "(NC 23\n",
      "9=côté))) 20\n",
      "(NP-OBJ 21\n",
      "(DET 22\n",
      "10=les) 21\n",
      "(NC 22\n",
      "11=dessins) 21\n",
      "(PP 22\n",
      "(P 23\n",
      "12=de) 22\n",
      "(NP 23\n",
      "(NC+ 24\n",
      "(NC 25\n",
      "13=serpents) 24\n",
      "(ET 25\n",
      "14=boas)) 23\n",
      "(AP 24\n",
      "(ADJ 25\n",
      "15=ouverts) 24\n",
      "(COORD 25\n",
      "(CC 26\n",
      "16=ou) 25\n",
      "(AP 26\n",
      "(ADJ 27\n",
      "17=fermés)))))))) 19\n",
      " 19\n",
      "(COORD 20\n",
      "(CC 21\n",
      "19=et) 20\n",
      "(PP 21\n",
      "(P 22\n",
      "20=de) 21\n",
      "(VPinf 22\n",
      "(VN 23\n",
      "(CLR-OBJ 24\n",
      "21=m') 23\n",
      "(VINF 24\n",
      "22=intéresser)) 22\n",
      "(ADV 23\n",
      "23=plutôt) 22\n",
      "(PP-A_OBJ 23\n",
      "(P 24\n",
      "24=à) 23\n",
      "(NP 24\n",
      "(DET 25\n",
      "25=la) 24\n",
      "(NC 25\n",
      "26=géographie)) 23\n",
      "(COORD 24\n",
      " 24\n",
      "(PP 25\n",
      "(P 26\n",
      "28=à) 25\n",
      "(NP 26\n",
      "(DET 27\n",
      "29=l') 26\n",
      "(NC 27\n",
      "30=histoire)))) 23\n",
      "(COORD 24\n",
      " 24\n",
      "(PP 25\n",
      "(P+D 26\n",
      "32=au) 25\n",
      "(NP 26\n",
      "(NC 27\n",
      "33=calcul)))) 23\n",
      "(COORD 24\n",
      "(CC 25\n",
      "34=et) 24\n",
      "(PP 25\n",
      "(P 26\n",
      "35=à) 25\n",
      "(NP 26\n",
      "(DET 27\n",
      "36=la) 26\n",
      "(NC 27\n",
      "37=grammaire))))))))) 18\n",
      ")\n",
      "(SENT 19\n",
      "(VN 20\n",
      "(CLS-SUJ 21\n",
      "0=C') 20\n",
      "(V 21\n",
      "1=est)) 19\n",
      "(ADV 20\n",
      "2=ainsi) 19\n",
      "(Ssub-ATS 20\n",
      "(NP-ATS 21\n",
      "(PROREL 22\n",
      "3=que)) 20\n",
      "(VN 21\n",
      "(CLS-SUJ 22\n",
      "4=j') 21\n",
      "(V 22\n",
      "5=ai) 21\n",
      "(VPP 22\n",
      "6=abandonné)) 20\n",
      " 20\n",
      "(PP-MOD 21\n",
      "(P 22\n",
      "8=à) 21\n",
      "(NP 22\n",
      "(DET 23\n",
      "9=l') 22\n",
      "(NC 23\n",
      "10=âge) 22\n",
      "(PP 23\n",
      "(P 24\n",
      "11=de) 23\n",
      "(NP 24\n",
      "(DET 25\n",
      "12=six) 24\n",
      "(NC 25\n",
      "13=ans))))) 20\n",
      " 20\n",
      "(NP-OBJ 21\n",
      "(DET 22\n",
      "15=une) 21\n",
      "(ADJ 22\n",
      "16=magnifique) 21\n",
      "(NC 22\n",
      "17=carrière) 21\n",
      "(PP 22\n",
      "(P 23\n",
      "18=de) 22\n",
      "(NP 23\n",
      "(NC 24\n",
      "19=peintre))))) 19\n",
      ")\n",
      "(SENT 20\n",
      "(VN 21\n",
      "(CLS-SUJ 22\n",
      "0=J') 21\n",
      "(V 22\n",
      "1=avais) 21\n",
      "(VPP 22\n",
      "2=été) 21\n",
      "(VPP 22\n",
      "3=découragé)) 20\n",
      "(PP-P_OBJ 21\n",
      "(P 22\n",
      "4=par) 21\n",
      "(NP 22\n",
      "(DET 23\n",
      "5=l') 22\n",
      "(NC 23\n",
      "6=insuccès) 22\n",
      "(PP 23\n",
      "(P 24\n",
      "7=de) 23\n",
      "(NP 24\n",
      "(DET 25\n",
      "8=mon) 24\n",
      "(NC 25\n",
      "9=dessin) 24\n",
      "(NC 25\n",
      "10=numéro) 24\n",
      "(ADJ 25\n",
      "11=1)) 23\n",
      "(COORD 24\n",
      "(CC 25\n",
      "12=et) 24\n",
      "(PP 25\n",
      "(P 26\n",
      "13=de) 25\n",
      "(NP 26\n",
      "(DET 27\n",
      "14=mon) 26\n",
      "(NC 27\n",
      "15=dessin) 26\n",
      "(NP 27\n",
      "(NC 28\n",
      "16=numéro) 27\n",
      "(ADJ 28\n",
      "17=2)))))))) 20\n",
      ")\n",
      "(SENT 21\n",
      "(NP-SUJ 22\n",
      "(DET 23\n",
      "0=Les) 22\n",
      "(ADJ 23\n",
      "1=grandes) 22\n",
      "(NC 23\n",
      "2=personnes)) 21\n",
      "(VN 22\n",
      "(ADV 23\n",
      "3=ne) 22\n",
      "(V 23\n",
      "4=comprennent)) 21\n",
      "(ADV 22\n",
      "5=jamais) 21\n",
      "(NP-OBJ 22\n",
      "(PRO 23\n",
      "6=rien)) 21\n",
      "(NP-MOD 22\n",
      "(ADJ 23\n",
      "7=toutes) 22\n",
      "(ADJ 23\n",
      "8=seules)) 21\n",
      " 21\n",
      "(COORD 22\n",
      "(CC 23\n",
      "10=et) 22\n",
      "(Sint 23\n",
      "(VN 24\n",
      "(CLS-SUJ 25\n",
      "11=c') 24\n",
      "(V 25\n",
      "12=est)) 23\n",
      "(AP-ATS 24\n",
      "(ADJ 25\n",
      "13=fatigant)) 23\n",
      " 23\n",
      "(PP-MOD 24\n",
      "(P 25\n",
      "15=pour) 24\n",
      "(NP 25\n",
      "(DET 26\n",
      "16=les) 25\n",
      "(NC 26\n",
      "17=enfants))) 23\n",
      " 23\n",
      "(PP-MOD 24\n",
      "(P 25\n",
      "19=de) 24\n",
      "(VPinf 25\n",
      "(ADV 26\n",
      "20=toujours) 25\n",
      "(COORD 26\n",
      "(CC 27\n",
      "21=et) 26\n",
      "(ADV 27\n",
      "22=toujours)) 25\n",
      "(VN 26\n",
      "(CLO-A_OBJ 27\n",
      "23=leur) 26\n",
      "(VINF 27\n",
      "24=donner)) 25\n",
      "(NP-OBJ 26\n",
      "(DET 27\n",
      "25=des) 26\n",
      "(NC 27\n",
      "26=explications)))))) 21\n",
      ")\n",
      "(SENT 22\n",
      "(VN 23\n",
      "(CLS-SUJ 24\n",
      "0=J') 23\n",
      "(V 24\n",
      "1=ai) 23\n",
      "(ADV 24\n",
      "2=donc) 23\n",
      "(VPP 24\n",
      "3=dû)) 22\n",
      "(VPinf-OBJ 23\n",
      "(VN 24\n",
      "(VINF 25\n",
      "4=choisir)) 23\n",
      "(NP-OBJ 24\n",
      "(DET 25\n",
      "5=un) 24\n",
      "(ADJ 25\n",
      "6=autre) 24\n",
      "(NC 25\n",
      "7=métier))) 22\n",
      "(COORD 23\n",
      "(CC 24\n",
      "8=et) 23\n",
      "(Sint 24\n",
      "(VN 25\n",
      "(CLS-SUJ 26\n",
      "9=j') 25\n",
      "(V 26\n",
      "10=ai) 25\n",
      "(VPP 26\n",
      "11=appris)) 24\n",
      "(PP-OBJ 25\n",
      "(P 26\n",
      "12=à) 25\n",
      "(VPinf 26\n",
      "(VN 27\n",
      "(VINF 28\n",
      "13=piloter)) 26\n",
      "(NP-OBJ 27\n",
      "(DET 28\n",
      "14=des) 27\n",
      "(NC 28\n",
      "15=avions)))))) 22\n",
      ")\n",
      "(SENT 23\n",
      "(VN 24\n",
      "(CLS-SUJ 25\n",
      "0=J') 24\n",
      "(V 25\n",
      "1=ai) 24\n",
      "(VPP 25\n",
      "2=volé)) 23\n",
      "(PP-MOD 24\n",
      "(AdP-MOD 25\n",
      "(ADV+ 26\n",
      "(DET 27\n",
      "3=un) 26\n",
      "(ADV 27\n",
      "4=peu)) 25\n",
      "(ADV 26\n",
      "5=partout)) 24\n",
      "(PP 25\n",
      "(P 26\n",
      "6=dans) 25\n",
      "(NP 26\n",
      "(DET 27\n",
      "7=le) 26\n",
      "(NC 27\n",
      "8=monde)))) 23\n",
      ")\n",
      "(SENT 24\n",
      "(COORD 25\n",
      "(CC 26\n",
      "0=Et) 25\n",
      "(Sint 26\n",
      "(NP-SUJ 27\n",
      "(DET 28\n",
      "1=la) 27\n",
      "(NC 28\n",
      "2=géographie)) 26\n",
      " 26\n",
      "(Sint-MOD 27\n",
      "(VN 28\n",
      "(CLS-SUJ 29\n",
      "4=c') 28\n",
      "(V 29\n",
      "5=est)) 27\n",
      "(AP-ATS 28\n",
      "(ADJ 29\n",
      "6=exact))) 26\n",
      " 26\n",
      "(VN 27\n",
      "(CLO-A_OBJ 28\n",
      "8=m') 27\n",
      "(V 28\n",
      "9=a) 27\n",
      "(ADV 28\n",
      "10=beaucoup) 27\n",
      "(VPP 28\n",
      "11=servi)))) 24\n",
      ")\n",
      "(SENT 25\n",
      "(VN 26\n",
      "(CLS-SUJ 27\n",
      "0=Je) 26\n",
      "(V 27\n",
      "1=savais)) 25\n",
      "(VPinf-OBJ 26\n",
      "(VN 27\n",
      "(VINF 28\n",
      "2=reconnaître)) 26\n",
      " 26\n",
      "(PP-MOD 27\n",
      "(P+D 28\n",
      "4=du) 27\n",
      "(NP 28\n",
      "(ADJ 29\n",
      "5=premier) 28\n",
      "(NC+ 29\n",
      "(NC 30\n",
      "6=coup) 29\n",
      "(P 30\n",
      "7=d') 29\n",
      "(NC 30\n",
      "8=oeil)))) 26\n",
      " 26\n",
      "(NP-OBJ 27\n",
      "(DET 28\n",
      "10=la) 27\n",
      "(NC 28\n",
      "11=chine) 27\n",
      "(PP 28\n",
      "(P 29\n",
      "12=de) 28\n",
      "(NP 29\n",
      "(DET 30\n",
      "13=l') 29\n",
      "(NPP 30\n",
      "14=arizona))))) 25\n",
      ")\n",
      "(SENT 26\n",
      "(VN 27\n",
      "(CLS-SUJ 28\n",
      "0=C') 27\n",
      "(V 28\n",
      "1=est)) 26\n",
      "(AP-ATS 27\n",
      "(ADV 28\n",
      "2=très) 27\n",
      "(ADJ 28\n",
      "3=utile)) 26\n",
      " 26\n",
      "(Ssub-MOD 27\n",
      "(CS 28\n",
      "5=si) 27\n",
      "(Sint 28\n",
      "(VN 29\n",
      "(CLS-SUJ 30\n",
      "6=l'on) 29\n",
      "(CLR 30\n",
      "7=s') 29\n",
      "(V 30\n",
      "8=est) 29\n",
      "(VPP 30\n",
      "9=égaré)) 28\n",
      "(PP-MOD 29\n",
      "(P 30\n",
      "10=pendant) 29\n",
      "(NP 30\n",
      "(DET 31\n",
      "11=la) 30\n",
      "(NC 31\n",
      "12=nuit))))) 26\n",
      ")\n",
      "(SENT 27\n",
      "(VN 28\n",
      "(CLS-SUJ 29\n",
      "0=J') 28\n",
      "(V 29\n",
      "1=ai) 28\n",
      "(ADV 29\n",
      "2=ainsi) 28\n",
      "(VPP 29\n",
      "3=eu)) 27\n",
      " 27\n",
      "(PP-MOD 28\n",
      "(P+ 29\n",
      "(P+D 30\n",
      "5=au) 29\n",
      "(NC 30\n",
      "6=cours) 29\n",
      "(P 30\n",
      "7=de)) 28\n",
      "(NP 29\n",
      "(DET 30\n",
      "8=ma) 29\n",
      "(NC 30\n",
      "9=vie))) 27\n",
      " 27\n",
      "(NP-OBJ 28\n",
      "(DET 29\n",
      "11=des) 28\n",
      "(NC 29\n",
      "12=tas) 28\n",
      "(PP 29\n",
      "(P 30\n",
      "13=de) 29\n",
      "(NP 30\n",
      "(NC 31\n",
      "14=contacts))) 28\n",
      "(PP 29\n",
      "(P 30\n",
      "15=avec) 29\n",
      "(NP 30\n",
      "(DET 31\n",
      "16=des) 30\n",
      "(NC 31\n",
      "17=tas) 30\n",
      "(PP 31\n",
      "(P 32\n",
      "18=de) 31\n",
      "(NP 32\n",
      "(NC 33\n",
      "19=gens) 32\n",
      "(AP 33\n",
      "(ADJ 34\n",
      "20=sérieux))))))) 27\n",
      ")\n",
      "(SENT 28\n",
      "(VN 29\n",
      "(CLS-SUJ 30\n",
      "0=J') 29\n",
      "(V 30\n",
      "1=ai) 29\n",
      "(ADV 30\n",
      "2=beaucoup) 29\n",
      "(VPP 30\n",
      "3=vécu)) 28\n",
      "(PP-P_OBJ 29\n",
      "(P 30\n",
      "4=chez) 29\n",
      "(NP 30\n",
      "(DET 31\n",
      "5=les) 30\n",
      "(ADJ 31\n",
      "6=grandes) 30\n",
      "(NC 31\n",
      "7=personnes))) 28\n",
      ")\n",
      "(SENT 29\n",
      "(VN 30\n",
      "(CLS-SUJ 31\n",
      "0=Je) 30\n",
      "(CLO-OBJ 31\n",
      "1=les) 30\n",
      "(V 31\n",
      "2=ai) 30\n",
      "(VPP 31\n",
      "3=vues)) 29\n",
      "(PP-MOD 30\n",
      "(P 31\n",
      "4=de) 30\n",
      "(AdP 31\n",
      "(ADV 32\n",
      "5=très) 31\n",
      "(ADV 32\n",
      "6=près))) 29\n",
      ")\n",
      "(SENT 30\n",
      "(NP-SUJ 31\n",
      "(PRO 32\n",
      "0=Ça)) 30\n",
      "(VN 31\n",
      "(ADV 32\n",
      "1=n') 31\n",
      "(V 32\n",
      "2=a) 31\n",
      "(AdP 32\n",
      "(ADV 33\n",
      "3=pas) 32\n",
      "(ADV 33\n",
      "4=trop)) 31\n",
      "(VPP 32\n",
      "5=amélioré)) 30\n",
      "(NP-OBJ 31\n",
      "(DET 32\n",
      "6=mon) 31\n",
      "(NC 32\n",
      "7=opinion)) 30\n",
      ")\n",
      "(SENT 31\n",
      "(Ssub-MOD 32\n",
      "(Ssub-MOD 33\n",
      "(CS 34\n",
      "0=Quand) 33\n",
      "(Sint 34\n",
      "(VN 35\n",
      "(CLS-SUJ 36\n",
      "1=j') 35\n",
      "(CLO-OBJ 36\n",
      "2=en) 35\n",
      "(V 36\n",
      "3=rencontrais)) 34\n",
      "(NP-OBJ 35\n",
      "(PRO 36\n",
      "4=une) 35\n",
      "(Srel 36\n",
      "(NP-SUJ 37\n",
      "(PROREL 38\n",
      "5=qui)) 36\n",
      "(VN 37\n",
      "(CLO-A_OBJ 38\n",
      "6=me) 37\n",
      "(V 38\n",
      "7=paraissait)) 36\n",
      "(AP-ATS 37\n",
      "(ADV+ 38\n",
      "(DET 39\n",
      "8=un) 38\n",
      "(ADV 39\n",
      "9=peu)) 37\n",
      "(ADJ 38\n",
      "10=lucide)))))) 32\n",
      ") 31\n",
      "(VN 32\n",
      "(CLS-SUJ 33\n",
      "12=je) 32\n",
      "(V 33\n",
      "13=faisais)) 31\n",
      "(NP-OBJ 32\n",
      "(DET 33\n",
      "14=l') 32\n",
      "(NC 33\n",
      "15=expérience) 32\n",
      "(PP 33\n",
      "(P 34\n",
      "16=sur) 33\n",
      "(NP 34\n",
      "(PRO 35\n",
      "17=elle))) 32\n",
      "(PP 33\n",
      "(P 34\n",
      "18=de) 33\n",
      "(NP 34\n",
      "(DET 35\n",
      "19=mon) 34\n",
      "(NC 35\n",
      "20=dessin) 34\n",
      "(NC+ 35\n",
      "(NC 36\n",
      "21=numéro) 35\n",
      "(ADJ 36\n",
      "22=1)) 34\n",
      "(Srel 35\n",
      "(NP-OBJ 36\n",
      "(PROREL 37\n",
      "23=que)) 35\n",
      "(VN 36\n",
      "(CLS-SUJ 37\n",
      "24=j') 36\n",
      "(V 37\n",
      "25=ai) 36\n",
      "(ADV 37\n",
      "26=toujours) 36\n",
      "(VPP 37\n",
      "27=conservé)))))) 31\n",
      "(Sint-MOD 32\n",
      "(VN 33\n",
      "(CLS-SUJ 34\n",
      "28=je) 33\n",
      "(V 34\n",
      "29=voulais)) 32\n",
      "(VPinf-OBJ 33\n",
      "(VN 34\n",
      "(VINF 35\n",
      "30=savoir)) 33\n",
      "(Ssub-OBJ 34\n",
      "(CS 35\n",
      "31=si) 34\n",
      "(Sint 35\n",
      "(VN 36\n",
      "(CLS-SUJ 37\n",
      "32=elle) 36\n",
      "(V 37\n",
      "33=était)) 35\n",
      "(ADV 36\n",
      "34=vraiment) 35\n",
      "(AP-ATS 36\n",
      "(ADJ 37\n",
      "35=compréhensive)))))) 31\n",
      ")\n",
      "(SENT 32\n",
      "(COORD 33\n",
      "(CC 34\n",
      "0=Mais) 33\n",
      "(Sint 34\n",
      "(ADV 35\n",
      "1=toujours) 34\n",
      "(VN 35\n",
      "(CLS-SUJ 36\n",
      "2=elle) 35\n",
      "(CLO-A_OBJ 36\n",
      "3=me) 35\n",
      "(V 36\n",
      "4=répondait)))) 32\n",
      ")\n",
      "(SENT 33\n",
      "(VN 34\n",
      "(CLS-SUJ 35\n",
      "0=c') 34\n",
      "(V 35\n",
      "1=est)) 33\n",
      "(NP-ATS 34\n",
      "(DET 35\n",
      "2=un) 34\n",
      "(NC 35\n",
      "3=chapeau)) 33\n",
      ")\n",
      "(SENT 34\n",
      "(ADV 35\n",
      "0=Alors) 34\n",
      "(VN 35\n",
      "(CLS-SUJ 36\n",
      "1=je) 35\n",
      "(ADV 36\n",
      "2=ne) 35\n",
      "(CLO-A_OBJ 36\n",
      "3=lui) 35\n",
      "(V 36\n",
      "4=parlais)) 34\n",
      "(COORD 35\n",
      "(CC 36\n",
      "5=ni) 35\n",
      "(PP 36\n",
      "(P 37\n",
      "6=de) 36\n",
      "(NP 37\n",
      "(NC 38\n",
      "7=serpents) 37\n",
      "(ADJ 38\n",
      "8=boas)))) 34\n",
      " 34\n",
      "(COORD 35\n",
      "(CC 36\n",
      "10=ni) 35\n",
      "(PP 36\n",
      "(P 37\n",
      "11=de) 36\n",
      "(NP 37\n",
      "(NC 38\n",
      "12=forêts) 37\n",
      "(AP 38\n",
      "(ADJ 39\n",
      "13=vierges))))) 34\n",
      " 34\n",
      "(COORD 35\n",
      "(CC 36\n",
      "15=ni) 35\n",
      "(PP 36\n",
      "(P 37\n",
      "16=d') 36\n",
      "(NP 37\n",
      "(NC 38\n",
      "17=étoiles)))) 34\n",
      ")\n",
      "(SENT 35\n",
      "(VN 36\n",
      "(CLS-SUJ 37\n",
      "0=Je) 36\n",
      "(CLR 37\n",
      "1=me) 36\n",
      "(V 37\n",
      "2=mettais)) 35\n",
      "(PP-P_OBJ 36\n",
      "(P 37\n",
      "3=à) 36\n",
      "(NP 37\n",
      "(DET 38\n",
      "4=sa) 37\n",
      "(NC 38\n",
      "5=portée))) 35\n",
      ")\n",
      "(SENT 36\n",
      "(VN 37\n",
      "(CLS-SUJ 38\n",
      "0=Je) 37\n",
      "(CLO-A_OBJ 38\n",
      "1=lui) 37\n",
      "(V 38\n",
      "2=parlais)) 36\n",
      "(PP-DE_OBJ 37\n",
      "(P 38\n",
      "3=de) 37\n",
      "(NP 38\n",
      "(NC 39\n",
      "4=bridge)) 37\n",
      "(COORD 38\n",
      " 38\n",
      "(PP 39\n",
      "(P 40\n",
      "6=de) 39\n",
      "(NP 40\n",
      "(NC 41\n",
      "7=golf)))) 37\n",
      "(COORD 38\n",
      " 38\n",
      "(PP 39\n",
      "(P 40\n",
      "9=de) 39\n",
      "(NP 40\n",
      "(NC 41\n",
      "10=politique)))) 37\n",
      "(COORD 38\n",
      "(CC 39\n",
      "11=et) 38\n",
      "(PP 39\n",
      "(P 40\n",
      "12=de) 39\n",
      "(NP 40\n",
      "(NC 41\n",
      "13=cravates))))) 36\n",
      ")\n",
      "(SENT 37\n",
      "(COORD 38\n",
      "(CC 39\n",
      "0=Et) 38\n",
      "(Sint 39\n",
      "(NP-SUJ 40\n",
      "(DET 41\n",
      "1=la) 40\n",
      "(ADJ 41\n",
      "2=grande) 40\n",
      "(NC 41\n",
      "3=personne)) 39\n",
      "(VN 40\n",
      "(V 41\n",
      "4=était)) 39\n",
      "(AP-ATS 40\n",
      "(ADV 41\n",
      "5=bien) 40\n",
      "(ADJ 41\n",
      "6=contente) 40\n",
      "(PP 41\n",
      "(P 42\n",
      "7=de) 41\n",
      "(VPinf 42\n",
      "(VN 43\n",
      "(VINF 44\n",
      "8=connaître)) 42\n",
      "(NP-OBJ 43\n",
      "(DET 44\n",
      "9=un) 43\n",
      "(NC 44\n",
      "10=homme) 43\n",
      "(AP 44\n",
      "(ADV 45\n",
      "11=aussi) 44\n",
      "(ADJ 45\n",
      "12=raisonnable)))))))) 37\n",
      ")\n",
      "(SENT 38\n",
      "(VN 39\n",
      "(CLS-SUJ 40\n",
      "0=J') 39\n",
      "(V 40\n",
      "1=ai) 39\n",
      "(ADV 40\n",
      "2=ainsi) 39\n",
      "(VPP 40\n",
      "3=vécu)) 38\n",
      "(AP-ATS 39\n",
      "(ADJ 40\n",
      "4=seul)) 38\n",
      " 38\n",
      "(PP-MOD 39\n",
      "(P 40\n",
      "6=sans) 39\n",
      "(NP 40\n",
      "(NC 41\n",
      "7=personne) 40\n",
      "(Srel 41\n",
      "(PP-MOD 42\n",
      "(P 43\n",
      "8=avec) 42\n",
      "(NP 43\n",
      "(PROREL 44\n",
      "9=qui))) 41\n",
      "(VN 42\n",
      "(VINF 43\n",
      "10=parler)) 41\n",
      "(ADV 42\n",
      "11=véritablement)))) 38\n",
      " 38\n",
      "(PP-MOD 39\n",
      "(P+ 40\n",
      "(P 41\n",
      "13=jusqu') 40\n",
      "(P 41\n",
      "14=à)) 39\n",
      "(NP 40\n",
      "(DET 41\n",
      "15=une) 40\n",
      "(NC 41\n",
      "16=panne))) 38\n",
      "(PP-MOD 39\n",
      "(P 40\n",
      "17=dans) 39\n",
      "(NP 40\n",
      "(DET 41\n",
      "18=le) 40\n",
      "(NC 41\n",
      "19=désert) 40\n",
      "(PP 41\n",
      "(P+D 42\n",
      "20=du) 41\n",
      "(NP 42\n",
      "(NPP 43\n",
      "21=sahara))))) 38\n",
      " 38\n",
      "(PP-MOD 39\n",
      "(P+ 40\n",
      "(CLS 41\n",
      "23=il) 40\n",
      "(CLO 41\n",
      "24=y) 40\n",
      "(V 41\n",
      "25=a)) 39\n",
      "(NP 40\n",
      "(DET 41\n",
      "26=six) 40\n",
      "(NC 41\n",
      "27=ans))) 38\n",
      ")\n",
      "(SENT 39\n",
      "(NP-SUJ 40\n",
      "(DET 41\n",
      "0=Quelque) 40\n",
      "(NC 41\n",
      "1=chose)) 39\n",
      "(VN 40\n",
      "(CLR 41\n",
      "2=s') 40\n",
      "(V 41\n",
      "3=était) 40\n",
      "(VPP 41\n",
      "4=cassé)) 39\n",
      "(PP-MOD 40\n",
      "(P 41\n",
      "5=dans) 40\n",
      "(NP 41\n",
      "(DET 42\n",
      "6=mon) 41\n",
      "(NC 42\n",
      "7=moteur))) 39\n",
      ")\n",
      "(SENT 40\n",
      "(COORD 41\n",
      "(CC 42\n",
      "0=Et) 41\n",
      "(Sint 42\n",
      "(Ssub-MOD 43\n",
      "(CS 44\n",
      "1=comme) 43\n",
      "(Sint 44\n",
      "(VN 45\n",
      "(CLS-SUJ 46\n",
      "2=je) 45\n",
      "(ADV 46\n",
      "3=n') 45\n",
      "(V 46\n",
      "4=avais)) 44\n",
      "(PP-MOD 45\n",
      "(P 46\n",
      "5=avec) 45\n",
      "(NP 46\n",
      "(PRO 47\n",
      "6=moi))) 44\n",
      "(COORD 45\n",
      "(CC 46\n",
      "7=ni) 45\n",
      "(NP 46\n",
      "(NC 47\n",
      "8=mécanicien))) 44\n",
      " 44\n",
      "(COORD 45\n",
      "(CC 46\n",
      "10=ni) 45\n",
      "(NP 46\n",
      "(NC 47\n",
      "11=passagers))))) 42\n",
      " 42\n",
      "(VN 43\n",
      "(CLS-SUJ 44\n",
      "13=je) 43\n",
      "(CLR 44\n",
      "14=me) 43\n",
      "(V 44\n",
      "15=préparai)) 42\n",
      "(PP-A_OBJ 43\n",
      "(P 44\n",
      "16=à) 43\n",
      "(VPinf 44\n",
      "(VN 45\n",
      "(VINF 46\n",
      "17=essayer)) 44\n",
      "(PP-DE_OBJ 45\n",
      "(P 46\n",
      "18=de) 45\n",
      "(VPinf 46\n",
      "(VN 47\n",
      "(VINF 48\n",
      "19=réussir)) 46\n",
      " 46\n",
      "(AP-MOD 47\n",
      "(ADV 48\n",
      "21=tout) 47\n",
      "(ADJ 48\n",
      "22=seul)) 46\n",
      " 46\n",
      "(NP-OBJ 47\n",
      "(DET 48\n",
      "24=une) 47\n",
      "(NC 48\n",
      "25=réparation) 47\n",
      "(AP 48\n",
      "(ADJ 49\n",
      "26=difficile))))))))) 40\n",
      ")\n",
      "(SENT 41\n",
      "(VN 42\n",
      "(CLS-SUJ 43\n",
      "0=C') 42\n",
      "(V 43\n",
      "1=était)) 41\n",
      "(PP-MOD 42\n",
      "(P 43\n",
      "2=pour) 42\n",
      "(NP 43\n",
      "(PRO 44\n",
      "3=moi))) 41\n",
      "(NP-ATS 42\n",
      "(DET 43\n",
      "4=une) 42\n",
      "(NC 43\n",
      "5=question) 42\n",
      "(PP 43\n",
      "(P 44\n",
      "6=de) 43\n",
      "(NP 44\n",
      "(NC 45\n",
      "7=vie)) 43\n",
      "(COORD 44\n",
      "(CC 45\n",
      "8=ou) 44\n",
      "(PP 45\n",
      "(P 46\n",
      "9=de) 45\n",
      "(NP 46\n",
      "(NC 47\n",
      "10=mort)))))) 41\n",
      ")\n",
      "(SENT 42\n",
      "(VN 43\n",
      "(CLS-SUJ 44\n",
      "0=J') 43\n",
      "(V 44\n",
      "1=avais)) 42\n",
      "(ADV+ 43\n",
      "(P 44\n",
      "2=à) 43\n",
      "(NC 44\n",
      "3=peine)) 42\n",
      "(NP-OBJ 43\n",
      "(DET+ 44\n",
      "(P 45\n",
      "4=de) 44\n",
      "(DET 45\n",
      "5=l')) 43\n",
      "(NC 44\n",
      "6=eau) 43\n",
      "(PP 44\n",
      "(P 45\n",
      "7=à) 44\n",
      "(VPinf 45\n",
      "(VN 46\n",
      "(VINF 47\n",
      "8=boire))))) 42\n",
      "(PP-MOD 43\n",
      "(P 44\n",
      "9=pour) 43\n",
      "(NP 44\n",
      "(DET 45\n",
      "10=huit) 44\n",
      "(NC 45\n",
      "11=jours))) 42\n",
      ")\n",
      "(SENT 43\n",
      "(NP-MOD 44\n",
      "(DET 45\n",
      "0=Le) 44\n",
      "(ADJ 45\n",
      "1=premier) 44\n",
      "(NC 45\n",
      "2=soir)) 43\n",
      "(VN 44\n",
      "(CLS-SUJ 45\n",
      "3=je) 44\n",
      "(CLR 45\n",
      "4=me) 44\n",
      "(V 45\n",
      "5=suis) 44\n",
      "(ADV 45\n",
      "6=donc) 44\n",
      "(VPP 45\n",
      "7=endormi)) 43\n",
      "(PP-MOD 44\n",
      "(P 45\n",
      "8=sur) 44\n",
      "(NP 45\n",
      "(DET 46\n",
      "9=le) 45\n",
      "(NC 46\n",
      "10=sable))) 43\n",
      "(PP-MOD 44\n",
      "(P 45\n",
      "11=à) 44\n",
      "(NP 45\n",
      "(DET 46\n",
      "12=mille) 45\n",
      "(NC 46\n",
      "13=milles) 45\n",
      "(PP 46\n",
      "(P 47\n",
      "14=de) 46\n",
      "(NP 47\n",
      "(DET 48\n",
      "15=toute) 47\n",
      "(NC 48\n",
      "16=terre) 47\n",
      "(VPpart 48\n",
      "(VPP 49\n",
      "17=habitée)))))) 43\n",
      ")\n",
      "(SENT 44\n",
      "(VN 45\n",
      "(CLS-SUJ 46\n",
      "0=J') 45\n",
      "(V 46\n",
      "1=étais)) 44\n",
      "(AP-ATS 45\n",
      "(AdP 46\n",
      "(ADV 47\n",
      "2=bien) 46\n",
      "(ADV 47\n",
      "3=plus)) 45\n",
      "(VPP 46\n",
      "4=isolé) 45\n",
      "(Ssub 46\n",
      "(CS 47\n",
      "5=qu') 46\n",
      "(NP 47\n",
      "(DET 48\n",
      "6=un) 47\n",
      "(NC 48\n",
      "7=naufragé)) 46\n",
      "(PP 47\n",
      "(P 48\n",
      "8=sur) 47\n",
      "(NP 48\n",
      "(DET 49\n",
      "9=un) 48\n",
      "(NC 49\n",
      "10=radeau))) 46\n",
      "(PP 47\n",
      "(P+ 48\n",
      "(P+D 49\n",
      "11=au) 48\n",
      "(NC 49\n",
      "12=milieu) 48\n",
      "(P 49\n",
      "13=de)) 47\n",
      "(NP 48\n",
      "(DET 49\n",
      "14=l') 48\n",
      "(NC 49\n",
      "15=océan))))) 44\n",
      ")\n",
      "(SENT 45\n",
      "(ADV 46\n",
      "0=Alors) 45\n",
      "(VN 46\n",
      "(CLS-SUJ 47\n",
      "1=vous) 46\n",
      "(V 47\n",
      "2=imaginez)) 45\n",
      "(NP-OBJ 46\n",
      "(DET 47\n",
      "3=ma) 46\n",
      "(NC 47\n",
      "4=surprise)) 45\n",
      " 45\n",
      "(PP-MOD 46\n",
      "(P+D 47\n",
      "6=au) 46\n",
      "(NP 47\n",
      "(NC+ 48\n",
      "(NC 49\n",
      "7=lever) 48\n",
      "(P+D 49\n",
      "8=du) 48\n",
      "(NC 49\n",
      "9=jour)))) 45\n",
      " 45\n",
      "(Ssub-MOD 46\n",
      "(CS 47\n",
      "11=quand) 46\n",
      "(Sint 47\n",
      "(NP-SUJ 48\n",
      "(DET 49\n",
      "12=une) 48\n",
      "(ADJ 49\n",
      "13=drôle) 48\n",
      "(P 49\n",
      "14=de) 48\n",
      "(ADJ 49\n",
      "15=petite) 48\n",
      "(NC 49\n",
      "16=voix)) 47\n",
      "(VN 48\n",
      "(CLO-OBJ 49\n",
      "17=m') 48\n",
      "(V 49\n",
      "18=a) 48\n",
      "(VPP 49\n",
      "19=réveillé)))) 45\n",
      ")\n",
      "(SENT 46\n",
      "(VN 47\n",
      "(CLS-SUJ 48\n",
      "0=Elle) 47\n",
      "(V 48\n",
      "1=disait)) 46\n",
      ")\n",
      "(SENT 47\n",
      "(Ssub 48\n",
      "(CS 49\n",
      "0=s') 48\n",
      "(Sint 49\n",
      "(VN 50\n",
      "(CLS-SUJ 51\n",
      "1=il) 50\n",
      "(CLO 51\n",
      "2=vous) 50\n",
      "(V 51\n",
      "3=plaît)))) 47\n",
      ")\n",
      "(SENT 48\n",
      "(VN 49\n",
      "(VIMP 50\n",
      "0=Dessine) 49\n",
      "(CLO-A_OBJ 50\n",
      "1=moi)) 48\n",
      "(NP-OBJ 49\n",
      "(DET 50\n",
      "2=un) 49\n",
      "(NC 50\n",
      "3=mouton)) 48\n",
      ")\n",
      "(SENT 49\n",
      "(I 50\n",
      "0=hein) 49\n",
      ")\n",
      "(SENT 50\n",
      "(VN 51\n",
      "(VIMP 52\n",
      "0=dessine) 51\n",
      "(CLO-A_OBJ 52\n",
      "1=moi)) 50\n",
      "(NP-OBJ 51\n",
      "(DET 52\n",
      "2=un) 51\n",
      "(NC 52\n",
      "3=mouton)) 50\n",
      ")\n",
      "(SENT 51\n",
      "(VN 52\n",
      "(CLS-SUJ 53\n",
      "0=J') 52\n",
      "(V 53\n",
      "1=ai) 52\n",
      "(VPP 53\n",
      "2=sauté)) 51\n",
      "(PP-P_OBJ 52\n",
      "(P 53\n",
      "3=sur) 52\n",
      "(NP 53\n",
      "(DET 54\n",
      "4=mes) 53\n",
      "(NC 54\n",
      "5=pieds))) 51\n",
      "(Ssub-MOD 52\n",
      "(CS+ 53\n",
      "(ADV 54\n",
      "6=comme) 53\n",
      "(CS 54\n",
      "7=si)) 52\n",
      "(Sint 53\n",
      "(VN 54\n",
      "(CLS-SUJ 55\n",
      "8=j') 54\n",
      "(V 55\n",
      "9=avais) 54\n",
      "(VPP 55\n",
      "10=été) 54\n",
      "(VPP 55\n",
      "11=frappé)) 53\n",
      "(PP-P_OBJ.AGT 54\n",
      "(P 55\n",
      "12=par) 54\n",
      "(NP 55\n",
      "(DET 56\n",
      "13=la) 55\n",
      "(NC 56\n",
      "14=foudre))))) 51\n",
      ")\n",
      "(SENT 52\n",
      "(VN 53\n",
      "(CLS-SUJ 54\n",
      "0=J') 53\n",
      "(V 54\n",
      "1=ai) 53\n",
      "(ADV 54\n",
      "2=bien) 53\n",
      "(VPP 54\n",
      "3=frotté)) 52\n",
      "(NP-OBJ 53\n",
      "(DET 54\n",
      "4=mes) 53\n",
      "(NC 54\n",
      "5=yeux)) 52\n",
      ")\n",
      "(SENT 53\n",
      "(VN 54\n",
      "(CLS-SUJ 55\n",
      "0=J') 54\n",
      "(V 55\n",
      "1=ai) 54\n",
      "(ADV 55\n",
      "2=bien) 54\n",
      "(VPP 55\n",
      "3=regardé)) 53\n",
      ")\n",
      "(SENT 54\n",
      "(COORD 55\n",
      "(CC 56\n",
      "0=Et) 55\n",
      "(Sint 56\n",
      "(VN 57\n",
      "(CLS-SUJ 58\n",
      "1=j') 57\n",
      "(V 58\n",
      "2=ai) 57\n",
      "(VPP 58\n",
      "3=vu)) 56\n",
      "(NP-OBJ 57\n",
      "(DET 58\n",
      "4=un) 57\n",
      "(ADJ 58\n",
      "5=petit) 57\n",
      "(NC 58\n",
      "6=bonhomme) 57\n",
      "(AP 58\n",
      "(ADV+ 59\n",
      "(ADV 60\n",
      "7=tout) 59\n",
      "(P 60\n",
      "8=à) 59\n",
      "(NC 60\n",
      "9=fait)) 58\n",
      "(ADJ 59\n",
      "10=extraordinaire)) 57\n",
      "(Srel 58\n",
      "(NP-SUJ 59\n",
      "(PROREL 60\n",
      "11=qui)) 58\n",
      "(VN 59\n",
      "(CLO-OBJ 60\n",
      "12=me) 59\n",
      "(V 60\n",
      "13=considérait)) 58\n",
      "(ADV 59\n",
      "14=gravement))))) 54\n",
      ")\n",
      "(SENT 55\n",
      "(VN 56\n",
      "(V 57\n",
      "0=Voilà)) 55\n",
      "(NP-OBJ 56\n",
      "(DET 57\n",
      "1=le) 56\n",
      "(ADJ 57\n",
      "2=meilleur) 56\n",
      "(NC 57\n",
      "3=portrait) 56\n",
      "(Srel 57\n",
      "(PP-A_OBJ 58\n",
      "(VPinf 59\n",
      "(NP-OBJ 60\n",
      "(PROREL 61\n",
      "4=que)) 59\n",
      "(VN 60\n",
      "(VINF 61\n",
      "13=faire)) 59\n",
      "(PP-DE_OBJ 60\n",
      "(P 61\n",
      "14=de) 60\n",
      "(NP 61\n",
      "(PRO 62\n",
      "15=lui)))) 58\n",
      "(P 59\n",
      "12=à)) 57\n",
      " 57\n",
      "(ADV+ 58\n",
      "(ADV 59\n",
      "6=plus) 58\n",
      "(ADV 59\n",
      "7=tard)) 57\n",
      " 57\n",
      "(VN 58\n",
      "(CLS-SUJ 59\n",
      "9=j') 58\n",
      "(V 59\n",
      "10=ai) 58\n",
      "(VPP 59\n",
      "11=réussi)))) 55\n",
      ")\n",
      "(SENT 56\n",
      "(COORD 57\n",
      "(CC 58\n",
      "0=Mais) 57\n",
      "(Sint 58\n",
      "(NP-SUJ 59\n",
      "(DET 60\n",
      "1=mon) 59\n",
      "(NC 60\n",
      "2=dessin)) 58\n",
      " 58\n",
      "(ADV+ 59\n",
      "(ADV 60\n",
      "4=bien) 59\n",
      "(ADJ 60\n",
      "5=sûr)) 58\n",
      " 58\n",
      "(VN 59\n",
      "(V 60\n",
      "7=est)) 58\n",
      "(AP-ATS 59\n",
      "(AdP 60\n",
      "(ADV 61\n",
      "8=beaucoup) 60\n",
      "(ADV 61\n",
      "9=moins)) 59\n",
      "(ADJ 60\n",
      "10=ravissant) 59\n",
      "(Ssub 60\n",
      "(CS 61\n",
      "11=que) 60\n",
      "(NP 61\n",
      "(DET 62\n",
      "12=le) 61\n",
      "(NC 62\n",
      "13=modèle)))))) 56\n",
      ")\n",
      "(SENT 57\n",
      "(VN 58\n",
      "(CLS-SUJ 59\n",
      "0=Ce) 58\n",
      "(ADV 59\n",
      "1=n') 58\n",
      "(V 59\n",
      "2=est)) 57\n",
      "(ADV 58\n",
      "3=pas) 57\n",
      "(NP-ATS 58\n",
      "(DET 59\n",
      "4=ma) 58\n",
      "(NC 59\n",
      "5=faute)) 57\n",
      ")\n",
      "(SENT 58\n",
      "(VN 59\n",
      "(CLS-SUJ 60\n",
      "0=J') 59\n",
      "(V 60\n",
      "1=avais) 59\n",
      "(VPP 60\n",
      "2=été) 59\n",
      "(VPP 60\n",
      "3=découragé)) 58\n",
      "(PP-MOD 59\n",
      "(P 60\n",
      "4=dans) 59\n",
      "(NP 60\n",
      "(DET 61\n",
      "5=ma) 60\n",
      "(NC 61\n",
      "6=carrière) 60\n",
      "(PP 61\n",
      "(P 62\n",
      "7=de) 61\n",
      "(NP 62\n",
      "(NC 63\n",
      "8=peintre))))) 58\n",
      "(PP-P_OBJ 59\n",
      "(P 60\n",
      "9=par) 59\n",
      "(NP 60\n",
      "(DET 61\n",
      "10=les) 60\n",
      "(ADJ 61\n",
      "11=grandes) 60\n",
      "(NC 61\n",
      "12=personnes))) 58\n",
      " 58\n",
      "(PP-MOD 59\n",
      "(P 60\n",
      "14=à) 59\n",
      "(NP 60\n",
      "(DET 61\n",
      "15=l') 60\n",
      "(NC 61\n",
      "16=âge) 60\n",
      "(PP 61\n",
      "(P 62\n",
      "17=de) 61\n",
      "(NP 62\n",
      "(DET 63\n",
      "18=six) 62\n",
      "(NC 63\n",
      "19=ans))))) 58\n",
      " 58\n",
      "(COORD 59\n",
      "(CC 60\n",
      "21=et) 59\n",
      "(Sint 60\n",
      "(VN 61\n",
      "(CLS-SUJ 62\n",
      "22=je) 61\n",
      "(ADV 62\n",
      "23=n') 61\n",
      "(V 62\n",
      "24=avais) 61\n",
      "(NP-OBJ 62\n",
      "(PRO 63\n",
      "25=rien)) 61\n",
      "(VPP 62\n",
      "26=appris)) 60\n",
      "(PP-A_OBJ 61\n",
      "(P 62\n",
      "27=à) 61\n",
      "(VPinf 62\n",
      "(VN 63\n",
      "(VINF 64\n",
      "28=dessiner)))) 60\n",
      " 60\n",
      "(PP-MOD 61\n",
      "(P 62\n",
      "30=sauf) 61\n",
      "(NP 62\n",
      "(DET 63\n",
      "31=les) 62\n",
      "(NC 63\n",
      "32=boas) 62\n",
      "(AP 63\n",
      "(ADJ 64\n",
      "33=fermés)) 62\n",
      "(COORD 63\n",
      "(CC 64\n",
      "34=et) 63\n",
      "(NP 64\n",
      "(DET 65\n",
      "35=les) 64\n",
      "(NC 65\n",
      "36=boas) 64\n",
      "(AP 65\n",
      "(ADJ 66\n",
      "37=ouverts)))))))) 58\n",
      ")\n",
      "(SENT 59\n",
      "(VN 60\n",
      "(CLS-SUJ 61\n",
      "0=Je) 60\n",
      "(V 61\n",
      "1=regardai)) 59\n",
      "(ADV 60\n",
      "2=donc) 59\n",
      "(NP-OBJ 60\n",
      "(DET 61\n",
      "3=cette) 60\n",
      "(NC 61\n",
      "4=apparition)) 59\n",
      "(PP-MOD 60\n",
      "(P 61\n",
      "5=avec) 60\n",
      "(NP 61\n",
      "(DET 62\n",
      "6=des) 61\n",
      "(NC 62\n",
      "7=yeux) 61\n",
      "(AP 62\n",
      "(ADV 63\n",
      "8=tout) 62\n",
      "(ADJ 63\n",
      "9=ronds) 62\n",
      "(PP 63\n",
      "(P 64\n",
      "10=d') 63\n",
      "(NP 64\n",
      "(NC 65\n",
      "11=étonnement)))))) 59\n",
      ")\n",
      "(SENT 60\n",
      "(VN 61\n",
      "(ADV 62\n",
      "0=N') 61\n",
      "(VIMP 62\n",
      "1=oubliez)) 60\n",
      "(ADV 61\n",
      "2=pas) 60\n",
      "(Ssub-OBJ 61\n",
      "(CS 62\n",
      "3=que) 61\n",
      "(Sint 62\n",
      "(VN 63\n",
      "(CLS-SUJ 64\n",
      "4=je) 63\n",
      "(CLR 64\n",
      "5=me) 63\n",
      "(V 64\n",
      "6=trouvais)) 62\n",
      "(PP-P_OBJ.O 63\n",
      "(P 64\n",
      "7=à) 63\n",
      "(NP 64\n",
      "(DET 65\n",
      "8=mille) 64\n",
      "(NC 65\n",
      "9=milles) 64\n",
      "(PP 65\n",
      "(P 66\n",
      "10=de) 65\n",
      "(NP 66\n",
      "(DET 67\n",
      "11=toute) 66\n",
      "(NC 67\n",
      "12=région) 66\n",
      "(VPpart 67\n",
      "(VPP 68\n",
      "13=habitée)))))))) 60\n",
      ")\n",
      "(SENT 61\n",
      "(COORD 62\n",
      "(CC 63\n",
      "0=Or) 62\n",
      "(Sint 63\n",
      "(NP-SUJ 64\n",
      "(DET 65\n",
      "1=mon) 64\n",
      "(ADJ 65\n",
      "2=petit) 64\n",
      "(NC 65\n",
      "3=bonhomme)) 63\n",
      "(VN 64\n",
      "(ADV 65\n",
      "4=ne) 64\n",
      "(CLO-A_OBJ 65\n",
      "5=me) 64\n",
      "(V 65\n",
      "6=semblait)) 63\n",
      "(COORD-OBJ 64\n",
      "(CC 65\n",
      "7=ni) 64\n",
      "(AP 65\n",
      "(ADJ 66\n",
      "8=égaré))) 63\n",
      " 63\n",
      "(COORD 64\n",
      "(CC 65\n",
      "10=ni) 64\n",
      "(VPpart 65\n",
      "(VPP 66\n",
      "11=mort) 65\n",
      "(PP-DE_OBJ 66\n",
      "(P 67\n",
      "12=de) 66\n",
      "(NP 67\n",
      "(NC 68\n",
      "13=fatigue))))) 63\n",
      " 63\n",
      "(COORD 64\n",
      "(CC 65\n",
      "15=ni) 64\n",
      "(VPpart 65\n",
      "(VPP 66\n",
      "16=mort) 65\n",
      "(PP-DE_OBJ 66\n",
      "(P 67\n",
      "17=de) 66\n",
      "(NP 67\n",
      "(NC 68\n",
      "18=faim))))) 63\n",
      " 63\n",
      "(COORD 64\n",
      "(CC 65\n",
      "20=ni) 64\n",
      "(VPpart 65\n",
      "(VPP 66\n",
      "21=mort) 65\n",
      "(PP-DE_OBJ 66\n",
      "(P 67\n",
      "22=de) 66\n",
      "(NP 67\n",
      "(NC 68\n",
      "23=soif))))) 63\n",
      " 63\n",
      "(COORD-MOD 64\n",
      "(CC 65\n",
      "25=ni) 64\n",
      "(VPpart 65\n",
      "(VPP 66\n",
      "26=mort) 65\n",
      "(PP-DE_OBJ 66\n",
      "(P 67\n",
      "27=de) 66\n",
      "(NP 67\n",
      "(NC 68\n",
      "28=peur))))))) 61\n",
      ")\n",
      "(SENT 62\n",
      "(VN 63\n",
      "(CLS-SUJ 64\n",
      "0=Il) 63\n",
      "(ADV 64\n",
      "1=n') 63\n",
      "(V 64\n",
      "2=avait)) 62\n",
      "(PP-MOD 63\n",
      "(P 64\n",
      "3=en) 63\n",
      "(PRO 64\n",
      "4=rien)) 62\n",
      "(NP-OBJ 63\n",
      "(DET 64\n",
      "5=l') 63\n",
      "(NC 64\n",
      "6=apparence) 63\n",
      "(PP 64\n",
      "(P 65\n",
      "7=d') 64\n",
      "(NP 65\n",
      "(DET 66\n",
      "8=un) 65\n",
      "(NC 66\n",
      "9=enfant) 65\n",
      "(VPpart 66\n",
      "(VPP 67\n",
      "10=perdu) 66\n",
      "(PP 67\n",
      "(P+D+ 68\n",
      "(P+D 69\n",
      "11=au) 68\n",
      "(NC 69\n",
      "12=milieu) 68\n",
      "(P+D 69\n",
      "13=du)) 67\n",
      "(NP 68\n",
      "(NC 69\n",
      "14=désert))) 66\n",
      " 66\n",
      "(PP 67\n",
      "(P 68\n",
      "16=à) 67\n",
      "(NP 68\n",
      "(DET 69\n",
      "17=mille) 68\n",
      "(NC 69\n",
      "18=milles) 68\n",
      "(PP 69\n",
      "(P 70\n",
      "19=de) 69\n",
      "(NP 70\n",
      "(DET 71\n",
      "20=toute) 70\n",
      "(NC 71\n",
      "21=région) 70\n",
      "(VPpart 71\n",
      "(VPP 72\n",
      "22=habitée)))))))))) 62\n",
      ")\n",
      "(SENT 63\n",
      "(Ssub-MOD 64\n",
      "(Ssub-MOD 65\n",
      "(CS 66\n",
      "0=Quand) 65\n",
      "(Sint 66\n",
      "(VN 67\n",
      "(CLS-SUJ 68\n",
      "1=je) 67\n",
      "(V 68\n",
      "2=réussis)) 66\n",
      "(ADV 67\n",
      "3=enfin) 66\n",
      "(PP-A_OBJ 67\n",
      "(P 68\n",
      "4=à) 67\n",
      "(VPinf 68\n",
      "(VN 69\n",
      "(VINF 70\n",
      "5=parler)))))) 64\n",
      ") 63\n",
      "(VN 64\n",
      "(CLS-SUJ 65\n",
      "7=je) 64\n",
      "(CLO-A_OBJ 65\n",
      "8=lui) 64\n",
      "(V 65\n",
      "9=dis)) 63\n",
      ")\n",
      "(SENT 64\n",
      "(COORD 65\n",
      "(COORD 66\n",
      "(CC 67\n",
      "0=mais)) 65\n",
      "))\n",
      "(SENT 66\n",
      "(NP-ATS 67\n",
      "(PROWH 68\n",
      "0=Qu')) 66\n",
      "(VN 67\n",
      "(V 68\n",
      "1=est) 67\n",
      "(CLS-SUJ 68\n",
      "2=ce)) 66\n",
      "(Srel-MOD.CLEFT 67\n",
      "(NP-OBJ 68\n",
      "(PROREL 69\n",
      "3=que)) 67\n",
      "(VN 68\n",
      "(CLS-SUJ 69\n",
      "4=tu) 68\n",
      "(V 69\n",
      "5=fais)) 67\n",
      "(ADV-MOD 68\n",
      "6=là)) 66\n",
      ")\n",
      "(SENT 67\n",
      "(CC 68\n",
      "0=Et) 67\n",
      "(Sint 68\n",
      "(VN 69\n",
      "(CLS-SUJ 70\n",
      "1=il) 69\n",
      "(CLO-A_OBJ 70\n",
      "2=me) 69\n",
      "(V 70\n",
      "3=répéta)) 68\n",
      "(ADV 69\n",
      "4=alors) 68\n",
      " 68\n",
      "(AdP-MOD 69\n",
      "(ADV 70\n",
      "6=tout) 69\n",
      "(ADV 70\n",
      "7=doucement)) 68\n",
      " 68\n",
      "(PP-MOD 69\n",
      "(P 70\n",
      "9=comme) 69\n",
      "(NP 70\n",
      "(DET 71\n",
      "10=une) 70\n",
      "(NC 71\n",
      "11=chose) 70\n",
      "(AP 71\n",
      "(ADV 72\n",
      "12=très) 71\n",
      "(ADJ 72\n",
      "13=sérieuse))))) 67\n",
      ")\n",
      "(SENT 68\n",
      "(Ssub 69\n",
      "(CS 70\n",
      "0=s') 69\n",
      "(Sint 70\n",
      "(VN 71\n",
      "(CLS-SUJ 72\n",
      "1=il) 71\n",
      "(CLO 72\n",
      "2=vous) 71\n",
      "(V 72\n",
      "3=plaît)))) 68\n",
      ")\n",
      "(SENT 69\n",
      "(VN 70\n",
      "(VIMP 71\n",
      "0=Dessine) 70\n",
      "(CLO-A_OBJ 71\n",
      "1=moi)) 69\n",
      "(NP-OBJ 70\n",
      "(DET 71\n",
      "2=un) 70\n",
      "(NC 71\n",
      "3=mouton)) 69\n",
      ")\n",
      "(SENT 70\n",
      "(Ssub-MOD 71\n",
      "(CS 72\n",
      "0=Quand) 71\n",
      "(Sint 72\n",
      "(NP-SUJ 73\n",
      "(DET 74\n",
      "1=le) 73\n",
      "(NC 74\n",
      "2=mystère)) 72\n",
      "(VN 73\n",
      "(V 74\n",
      "3=est)) 72\n",
      "(AP-ATS 73\n",
      "(ADV 74\n",
      "4=trop) 73\n",
      "(ADJ 74\n",
      "5=impressionnant)))) 70\n",
      " 70\n",
      "(VN 71\n",
      "(CLS-SUJ 72\n",
      "7=on) 71\n",
      "(ADV 72\n",
      "8=n') 71\n",
      "(V 72\n",
      "9=ose)) 70\n",
      "(ADV 71\n",
      "10=pas) 70\n",
      "(VPinf-OBJ 71\n",
      "(VN 72\n",
      "(VINF 73\n",
      "11=désobéir))) 70\n",
      ")\n",
      "(SENT 71\n",
      "(AP-MOD 72\n",
      "(ADV 73\n",
      "0=Aussi) 72\n",
      "(ADJ 73\n",
      "1=absurde) 72\n",
      "(Ssub 73\n",
      "(CS 74\n",
      "2=que) 73\n",
      "(Sint 74\n",
      "(NP-SUJ 75\n",
      "(PRO 76\n",
      "3=cela)) 74\n",
      "(VN 75\n",
      "(CLO-A_OBJ 76\n",
      "4=me) 75\n",
      "(V 76\n",
      "5=semblât)) 74\n",
      "(PP-ATS 75\n",
      "(P 76\n",
      "6=à) 75\n",
      "(NP 76\n",
      "(DET 77\n",
      "7=mille) 76\n",
      "(NC 77\n",
      "8=milles) 76\n",
      "(PP 77\n",
      "(P 78\n",
      "9=de) 77\n",
      "(NP 78\n",
      "(ADJ 79\n",
      "10=tous) 78\n",
      "(DET 79\n",
      "11=les) 78\n",
      "(NC 79\n",
      "12=endroits) 78\n",
      "(AP 79\n",
      "(ADJ 80\n",
      "13=habités))))) 75\n",
      "(COORD 76\n",
      "(CC 77\n",
      "14=et) 76\n",
      "(PP 77\n",
      "(P 78\n",
      "15=en) 77\n",
      "(NP 78\n",
      "(NC 79\n",
      "16=danger) 78\n",
      "(PP 79\n",
      "(P 80\n",
      "17=de) 79\n",
      "(NP 80\n",
      "(NC 81\n",
      "18=mort)))))))))) 71\n",
      " 71\n",
      "(VN 72\n",
      "(CLS-SUJ 73\n",
      "20=je) 72\n",
      "(V 73\n",
      "21=sortis)) 71\n",
      "(PP-DE_OBJ 72\n",
      "(P 73\n",
      "22=de) 72\n",
      "(NP 73\n",
      "(DET 74\n",
      "23=ma) 73\n",
      "(NC 74\n",
      "24=poche))) 71\n",
      "(NP-OBJ 72\n",
      "(DET 73\n",
      "25=une) 72\n",
      "(NC 73\n",
      "26=feuille) 72\n",
      "(PP 73\n",
      "(P 74\n",
      "27=de) 73\n",
      "(NP 74\n",
      "(NC 75\n",
      "28=papier))) 72\n",
      "(COORD 73\n",
      "(CC 74\n",
      "29=et) 73\n",
      "(NP 74\n",
      "(DET 75\n",
      "30=un) 74\n",
      "(NC 75\n",
      "31=stylographe)))) 71\n",
      ")\n",
      "(SENT 72\n",
      "(COORD 73\n",
      "(COORD 74\n",
      "(CC 75\n",
      "0=Mais) 74\n",
      "(Sint 75\n",
      "(VN 76\n",
      "(CLS-SUJ 77\n",
      "1=je) 76\n",
      "(CLR 77\n",
      "2=me) 76\n",
      "(V 77\n",
      "3=rappelai)) 75\n",
      "(ADV 76\n",
      "4=alors) 75\n",
      "(Ssub-OBJ 76\n",
      "(CS 77\n",
      "5=que) 76\n",
      "(Sint 77\n",
      "(VN 78\n",
      "(CLS-SUJ 79\n",
      "6=j') 78\n",
      "(V 79\n",
      "7=avais) 78\n",
      "(ADV 79\n",
      "8=surtout) 78\n",
      "(VPP 79\n",
      "9=étudié)) 77\n",
      "(NP-OBJ 78\n",
      "(DET 79\n",
      "10=la) 78\n",
      "(NC 79\n",
      "11=géographie) 78\n",
      "(COORD 79\n",
      " 79\n",
      "(NP 80\n",
      "(DET 81\n",
      "13=l') 80\n",
      "(NC 81\n",
      "14=histoire))) 78\n",
      "(COORD 79\n",
      " 79\n",
      "(NP 80\n",
      "(DET 81\n",
      "16=le) 80\n",
      "(NC 81\n",
      "17=calcul))) 78\n",
      "(COORD 79\n",
      "(CC 80\n",
      "18=et) 79\n",
      "(NP 80\n",
      "(DET 81\n",
      "19=la) 80\n",
      "(NC 81\n",
      "20=grammaire)))))))) 73\n",
      "(COORD 74\n",
      "(CC 75\n",
      "21=et) 74\n",
      "(Sint 75\n",
      "(VN 76\n",
      "(CLS-SUJ 77\n",
      "22=je) 76\n",
      "(V 77\n",
      "23=dis)) 75\n",
      "(PP-A_OBJ 76\n",
      "(P+D 77\n",
      "24=au) 76\n",
      "(NP 77\n",
      "(ADJ 78\n",
      "25=petit) 77\n",
      "(NC 78\n",
      "26=bonhomme))) 75\n",
      "(PP-MOD 76\n",
      "(P 77\n",
      "27=avec) 76\n",
      "(NP 77\n",
      "(ADV+ 78\n",
      "(DET 79\n",
      "28=un) 78\n",
      "(NC 79\n",
      "29=peu)) 77\n",
      "(P 78\n",
      "30=de) 77\n",
      "(ADJ 78\n",
      "31=mauvaise) 77\n",
      "(NC 78\n",
      "32=humeur))) 75\n",
      "(Ssub-OBJ 76\n",
      "(CS 77\n",
      "33=que) 76\n",
      "(Sint 77\n",
      "(VN 78\n",
      "(CLS-SUJ 79\n",
      "34=je) 78\n",
      "(ADV 79\n",
      "35=ne) 78\n",
      "(V 79\n",
      "36=savais)) 77\n",
      "(ADV 78\n",
      "37=pas) 77\n",
      "(VPinf-OBJ 78\n",
      "(VN 79\n",
      "(VINF 80\n",
      "38=dessiner)))))))) 72\n",
      ")\n",
      "(SENT 73\n",
      "(VN 74\n",
      "(CLS-SUJ 75\n",
      "0=Il) 74\n",
      "(CLO-A_OBJ 75\n",
      "1=me) 74\n",
      "(V 75\n",
      "2=répondit)) 73\n",
      ")\n",
      "(SENT 74\n",
      "(NP-SUJ 75\n",
      "(PRO 76\n",
      "0=ça)) 74\n",
      "(VN 75\n",
      "(ADV 76\n",
      "1=ne) 75\n",
      "(V 76\n",
      "2=fait)) 74\n",
      "(NP-OBJ 75\n",
      "(PRO 76\n",
      "3=rien)) 74\n",
      ")\n",
      "(SENT 75\n",
      "(VN 76\n",
      "(VIMP 77\n",
      "0=Dessine) 76\n",
      "(CLO-A_OBJ 77\n",
      "1=moi)) 75\n",
      "(NP-OBJ 76\n",
      "(DET 77\n",
      "2=un) 76\n",
      "(NC 77\n",
      "3=mouton)) 75\n",
      ")\n",
      "(SENT 76\n",
      "(Ssub-MOD 77\n",
      "(CS 78\n",
      "0=Comme) 77\n",
      "(Sint 78\n",
      "(VN 79\n",
      "(CLS-SUJ 80\n",
      "1=je) 79\n",
      "(ADV 80\n",
      "2=n') 79\n",
      "(V 80\n",
      "3=avais) 79\n",
      "(ADV 80\n",
      "4=jamais) 79\n",
      "(VPP 80\n",
      "5=dessiné)) 78\n",
      "(NP-OBJ 79\n",
      "(DET 80\n",
      "6=un) 79\n",
      "(NC 80\n",
      "7=mouton)))) 76\n",
      "(VN 77\n",
      "(CLS-SUJ 78\n",
      "8=je) 77\n",
      "(V 78\n",
      "9=refis)) 76\n",
      " 76\n",
      "(PP-MOD 77\n",
      "(P 78\n",
      "11=pour) 77\n",
      "(NP 78\n",
      "(PRO 79\n",
      "12=lui))) 76\n",
      " 76\n",
      "(NP-OBJ 77\n",
      "(DET 78\n",
      "14=l') 77\n",
      "(PRO 78\n",
      "15=un) 77\n",
      "(PP 78\n",
      "(P+D 79\n",
      "16=des) 78\n",
      "(NP 79\n",
      "(ADJ 80\n",
      "17=deux) 79\n",
      "(ADJ 80\n",
      "18=seuls) 79\n",
      "(NC 80\n",
      "19=dessins) 79\n",
      "(Srel 80\n",
      "(AP-ATS 81\n",
      "(PP-DEP 82\n",
      "(PROREL 83\n",
      "20=dont)) 81\n",
      "(ADJ 82\n",
      "23=capable)) 80\n",
      "(VN 81\n",
      "(CLS-SUJ 82\n",
      "21=j') 81\n",
      "(V 82\n",
      "22=étais)))))) 76\n",
      ")\n",
      "(SENT 77\n",
      "(NP 78\n",
      "(PRO 79\n",
      "0=Celui) 78\n",
      "(PP 79\n",
      "(P+D 80\n",
      "1=du) 79\n",
      "(NP 80\n",
      "(NC 81\n",
      "2=boa))) 78\n",
      "(VPpart 79\n",
      "(VPP 80\n",
      "3=fermé))) 77\n",
      ")\n",
      "(SENT 78\n",
      "(COORD 79\n",
      "(CC 80\n",
      "0=Et) 79\n",
      "(Sint 80\n",
      "(VN 81\n",
      "(CLS-SUJ 82\n",
      "1=je) 81\n",
      "(V 82\n",
      "2=fus)) 80\n",
      "(AP-ATS 81\n",
      "(ADJ 82\n",
      "3=stupéfait) 81\n",
      "(PP 82\n",
      "(P 83\n",
      "4=d') 82\n",
      "(VPinf 83\n",
      "(VN 84\n",
      "(VINF 85\n",
      "5=entendre)) 83\n",
      "(NP-OBJ 84\n",
      "(DET 85\n",
      "6=le) 84\n",
      "(ADJ 85\n",
      "7=petit) 84\n",
      "(NC 85\n",
      "8=bonhomme)) 83\n",
      "(VN 84\n",
      "(CLO-A_OBJ 85\n",
      "9=me) 84\n",
      "(VINF 85\n",
      "10=répondre))))))) 78\n",
      ")\n",
      "(SENT 79\n",
      "(ADV 80\n",
      "0=non) 79\n",
      ")\n",
      "(SENT 80\n",
      "(ADV 81\n",
      "0=Non) 80\n",
      ")\n",
      "(SENT 81\n",
      "(VN 82\n",
      "(CLS-SUJ 83\n",
      "0=Je) 82\n",
      "(ADV 83\n",
      "1=ne) 82\n",
      "(V 83\n",
      "2=veux)) 81\n",
      "(ADV 82\n",
      "3=pas) 81\n",
      "(PP-DE_OBJ 82\n",
      "(P 83\n",
      "4=d') 82\n",
      "(NP 83\n",
      "(DET 84\n",
      "5=un) 83\n",
      "(NC 84\n",
      "6=éléphant))) 81\n",
      "(PP-MOD 82\n",
      "(P 83\n",
      "7=dans) 82\n",
      "(NP 83\n",
      "(DET 84\n",
      "8=un) 83\n",
      "(NC 84\n",
      "9=boa))) 81\n",
      ")\n",
      "(SENT 82\n",
      "(NP-SUJ 83\n",
      "(DET 84\n",
      "0=Un) 83\n",
      "(NC 84\n",
      "1=boa)) 82\n",
      "(VN 83\n",
      "(CLS-SUJ 84\n",
      "2=c') 83\n",
      "(V 84\n",
      "3=est)) 82\n",
      "(AP-ATS 83\n",
      "(ADV 84\n",
      "4=très) 83\n",
      "(ADJ 84\n",
      "5=dangereux)) 82\n",
      " 82\n",
      "(COORD 83\n",
      "(CC 84\n",
      "7=et) 83\n",
      "(NP 84\n",
      "(DET 85\n",
      "8=un) 84\n",
      "(NC 85\n",
      "9=éléphant)) 83\n",
      "(VN 84\n",
      "(CLS-SUJ 85\n",
      "10=c') 84\n",
      "(V 85\n",
      "11=est)) 83\n",
      "(AP-ATS 84\n",
      "(ADV 85\n",
      "12=très) 84\n",
      "(ADJ 85\n",
      "13=encombrant))) 82\n",
      ")\n",
      "(SENT 83\n",
      "(PP-MOD 84\n",
      "(P 85\n",
      "0=Chez) 84\n",
      "(NP 85\n",
      "(PRO 86\n",
      "1=moi))) 83\n",
      "(VN 84\n",
      "(CLS-SUJ 85\n",
      "2=c') 84\n",
      "(V 85\n",
      "3=est)) 83\n",
      "(AP-ATS 84\n",
      "(ADV 85\n",
      "4=tout) 84\n",
      "(ADJ 85\n",
      "5=petit)) 83\n",
      ")\n",
      "(SENT 84\n",
      "(VN 85\n",
      "(CLS-SUJ 86\n",
      "0=J') 85\n",
      "(V+ 86\n",
      "(V 87\n",
      "1=ai) 86\n",
      "(NC 87\n",
      "2=besoin))) 84\n",
      "(PP-DE_OBJ 85\n",
      "(P 86\n",
      "3=d') 85\n",
      "(NP 86\n",
      "(DET 87\n",
      "4=un) 86\n",
      "(NC 87\n",
      "5=mouton))) 84\n",
      ")\n",
      "(SENT 85\n",
      "(VN 86\n",
      "(VIMP 87\n",
      "0=Dessine) 86\n",
      "(CLO-A_OBJ 87\n",
      "1=moi)) 85\n",
      "(NP-OBJ 86\n",
      "(DET 87\n",
      "2=un) 86\n",
      "(NC 87\n",
      "3=mouton)) 85\n",
      ")\n",
      "(SENT 86\n",
      "(ADV 87\n",
      "0=Alors) 86\n",
      "(VN 87\n",
      "(CLS-SUJ 88\n",
      "1=j') 87\n",
      "(V 88\n",
      "2=ai) 87\n",
      "(VPP 88\n",
      "3=dessiné)) 86\n",
      ")\n",
      "(SENT 87\n",
      "(VN 88\n",
      "(CLS-SUJ 89\n",
      "0=Il) 88\n",
      "(V 89\n",
      "1=regarda)) 87\n",
      "(ADV 88\n",
      "2=attentivement) 87\n",
      "(COORD 88\n",
      " 88\n",
      "(CC 89\n",
      "4=puis) 88\n",
      "))\n",
      "(SENT 89\n",
      "(ADV 90\n",
      "0=non) 89\n",
      ")\n",
      "(SENT 90\n",
      "(NP-SUJ 91\n",
      "(PRO+ 92\n",
      "(PRO 93\n",
      "0=Celui) 92\n",
      "(ADV 93\n",
      "1=là))) 90\n",
      "(VN 91\n",
      "(V 92\n",
      "2=est)) 90\n",
      "(AP-ATS 91\n",
      "(ADV 92\n",
      "3=très) 91\n",
      "(ADJ 92\n",
      "4=malade)) 90\n",
      ")\n",
      "(SENT 91\n",
      "(VN 92\n",
      "(VIMP 93\n",
      "0=Fais) 92\n",
      "(CLO-DE_OBJ 93\n",
      "1=en)) 91\n",
      "(NP-OBJ 92\n",
      "(DET 93\n",
      "2=un) 92\n",
      "(PRO 93\n",
      "3=autre)) 91\n",
      ")\n",
      "(VN 92\n",
      "(CLS-SUJ 93\n",
      "0=Je) 92\n",
      "(V 93\n",
      "1=dessinai:))\n",
      "(SENT 94\n",
      "(NP-SUJ 95\n",
      "(DET 96\n",
      "0=mon) 95\n",
      "(NC 96\n",
      "1=ami)) 94\n",
      "(VN 95\n",
      "(V 96\n",
      "2=sourit)) 94\n",
      "(ADV 95\n",
      "3=gentiment) 94\n",
      " 94\n",
      "(PP-MOD 95\n",
      "(P 96\n",
      "5=avec) 95\n",
      "(NP 96\n",
      "(NC 97\n",
      "6=indulgence))) 94\n",
      ")\n",
      "(SENT 95\n",
      "(VN 96\n",
      "(CLS-SUJ 97\n",
      "0=tu) 96\n",
      "(V 97\n",
      "1=vois)) 95\n",
      "(ADV 96\n",
      "2=bien) 95\n",
      ")\n",
      "(SENT 96\n",
      "(VN 97\n",
      "(CLS-SUJ 98\n",
      "0=Ce) 97\n",
      "(ADV 98\n",
      "1=n') 97\n",
      "(V 98\n",
      "2=est)) 96\n",
      "(ADV 97\n",
      "3=pas) 96\n",
      "(NP-ATS 97\n",
      "(DET 98\n",
      "4=un) 97\n",
      "(NC 98\n",
      "5=mouton)) 96\n",
      " 96\n",
      "(Sint-MOD 97\n",
      "(VN 98\n",
      "(CLS-SUJ 99\n",
      "7=c') 98\n",
      "(V 99\n",
      "8=est)) 97\n",
      "(NP-ATS 98\n",
      "(DET 99\n",
      "9=un) 98\n",
      "(NC 99\n",
      "10=bélier))) 96\n",
      ")\n",
      "(SENT 97\n",
      "(VN 98\n",
      "(CLS-SUJ 99\n",
      "0=Il) 98\n",
      "(V 99\n",
      "1=a)) 97\n",
      "(NP-OBJ 98\n",
      "(DET 99\n",
      "2=des) 98\n",
      "(NC 99\n",
      "3=cornes)) 97\n",
      ")\n",
      "(SENT 98\n",
      "(VN 99\n",
      "(CLS-SUJ 100\n",
      "0=Je) 99\n",
      "(V 100\n",
      "1=refis)) 98\n",
      "(ADV 99\n",
      "2=donc) 98\n",
      "(ADV 99\n",
      "3=encore) 98\n",
      "(NP-OBJ 99\n",
      "(DET 100\n",
      "4=mon) 99\n",
      "(NC 100\n",
      "5=dessin)) 98\n",
      ")\n",
      "(SENT 99\n",
      "(COORD 100\n",
      "(CC 101\n",
      "0=mais) 100\n",
      "(Sint 101\n",
      "(VN 102\n",
      "(CLS-SUJ 103\n",
      "1=il) 102\n",
      "(V 103\n",
      "2=fut) 102\n",
      "(VPP 103\n",
      "3=refusé)) 101\n",
      " 101\n",
      "(PP-MOD 102\n",
      "(P 103\n",
      "5=comme) 102\n",
      "(NP 103\n",
      "(DET 104\n",
      "6=les) 103\n",
      "(NC 104\n",
      "7=précédents)))) 100\n",
      "))\n",
      "(SENT 101\n",
      "(NP-SUJ 102\n",
      "(PRO+ 103\n",
      "(PRO 104\n",
      "0=celui) 103\n",
      "(ADV 104\n",
      "1=là))) 101\n",
      "(VN 102\n",
      "(V 103\n",
      "2=est)) 101\n",
      "(AP-ATS 102\n",
      "(ADV 103\n",
      "3=trop) 102\n",
      "(ADJ 103\n",
      "4=vieux)) 101\n",
      ")\n",
      "(SENT 102\n",
      "(VN 103\n",
      "(CLS-SUJ 104\n",
      "0=Je) 103\n",
      "(V 104\n",
      "1=veux)) 102\n",
      "(NP-OBJ 103\n",
      "(DET 104\n",
      "2=un) 103\n",
      "(NC 104\n",
      "3=mouton) 103\n",
      "(Srel 104\n",
      "(NP-SUJ 105\n",
      "(PROREL 106\n",
      "4=qui)) 104\n",
      "(VN 105\n",
      "(VS 106\n",
      "5=vive)) 104\n",
      "(ADV 105\n",
      "6=longtemps))) 102\n",
      ")\n",
      "(SENT 103\n",
      "(ADV 104\n",
      "0=Alors) 103\n",
      " 103\n",
      "(PP-MOD 104\n",
      "(P+ 105\n",
      "(NC 106\n",
      "2=faute) 105\n",
      "(P 106\n",
      "3=de)) 104\n",
      "(NP 105\n",
      "(NC 106\n",
      "4=patience))) 103\n",
      " 103\n",
      "(Ssub-MOD 104\n",
      "(CS 105\n",
      "6=comme) 104\n",
      "(Sint 105\n",
      "(VN 106\n",
      "(CLS-SUJ 107\n",
      "7=j') 106\n",
      "(V 107\n",
      "8=avais)) 105\n",
      "(NP-OBJ 106\n",
      "(NC 107\n",
      "9=hâte)) 105\n",
      "(PP-DE_OBJ 106\n",
      "(P 107\n",
      "10=de) 106\n",
      "(VPinf 107\n",
      "(VN 108\n",
      "(VINF 109\n",
      "11=commencer)) 107\n",
      "(NP-OBJ 108\n",
      "(DET 109\n",
      "12=le) 108\n",
      "(NC 109\n",
      "13=démontage) 108\n",
      "(PP 109\n",
      "(P 110\n",
      "14=de) 109\n",
      "(NP 110\n",
      "(DET 111\n",
      "15=mon) 110\n",
      "(NC 111\n",
      "16=moteur)))))))) 103\n",
      " 103\n",
      "(VN 104\n",
      "(CLS-SUJ 105\n",
      "18=je) 104\n",
      "(V 105\n",
      "19=griffonnai)) 103\n",
      "(NP-OBJ 104\n",
      "(DET 105\n",
      "20=ce) 104\n",
      "(NC 105\n",
      "21=dessin) 104\n",
      "(ADV 105\n",
      "22=ci:)))\n",
      "(SENT 106\n",
      "(COORD 107\n",
      "(CC 108\n",
      "0=et) 107\n",
      "(VN 108\n",
      "(CLS-SUJ 109\n",
      "1=je) 108\n",
      "(V 109\n",
      "2=lançai))) 106\n",
      ")\n",
      "(SENT 107\n",
      "(NP 108\n",
      "(PRO 109\n",
      "0=ça)) 107\n",
      "(VN 108\n",
      "(CLS-SUJ 109\n",
      "1=c') 108\n",
      "(V 109\n",
      "2=est)) 107\n",
      "(NP-ATS 108\n",
      "(DET 109\n",
      "3=la) 108\n",
      "(NC 109\n",
      "4=caisse)) 107\n",
      ")\n",
      "(SENT 108\n",
      "(NP-SUJ 109\n",
      "(DET 110\n",
      "0=Le) 109\n",
      "(NC 110\n",
      "1=mouton) 109\n",
      "(Srel 110\n",
      "(NP-OBJ 111\n",
      "(PROREL 112\n",
      "2=que)) 110\n",
      "(VN 111\n",
      "(CLS-SUJ 112\n",
      "3=tu) 111\n",
      "(V 112\n",
      "4=veux)))) 108\n",
      "(VN 109\n",
      "(V 110\n",
      "5=est)) 108\n",
      "(ADV-P_OBJ.O 109\n",
      "6=dedans) 108\n",
      ")\n",
      "(SENT 109\n",
      "(COORD 110\n",
      "(CC 111\n",
      "0=Mais) 110\n",
      "(Sint 111\n",
      "(VN 112\n",
      "(CLS-SUJ 113\n",
      "1=je) 112\n",
      "(V 113\n",
      "2=fus) 112\n",
      "(ADV 113\n",
      "3=bien) 112\n",
      "(VPP 113\n",
      "4=surpris)) 111\n",
      "(PP-DE_OBJ 112\n",
      "(P 113\n",
      "5=de) 112\n",
      "(VPinf 113\n",
      "(VN 114\n",
      "(VINF 115\n",
      "6=voir)) 113\n",
      "(VPinf-OBJ 114\n",
      "(VN 115\n",
      "(CLR 116\n",
      "7=s') 115\n",
      "(VINF 116\n",
      "8=illuminer)) 114\n",
      "(NP-OBJ 115\n",
      "(DET 116\n",
      "9=le) 115\n",
      "(NC 116\n",
      "10=visage) 115\n",
      "(PP 116\n",
      "(P 117\n",
      "11=de) 116\n",
      "(NP 117\n",
      "(DET 118\n",
      "12=mon) 117\n",
      "(ADJ 118\n",
      "13=jeune) 117\n",
      "(NC 118\n",
      "14=juge))))))))) 109\n",
      ")\n",
      "(SENT 110\n",
      "(VN 111\n",
      "(VN 112\n",
      "(CLS-SUJ 113\n",
      "0=c') 112\n",
      "(V 113\n",
      "1=est)) 111\n",
      "(ADV+ 112\n",
      "(ADV 113\n",
      "2=tout) 112\n",
      "(P 113\n",
      "3=a) 112\n",
      "(VPP 113\n",
      "4=fait))) 110\n",
      "(PP-ATS 111\n",
      "(P 112\n",
      "5=comme) 111\n",
      "(NP 112\n",
      "(PRO 113\n",
      "6=ça))) 110\n",
      "(Srel-MOD 111\n",
      "(NP-MOD 112\n",
      "(PROREL 113\n",
      "7=que)) 111\n",
      "(VN 112\n",
      "(CLS-SUJ 113\n",
      "8=je) 112\n",
      "(CLO-OBJ 113\n",
      "9=le) 112\n",
      "(V 113\n",
      "10=voulais))) 110\n",
      ")\n",
      "(SENT 111\n",
      "(VN 112\n",
      "(V 113\n",
      "0=Crois) 112\n",
      "(CLS-SUJ 113\n",
      "1=tu)) 111\n",
      "(Ssub-OBJ 112\n",
      "(CS 113\n",
      "2=qu') 112\n",
      "(Sint 113\n",
      "(VN 114\n",
      "(CLS-SUJ 115\n",
      "3=il) 114\n",
      "(VS 115\n",
      "4=faille)) 113\n",
      "(NP-OBJ 114\n",
      "(ADV 115\n",
      "5=beaucoup) 114\n",
      "(P 115\n",
      "6=d') 114\n",
      "(NC 115\n",
      "7=herbe)) 113\n",
      "(PP-A_OBJ 114\n",
      "(P 115\n",
      "8=à) 114\n",
      "(NP 115\n",
      "(DET 116\n",
      "9=ce) 115\n",
      "(NC 116\n",
      "10=mouton))))) 111\n",
      ")\n",
      "(SENT 112\n",
      "(ADVWH 113\n",
      "0=pourquoi) 112\n",
      ")\n",
      "(SENT 113\n",
      "(Ssub 114\n",
      "(CS+ 115\n",
      "(CS 116\n",
      "0=parce) 115\n",
      "(CS 116\n",
      "1=que)) 114\n",
      "(Sint 115\n",
      "(PP-MOD 116\n",
      "(P 117\n",
      "2=chez) 116\n",
      "(NP 117\n",
      "(PRO 118\n",
      "3=moi))) 115\n",
      "(VN 116\n",
      "(CLS-SUJ 117\n",
      "4=c') 116\n",
      "(V 117\n",
      "5=est)) 115\n",
      "(AP-ATS 116\n",
      "(ADV 117\n",
      "6=tout) 116\n",
      "(ADJ 117\n",
      "7=petit)))) 113\n",
      ")\n",
      "(SENT 114\n",
      "(NP-SUJ 115\n",
      "(PRO 116\n",
      "0=ça)) 114\n",
      "(VN 115\n",
      "(V 116\n",
      "1=suffira)) 114\n",
      "(ADV 115\n",
      "2=sûrement) 114\n",
      ")\n",
      "(SENT 115\n",
      "(VN 116\n",
      "(CLS-SUJ 117\n",
      "0=Je) 116\n",
      "(CLO-A_OBJ 117\n",
      "1=t') 116\n",
      "(V 117\n",
      "2=ai) 116\n",
      "(VPP 117\n",
      "3=donné)) 115\n",
      "(NP-OBJ 116\n",
      "(DET 117\n",
      "4=un) 116\n",
      "(AP 117\n",
      "(ADV 118\n",
      "5=tout) 117\n",
      "(ADJ 118\n",
      "6=petit)) 116\n",
      "(NC 117\n",
      "7=mouton)) 115\n",
      ")\n",
      "(SENT 116\n",
      "(VN 117\n",
      "(CLS-SUJ 118\n",
      "0=Il) 117\n",
      "(V 118\n",
      "1=pencha)) 116\n",
      "(NP-OBJ 117\n",
      "(DET 118\n",
      "2=la) 117\n",
      "(NC 118\n",
      "3=tête)) 116\n",
      "(PP-P_OBJ.O 117\n",
      "(P 118\n",
      "4=vers) 117\n",
      "(NP 118\n",
      "(DET 119\n",
      "5=le) 118\n",
      "(NC 119\n",
      "6=dessin))) 116\n",
      ")\n",
      "(SENT 117\n",
      "(AP 118\n",
      "(ADV 119\n",
      "0=pas) 118\n",
      "(ADV 119\n",
      "1=si) 118\n",
      "(ADJ 119\n",
      "2=petit) 118\n",
      "(Ssub 119\n",
      "(CS 120\n",
      "3=que) 119\n",
      "(NP 120\n",
      "(PRO 121\n",
      "4=ça)))) 117\n",
      ")\n",
      "(SENT 118\n",
      "(I 119\n",
      "0=Tiens) 118\n",
      ")\n",
      "(SENT 119\n",
      "(VN 120\n",
      "(CLS-SUJ 121\n",
      "0=Il) 120\n",
      "(CLR 121\n",
      "1=s') 120\n",
      "(V 121\n",
      "2=est) 120\n",
      "(VPP 121\n",
      "3=endormi)) 119\n",
      ")\n",
      "(SENT 120\n",
      "(COORD 121\n",
      "(CC 122\n",
      "0=Et) 121\n",
      "(Sint 122\n",
      "(VN 123\n",
      "(CLS-SUJ 124\n",
      "1=c') 123\n",
      "(V 124\n",
      "2=est)) 122\n",
      "(ADV 123\n",
      "3=ainsi) 122\n",
      "(Srel-MOD 123\n",
      "(NP-OBJ 124\n",
      "(PROREL 125\n",
      "4=que)) 123\n",
      "(VN 124\n",
      "(CLS-SUJ 125\n",
      "5=je) 124\n",
      "(V 125\n",
      "6=fis)) 123\n",
      "(NP-OBJ 124\n",
      "(DET 125\n",
      "7=la) 124\n",
      "(NC 125\n",
      "8=connaissance)) 123\n",
      "(PP-DE_OBJ 124\n",
      "(P+D 125\n",
      "9=du) 124\n",
      "(NP 125\n",
      "(ADJ 126\n",
      "10=petit) 125\n",
      "(NC 126\n",
      "11=prince)))))) 120\n",
      ")\n",
      "(SENT 121\n",
      "(VN 122\n",
      "(CLS-SUJ 123\n",
      "0=Il) 122\n",
      "(CLO-A_OBJ 123\n",
      "1=me) 122\n",
      "(V 123\n",
      "2=fallut)) 121\n",
      "(ADV 122\n",
      "3=longtemps) 121\n",
      "(PP-MOD 122\n",
      "(P 123\n",
      "4=pour) 122\n",
      "(VPinf 123\n",
      "(VN 124\n",
      "(VINF 125\n",
      "5=comprendre)) 123\n",
      "(Ssub-OBJ 124\n",
      "(PP-DE_OBJ 125\n",
      "(P 126\n",
      "6=d') 125\n",
      "(ADVWH 126\n",
      "7=où)) 124\n",
      "(VN 125\n",
      "(CLS-SUJ 126\n",
      "8=il) 125\n",
      "(V 126\n",
      "9=venait))))) 121\n",
      ")\n",
      "(SENT 122\n",
      "(NP-SUJ 123\n",
      "(DET 124\n",
      "0=Le) 123\n",
      "(ADJ 124\n",
      "1=petit) 123\n",
      "(NC 124\n",
      "2=prince) 123\n",
      " 123\n",
      "(Srel 124\n",
      "(NP-SUJ 125\n",
      "(PROREL 126\n",
      "4=qui)) 124\n",
      "(VN 125\n",
      "(CLO-A_OBJ 126\n",
      "5=me) 125\n",
      "(V 126\n",
      "6=posait)) 124\n",
      "(NP-OBJ 125\n",
      "(ADV 126\n",
      "7=beaucoup) 125\n",
      "(P 126\n",
      "8=de) 125\n",
      "(NC 126\n",
      "9=questions)))) 122\n",
      " 122\n",
      "(VN 123\n",
      "(ADV 124\n",
      "11=ne) 123\n",
      "(V 124\n",
      "12=semblait)) 122\n",
      "(ADV 123\n",
      "13=jamais) 122\n",
      "(VPinf-ATS 123\n",
      "(VN 124\n",
      "(VINF 125\n",
      "14=entendre)) 123\n",
      "(NP-OBJ 124\n",
      "(DET 125\n",
      "15=les) 124\n",
      "(PRO 125\n",
      "16=miennes))) 122\n",
      ")\n",
      "(SENT 123\n",
      "(VN 124\n",
      "(CLS-SUJ 125\n",
      "0=Ce) 124\n",
      "(V 125\n",
      "1=sont)) 123\n",
      "(NP-ATS 124\n",
      "(DET 125\n",
      "2=des) 124\n",
      "(NC 125\n",
      "3=mots) 124\n",
      "(VPpart 125\n",
      "(VPP 126\n",
      "4=prononcés) 125\n",
      "(ADV+ 126\n",
      "(P 127\n",
      "5=par) 126\n",
      "(NP 127\n",
      "(NC 128\n",
      "6=hasard)))) 124\n",
      "(Srel 125\n",
      "(NP-SUJ 126\n",
      "(PROREL 127\n",
      "7=qui)) 125\n",
      " 125\n",
      "(ADV+ 126\n",
      "(ADV 127\n",
      "9=peu) 126\n",
      "(P 127\n",
      "10=à) 126\n",
      "(ADV 127\n",
      "11=peu)) 125\n",
      " 125\n",
      "(VN 126\n",
      "(CLO-A_OBJ 127\n",
      "13=m') 126\n",
      "(V 127\n",
      "14=ont) 126\n",
      "(NP-OBJ 127\n",
      "(PRO 128\n",
      "15=tout)) 126\n",
      "(VPP 127\n",
      "16=révélé)))) 123\n",
      ")\n",
      "(SENT 124\n",
      "(ADV 125\n",
      "0=Ainsi) 124\n",
      " 124\n",
      "(Ssub-MOD 125\n",
      "(CS 126\n",
      "2=quand) 125\n",
      "(Sint 126\n",
      "(VN 127\n",
      "(CLS-SUJ 128\n",
      "3=il) 127\n",
      "(V 128\n",
      "4=aperçut)) 126\n",
      "(PP-MOD 127\n",
      "(P 128\n",
      "5=pour) 127\n",
      "(NP 128\n",
      "(DET 129\n",
      "6=la) 128\n",
      "(ADJ 129\n",
      "7=première) 128\n",
      "(NC 129\n",
      "8=fois))) 126\n",
      "(NP-OBJ 127\n",
      "(DET 128\n",
      "9=mon) 127\n",
      "(NC 128\n",
      "10=avion)))) 124\n",
      " 124\n",
      "(VN 125\n",
      "(CLS-SUJ 126\n",
      "12=je) 125\n",
      "(ADV 126\n",
      "13=ne) 125\n",
      "(V 126\n",
      "14=dessinerai)) 124\n",
      "(ADV 125\n",
      "15=pas) 124\n",
      "(NP-OBJ 125\n",
      "(DET 126\n",
      "16=mon) 125\n",
      "(NC 126\n",
      "17=avion)) 124\n",
      " 124\n",
      "(Sint-MOD 125\n",
      "(VN 126\n",
      "(CLS-SUJ 127\n",
      "19=c') 126\n",
      "(V 127\n",
      "20=est)) 125\n",
      "(NP-ATS 126\n",
      "(DET 127\n",
      "21=un) 126\n",
      "(NC 127\n",
      "22=dessin) 126\n",
      "(AP 127\n",
      "(AdP 128\n",
      "(ADV 129\n",
      "23=beaucoup) 128\n",
      "(ADV 129\n",
      "24=trop)) 127\n",
      "(ADJ 128\n",
      "25=compliqué) 127\n",
      "(PP 128\n",
      "(P 129\n",
      "26=pour) 128\n",
      "(NP 129\n",
      "(PRO 130\n",
      "27=moi)))))) 124\n",
      " 124\n",
      "(VN 125\n",
      "(CLS-SUJ 126\n",
      "29=il) 125\n",
      "(CLO-A_OBJ 126\n",
      "30=me) 125\n",
      "(V 126\n",
      "31=demanda)) 124\n",
      ")\n",
      "(SENT 125\n",
      "(NP-ATS 126\n",
      "(PROWH 127\n",
      "0=qu')) 125\n",
      "(VN 126\n",
      "(V 127\n",
      "1=est) 126\n",
      "(CLS-SUJ 127\n",
      "2=ce)) 125\n",
      "(Srel-MOD.CLEFT 126\n",
      "(NP-ATS 127\n",
      "(PROREL 128\n",
      "3=que)) 126\n",
      "(VN 127\n",
      "(CLS-SUJ 128\n",
      "4=c') 127\n",
      "(V 128\n",
      "5=est)) 126\n",
      "(Ssub-ATS 127\n",
      "(CS 128\n",
      "6=que) 127\n",
      "(NP 128\n",
      "(DET 129\n",
      "7=cette) 128\n",
      "(NC 129\n",
      "8=chose) 128\n",
      "(ADV 129\n",
      "9=là)))) 125\n",
      ")\n",
      "(SENT 126\n",
      "(VN 127\n",
      "(CLS-SUJ 128\n",
      "0=ce) 127\n",
      "(ADV 128\n",
      "1=n') 127\n",
      "(V 128\n",
      "2=est)) 126\n",
      "(ADV 127\n",
      "3=pas) 126\n",
      "(NP-ATS 127\n",
      "(DET 128\n",
      "4=une) 127\n",
      "(NC 128\n",
      "5=chose)) 126\n",
      ")\n",
      "(SENT 127\n",
      "(NP-SUJ 128\n",
      "(PRO 129\n",
      "0=Ça)) 127\n",
      "(VN 128\n",
      "(V 129\n",
      "1=vole)) 127\n",
      ")\n",
      "(SENT 128\n",
      "(VN 129\n",
      "(CLS-SUJ 130\n",
      "0=C') 129\n",
      "(V 130\n",
      "1=est)) 128\n",
      "(NP-ATS 129\n",
      "(DET 130\n",
      "2=un) 129\n",
      "(NC 130\n",
      "3=avion)) 128\n",
      ")\n",
      "(SENT 129\n",
      "(VN 130\n",
      "(CLS-SUJ 131\n",
      "0=C') 130\n",
      "(V 131\n",
      "1=est)) 129\n",
      "(NP-ATS 130\n",
      "(DET 131\n",
      "2=mon) 130\n",
      "(NC 131\n",
      "3=avion)) 129\n",
      ")\n",
      "(SENT 130\n",
      "(COORD 131\n",
      "(CC 132\n",
      "0=Et) 131\n",
      "(Sint 132\n",
      "(VN 133\n",
      "(CLS-SUJ 134\n",
      "1=j') 133\n",
      "(V 134\n",
      "2=étais)) 132\n",
      "(AP-ATS 133\n",
      "(ADJ 134\n",
      "3=fier) 133\n",
      "(PP 134\n",
      "(P 135\n",
      "4=de) 134\n",
      "(VPinf 135\n",
      "(VN 136\n",
      "(CLO-A_OBJ 137\n",
      "5=lui) 136\n",
      "(VINF 137\n",
      "6=apprendre)) 135\n",
      "(Ssub-OBJ 136\n",
      "(CS 137\n",
      "7=que) 136\n",
      "(Sint 137\n",
      "(VN 138\n",
      "(CLS-SUJ 139\n",
      "8=je) 138\n",
      "(V 139\n",
      "9=volais))))))))) 130\n",
      ")\n",
      "(SENT 131\n",
      "(ADV 132\n",
      "0=Alors) 131\n",
      "(VN 132\n",
      "(CLS-SUJ 133\n",
      "1=il) 132\n",
      "(CLR 133\n",
      "2=s') 132\n",
      "(V 133\n",
      "3=écria:)))\n",
      "(SENT 134\n",
      "(ADVWH 135\n",
      "0=comment) 134\n",
      ")\n",
      "(SENT 135\n",
      "(VN 136\n",
      "(CLS-SUJ 137\n",
      "0=Tu) 136\n",
      "(V 137\n",
      "1=es) 136\n",
      "(VPP 137\n",
      "2=tombé)) 135\n",
      "(PP-DE_OBJ 136\n",
      "(P+D 137\n",
      "3=du) 136\n",
      "(NP 137\n",
      "(NC 138\n",
      "4=ciel))) 135\n",
      ")\n",
      "(SENT 136\n",
      "(ADV 137\n",
      "0=oui) 136\n",
      " 136\n",
      "(VN 137\n",
      "(V 138\n",
      "2=fis) 137\n",
      "(CLS-SUJ 138\n",
      "3=je)) 136\n",
      "(ADV 137\n",
      "4=modestement) 136\n",
      ")\n",
      "(SENT 137\n",
      "(I 138\n",
      "0=ah) 137\n",
      ")\n",
      "(SENT 138\n",
      "(NP 139\n",
      "(PRO 140\n",
      "0=Ça)) 138\n",
      "(VN 139\n",
      "(CLS-SUJ 140\n",
      "1=c') 139\n",
      "(V 140\n",
      "2=est)) 138\n",
      "(AP-ATS 139\n",
      "(ADJ 140\n",
      "3=drôle)) 138\n",
      ")\n",
      "(SENT 139\n",
      "(COORD 140\n",
      "(CC 141\n",
      "0=Et) 140\n",
      "(Sint 141\n",
      "(NP-SUJ 142\n",
      "(DET 143\n",
      "1=le) 142\n",
      "(ADJ 143\n",
      "2=petit) 142\n",
      "(NC 143\n",
      "3=prince)) 141\n",
      "(VN 142\n",
      "(V 143\n",
      "4=eut)) 141\n",
      "(NP-OBJ 142\n",
      "(DET 143\n",
      "5=un) 142\n",
      "(AP 143\n",
      "(ADV 144\n",
      "6=très) 143\n",
      "(ADJ 144\n",
      "7=joli)) 142\n",
      "(NC+ 143\n",
      "(NC 144\n",
      "8=éclat) 143\n",
      "(P 144\n",
      "9=de) 143\n",
      "(NC 144\n",
      "10=rire)) 142\n",
      "(Srel 143\n",
      "(NP-SUJ 144\n",
      "(PROREL 145\n",
      "11=qui)) 143\n",
      "(VN 144\n",
      "(CLO-OBJ 145\n",
      "12=m') 144\n",
      "(V 145\n",
      "13=irrita)) 143\n",
      "(ADV 144\n",
      "14=beaucoup))))) 139\n",
      ")\n",
      "(SENT 140\n",
      "(VN 141\n",
      "(CLS-SUJ 142\n",
      "0=Je) 141\n",
      "(V 142\n",
      "1=désire)) 140\n",
      "(Ssub-OBJ 141\n",
      "(CS 142\n",
      "2=que) 141\n",
      "(Sint 142\n",
      "(VN 143\n",
      "(CLS-SUJ 144\n",
      "3=l'on) 143\n",
      "(VS 144\n",
      "4=prenne)) 142\n",
      "(NP-OBJ 143\n",
      "(DET 144\n",
      "5=mes) 143\n",
      "(NC 144\n",
      "6=malheurs)) 142\n",
      "(PP-P_OBJ.O 143\n",
      "(P+D 144\n",
      "7=au) 143\n",
      "(AP 144\n",
      "(ADJ 145\n",
      "8=sérieux))))) 140\n",
      ")\n",
      "(SENT 141\n",
      "(COORD 142\n",
      "(CC 143\n",
      "0=Puis) 142\n",
      "(VN 143\n",
      "(CLS-SUJ 144\n",
      "1=il) 143\n",
      "(V 144\n",
      "2=ajouta))) 141\n",
      ")\n",
      "(SENT 142\n",
      "(ADV 143\n",
      "0=alors) 142\n",
      " 142\n",
      "(NP-SUJ 143\n",
      "(PRO 144\n",
      "2=toi) 143\n",
      "(ADV 144\n",
      "3=aussi)) 142\n",
      "(VN 143\n",
      "(CLS-SUJ 144\n",
      "4=tu) 143\n",
      "(V 144\n",
      "5=viens)) 142\n",
      "(PP-P_OBJ 143\n",
      "(P+D 144\n",
      "6=du) 143\n",
      "(NP 144\n",
      "(NC 145\n",
      "7=ciel))) 142\n",
      ")\n",
      "(SENT 143\n",
      "(PP-ATS 144\n",
      "(P 145\n",
      "0=De) 144\n",
      "(NP 145\n",
      "(DETWH 146\n",
      "1=quelle) 145\n",
      "(NC 146\n",
      "2=planète))) 143\n",
      "(VN 144\n",
      "(V 145\n",
      "3=es) 144\n",
      "(CLS-SUJ 145\n",
      "4=tu)) 143\n",
      ")\n",
      "(SENT 144\n",
      "(VN 145\n",
      "(CLS-SUJ 146\n",
      "0=J') 145\n",
      "(V 146\n",
      "1=entrevis)) 144\n",
      "(ADV 145\n",
      "2=aussitôt) 144\n",
      "(NP-OBJ 145\n",
      "(DET 146\n",
      "3=une) 145\n",
      "(NC 146\n",
      "4=lueur)) 144\n",
      " 144\n",
      "(PP-MOD 145\n",
      "(P 146\n",
      "6=dans) 145\n",
      "(NP 146\n",
      "(DET 147\n",
      "7=le) 146\n",
      "(NC 147\n",
      "8=mystère) 146\n",
      "(PP 147\n",
      "(P 148\n",
      "9=de) 147\n",
      "(NP 148\n",
      "(DET 149\n",
      "10=sa) 148\n",
      "(NC 149\n",
      "11=présence))))) 144\n",
      " 144\n",
      "(COORD 145\n",
      "(CC 146\n",
      "13=et) 145\n",
      "(Sint 146\n",
      "(VN 147\n",
      "(CLS-SUJ 148\n",
      "14=j') 147\n",
      "(V 148\n",
      "15=interrogeai)) 146\n",
      "(ADV 147\n",
      "16=brusquement))) 144\n",
      ")\n",
      "(SENT 145\n",
      "(VN 146\n",
      "(CLS-SUJ 147\n",
      "0=tu) 146\n",
      "(V 147\n",
      "1=viens)) 145\n",
      "(ADV 146\n",
      "2=donc) 145\n",
      "(PP-DE_OBJ 146\n",
      "(P 147\n",
      "3=d') 146\n",
      "(NP 147\n",
      "(DET 148\n",
      "4=une) 147\n",
      "(ADJ 148\n",
      "5=autre) 147\n",
      "(NC 148\n",
      "6=planète))) 145\n",
      ")\n",
      "(SENT 146\n",
      "(COORD 147\n",
      "(CC 148\n",
      "0=Mais) 147\n",
      "(Sint 148\n",
      "(VN 149\n",
      "(CLS-SUJ 150\n",
      "1=il) 149\n",
      "(ADV 150\n",
      "2=ne) 149\n",
      "(CLO-A_OBJ 150\n",
      "3=me) 149\n",
      "(V 150\n",
      "4=répondit)) 148\n",
      "(ADV 149\n",
      "5=pas))) 146\n",
      ")\n",
      "(SENT 147\n",
      "(VN 148\n",
      "(CLS-SUJ 149\n",
      "0=Il) 148\n",
      "(V 149\n",
      "1=hochait)) 147\n",
      "(NP-OBJ 148\n",
      "(DET 149\n",
      "2=la) 148\n",
      "(NC 149\n",
      "3=tête)) 147\n",
      "(ADV 148\n",
      "4=doucement) 147\n",
      "(PP-MOD 148\n",
      "(ADV 149\n",
      "5=tout) 148\n",
      "(P 149\n",
      "6=en) 148\n",
      "(VPpart 149\n",
      "(VN 150\n",
      "(VPR 151\n",
      "7=regardant)) 149\n",
      "(NP-OBJ 150\n",
      "(DET 151\n",
      "8=mon) 150\n",
      "(NC 151\n",
      "9=avion)))) 147\n",
      ")\n",
      "(SENT 148\n",
      "(VN 149\n",
      "(CLS-SUJ 150\n",
      "0=c') 149\n",
      "(V 150\n",
      "1=est)) 148\n",
      "(AP-ATS 149\n",
      "(ADJ 150\n",
      "2=vrai)) 148\n",
      "(Ssub-OBJ 149\n",
      "(CS 150\n",
      "3=que) 149\n",
      "(Sint 150\n",
      " 150\n",
      "(ADV+ 151\n",
      "(ADV 152\n",
      "5=là) 151\n",
      "(ADV 152\n",
      "6=dessus)) 150\n",
      " 150\n",
      "(VN 151\n",
      "(CLS-SUJ 152\n",
      "8=tu) 151\n",
      "(ADV 152\n",
      "9=ne) 151\n",
      "(V 152\n",
      "10=peux)) 150\n",
      "(ADV 151\n",
      "11=pas) 150\n",
      "(VPinf-OBJ 151\n",
      "(VN 152\n",
      "(VINF 153\n",
      "12=venir)) 151\n",
      "(PP-MOD 152\n",
      "(P 153\n",
      "13=de) 152\n",
      "(AdP 153\n",
      "(ADV 154\n",
      "14=bien) 153\n",
      "(ADV 154\n",
      "15=loin)))))) 148\n",
      ")\n",
      "(SENT 149\n",
      "(COORD 150\n",
      "(CC 151\n",
      "0=Et) 150\n",
      "(VN 151\n",
      "(CLS-SUJ 152\n",
      "1=il) 151\n",
      "(CLR 152\n",
      "2=s') 151\n",
      "(V 152\n",
      "3=enfonça)) 150\n",
      "(PP-P_OBJ 151\n",
      "(P 152\n",
      "4=dans) 151\n",
      "(NP 152\n",
      "(DET 153\n",
      "5=une) 152\n",
      "(NC 153\n",
      "6=rêverie) 152\n",
      "(Srel 153\n",
      "(NP-SUJ 154\n",
      "(PROREL 155\n",
      "7=qui)) 153\n",
      "(VN 154\n",
      "(V 155\n",
      "8=dura)) 153\n",
      "(ADV 154\n",
      "9=longtemps))))) 149\n",
      ")\n",
      "(SENT 150\n",
      "(COORD 151\n",
      "(CC 152\n",
      "0=Puis) 151\n",
      "(Sint 152\n",
      " 152\n",
      "(VPpart-MOD 153\n",
      "(VN 154\n",
      "(VPR 155\n",
      "2=sortant)) 153\n",
      "(NP-OBJ 154\n",
      "(DET 155\n",
      "3=mon) 154\n",
      "(NC 155\n",
      "4=mouton)) 153\n",
      "(PP-DE_OBJ 154\n",
      "(P 155\n",
      "5=de) 154\n",
      "(NP 155\n",
      "(DET 156\n",
      "6=sa) 155\n",
      "(NC 156\n",
      "7=poche)))) 152\n",
      " 152\n",
      "(VN 153\n",
      "(CLS-SUJ 154\n",
      "9=il) 153\n",
      "(CLR 154\n",
      "10=se) 153\n",
      "(V 154\n",
      "11=plongea)) 152\n",
      "(PP-P_OBJ.O 153\n",
      "(P 154\n",
      "12=dans) 153\n",
      "(NP 154\n",
      "(DET 155\n",
      "13=la) 154\n",
      "(NC 155\n",
      "14=contemplation) 154\n",
      "(PP 155\n",
      "(P 156\n",
      "15=de) 155\n",
      "(NP 156\n",
      "(DET 157\n",
      "16=son) 156\n",
      "(NC 157\n",
      "17=trésor))))))) 150\n",
      ")\n",
      "(SENT 151\n",
      "(VN 152\n",
      "(CLS-SUJ 153\n",
      "0=Vous) 152\n",
      "(V 153\n",
      "1=imaginez)) 151\n",
      "(Ssub-OBJ 152\n",
      "(ADVWH 153\n",
      "2=combien) 152\n",
      "(VN 153\n",
      "(CLS-SUJ 154\n",
      "3=j') 153\n",
      "(V 154\n",
      "4=avais) 153\n",
      "(VPP 154\n",
      "5=pu)) 152\n",
      "(VPinf-OBJ 153\n",
      "(VN 154\n",
      "(VINF 155\n",
      "6=être) 154\n",
      "(VPP 155\n",
      "7=intrigué)) 153\n",
      "(PP-P_OBJ.AGT 154\n",
      "(P 155\n",
      "8=par) 154\n",
      "(NP 155\n",
      "(DET 156\n",
      "9=cette) 155\n",
      "(ADJ 156\n",
      "10=demi) 155\n",
      "(NC 156\n",
      "11=confidence) 155\n",
      "(PP 156\n",
      "(P 157\n",
      "12=sur) 156\n",
      "(NP 157\n",
      "(DET 158\n",
      "13=les) 157\n",
      "(ADJ 158\n",
      "14=autres) 157\n",
      "(NC 158\n",
      "15=planètes))))))) 151\n",
      ")\n",
      "(SENT 152\n",
      "(VN 153\n",
      "(CLS-SUJ 154\n",
      "0=Je) 153\n",
      "(CLR 154\n",
      "1=m') 153\n",
      "(V 154\n",
      "2=efforçai)) 152\n",
      "(ADV 153\n",
      "3=donc) 152\n",
      "(PP-DE_OBJ 153\n",
      "(P 154\n",
      "4=d') 153\n",
      "(VPinf 154\n",
      "(VN 155\n",
      "(CLO 156\n",
      "5=en) 155\n",
      "(VINF 156\n",
      "6=savoir)) 154\n",
      "(AP-MOD 155\n",
      "(ADV 156\n",
      "7=plus) 155\n",
      "(ADJ 156\n",
      "8=long)))) 152\n",
      ")\n",
      "(SENT 153\n",
      "(PP-P_OBJ.DLOC 154\n",
      "(P 155\n",
      "0=d') 154\n",
      "(ADVWH 155\n",
      "1=où)) 153\n",
      "(VN 154\n",
      "(V 155\n",
      "2=viens) 154\n",
      "(CLS-SUJ 155\n",
      "3=tu)) 153\n",
      " 153\n",
      "(NP-MOD 154\n",
      "(DET 155\n",
      "5=mon) 154\n",
      "(ADJ 155\n",
      "6=petit) 154\n",
      "(NC 155\n",
      "7=bonhomme)) 153\n",
      ")\n",
      "(SENT 154\n",
      "(ADVWH-P_OBJ.LOC 155\n",
      "0=Où) 154\n",
      "(VN 155\n",
      "(V 156\n",
      "1=est) 155\n",
      "(CLS-SUJ 156\n",
      "2=ce)) 154\n",
      "(PP-MOD.LOC 155\n",
      "(P 156\n",
      "3=chez) 155\n",
      "(NP 156\n",
      "(PRO 157\n",
      "4=toi))) 154\n",
      ")\n",
      "(SENT 155\n",
      "(VPinf-OBJ 156\n",
      "(ADVWH-MOD.LOC 157\n",
      "0=Où) 156\n",
      "(VN 157\n",
      "(VINF 158\n",
      "3=emporter)) 156\n",
      "(NP-OBJ 157\n",
      "(DET 158\n",
      "4=mon) 157\n",
      "(NC 158\n",
      "5=mouton))) 155\n",
      "(VN 156\n",
      "(V 157\n",
      "1=veux) 156\n",
      "(CLS-SUJ 157\n",
      "2=tu)) 155\n",
      ")\n",
      "(SENT 156\n",
      "(VN 157\n",
      "(CLS-SUJ 158\n",
      "0=Il) 157\n",
      "(CLO-A_OBJ 158\n",
      "1=me) 157\n",
      "(V 158\n",
      "2=répondit)) 156\n",
      "(PP-MOD 157\n",
      "(P 158\n",
      "3=après) 157\n",
      "(NP 158\n",
      "(DET 159\n",
      "4=un) 158\n",
      "(NC 159\n",
      "5=silence) 158\n",
      "(AP 159\n",
      "(ADJ 160\n",
      "6=méditatif)))) 156\n",
      ")\n",
      "(SENT 157\n",
      "(PRO 158\n",
      "0=ce) 157\n",
      "(Srel 158\n",
      "(NP-SUJ 159\n",
      "(PROREL 160\n",
      "1=qui)) 158\n",
      "(VN 159\n",
      "(V 160\n",
      "2=est)) 158\n",
      "(ADV 159\n",
      "3=bien)) 157\n",
      " 157\n",
      "(PP-MOD 158\n",
      "(P 159\n",
      "5=avec) 158\n",
      "(NP 159\n",
      "(DET 160\n",
      "6=la) 159\n",
      "(NC 160\n",
      "7=caisse) 159\n",
      "(Srel 160\n",
      "(NP-OBJ 161\n",
      "(PROREL 162\n",
      "8=que)) 160\n",
      "(VN 161\n",
      "(CLS-SUJ 162\n",
      "9=tu) 161\n",
      "(CLO-A_OBJ 162\n",
      "10=m') 161\n",
      "(V 162\n",
      "11=as) 161\n",
      "(VPP 162\n",
      "12=donnée))))) 157\n",
      " 157\n",
      "(VN 158\n",
      "(CLS-SUJ 159\n",
      "14=c') 158\n",
      "(V 159\n",
      "15=est)) 157\n",
      "(Ssub-ATS 158\n",
      "(CS 159\n",
      "16=que) 158\n",
      "(Sint 159\n",
      " 159\n",
      "(NP-MOD 160\n",
      "(DET 161\n",
      "18=la) 160\n",
      "(NC 161\n",
      "19=nuit)) 159\n",
      " 159\n",
      "(NP-SUJ 160\n",
      "(PRO 161\n",
      "21=ça)) 159\n",
      "(VN 160\n",
      "(CLO-A_OBJ 161\n",
      "22=lui) 160\n",
      "(V 161\n",
      "23=servira)) 159\n",
      "(PP-DE_OBJ 160\n",
      "(P 161\n",
      "24=de) 160\n",
      "(NP 161\n",
      "(NC 162\n",
      "25=maison))))) 157\n",
      ")\n",
      "(SENT 158\n",
      "(ADV+ 159\n",
      "(ADV 160\n",
      "0=bien) 159\n",
      "(ADJ 160\n",
      "1=sûr)) 158\n",
      ")\n",
      "(SENT 159\n",
      "(COORD 160\n",
      "(CC 161\n",
      "0=Et) 160\n",
      "(Sint 161\n",
      "(Ssub-MOD 162\n",
      "(CS 163\n",
      "1=si) 162\n",
      "(Sint 163\n",
      "(VN 164\n",
      "(CLS-SUJ 165\n",
      "2=tu) 164\n",
      "(V 165\n",
      "3=es)) 163\n",
      "(AP-ATS 164\n",
      "(ADJ 165\n",
      "4=gentil)))) 161\n",
      " 161\n",
      "(VN 162\n",
      "(CLS-SUJ 163\n",
      "6=je) 162\n",
      "(CLO-A_OBJ 163\n",
      "7=te) 162\n",
      "(V 163\n",
      "8=donnerai)) 161\n",
      "(ADV 162\n",
      "9=aussi) 161\n",
      "(NP-OBJ 162\n",
      "(DET 163\n",
      "10=une) 162\n",
      "(NC 163\n",
      "11=corde) 162\n",
      "(PP 163\n",
      "(P 164\n",
      "12=pour) 163\n",
      "(VPinf 164\n",
      "(VN 165\n",
      "(CLO-OBJ 166\n",
      "13=l') 165\n",
      "(VINF 166\n",
      "14=attacher)) 164\n",
      "(PP-MOD 165\n",
      "(P 166\n",
      "15=pendant) 165\n",
      "(NP 166\n",
      "(DET 167\n",
      "16=le) 166\n",
      "(NC 167\n",
      "17=jour)))))))) 159\n",
      ")\n",
      "(SENT 160\n",
      "(CC 161\n",
      "0=Et) 160\n",
      "(NP 161\n",
      "(DET 162\n",
      "1=un) 161\n",
      "(NC 162\n",
      "2=piquet)) 160\n",
      ")\n",
      "(SENT 161\n",
      "(NP-SUJ 162\n",
      "(DET 163\n",
      "0=La) 162\n",
      "(NC 163\n",
      "1=proposition)) 161\n",
      "(VN 162\n",
      "(V 163\n",
      "2=parut)) 161\n",
      "(VPinf-ATS 162\n",
      "(VN 163\n",
      "(VINF 164\n",
      "3=choquer)) 162\n",
      "(NP-OBJ 163\n",
      "(DET 164\n",
      "4=le) 163\n",
      "(ADJ 164\n",
      "5=petit) 163\n",
      "(NC 164\n",
      "6=prince))) 161\n",
      ")\n",
      "(SENT 162\n",
      "(VPinf 163\n",
      "(VN 164\n",
      "(CLO-OBJ 165\n",
      "0=l') 164\n",
      "(VINF 165\n",
      "1=attacher))) 162\n",
      ")\n",
      "(SENT 163\n",
      "(NP 164\n",
      "(DET 165\n",
      "0=Quelle) 164\n",
      "(ADJ 165\n",
      "1=drôle) 164\n",
      "(P 165\n",
      "2=d') 164\n",
      "(NC 165\n",
      "3=idée)) 163\n",
      ")\n",
      "(SENT 164\n",
      "(COORD 165\n",
      "(CC 166\n",
      "0=mais) 165\n",
      "(Sint 166\n",
      "(Ssub-MOD 167\n",
      "(CS 168\n",
      "1=si) 167\n",
      "(Sint 168\n",
      "(VN 169\n",
      "(CLS-SUJ 170\n",
      "2=tu) 169\n",
      "(ADV 170\n",
      "3=ne) 169\n",
      "(CLO-OBJ 170\n",
      "4=l') 169\n",
      "(V 170\n",
      "5=attaches)) 168\n",
      "(ADV 169\n",
      "6=pas))) 166\n",
      " 166\n",
      "(VN 167\n",
      "(CLS-SUJ 168\n",
      "8=il) 167\n",
      "(V 168\n",
      "9=ira)) 166\n",
      "(ADV+ 167\n",
      "(ADV 168\n",
      "10=n') 167\n",
      "(V 168\n",
      "11=importe) 167\n",
      "(ADV 168\n",
      "12=où)) 166\n",
      " 166\n",
      "(COORD 167\n",
      "(CC 168\n",
      "14=et) 167\n",
      "(Sint 168\n",
      "(VN 169\n",
      "(CLS-SUJ 170\n",
      "15=il) 169\n",
      "(CLR-OBJ 170\n",
      "16=se) 169\n",
      "(V 170\n",
      "17=perdra)))))) 164\n",
      ")\n",
      "(SENT 165\n",
      "(COORD 166\n",
      "(CC 167\n",
      "0=Et) 166\n",
      "(Sint 167\n",
      "(NP-SUJ 168\n",
      "(DET 169\n",
      "1=mon) 168\n",
      "(NC 169\n",
      "2=ami)) 167\n",
      "(VN 168\n",
      "(V 169\n",
      "3=eut)) 167\n",
      "(NP-OBJ 168\n",
      "(DET 169\n",
      "4=un) 168\n",
      "(ADJ 169\n",
      "5=nouvel) 168\n",
      "(NC+ 169\n",
      "(NC 170\n",
      "6=éclat) 169\n",
      "(P 170\n",
      "7=de) 169\n",
      "(NC 170\n",
      "8=rire))))) 165\n",
      ")\n",
      "(SENT 166\n",
      "(COORD 167\n",
      "(CC 168\n",
      "0=mais) 167\n",
      "(Sint 168\n",
      "(ADVWH 169\n",
      "1=où) 168\n",
      "(VN 169\n",
      "(V 170\n",
      "2=veux) 169\n",
      "(CLS-SUJ 170\n",
      "3=tu)) 168\n",
      "(Ssub-OBJ 169\n",
      "(CS 170\n",
      "4=qu') 169\n",
      "(Sint 170\n",
      "(VN 171\n",
      "(CLS-SUJ 172\n",
      "5=il) 171\n",
      "(VS 172\n",
      "6=aille)))))) 166\n",
      ")\n",
      "(SENT 167\n",
      "(ADV+ 168\n",
      "(ADV 169\n",
      "0=n') 168\n",
      "(V 169\n",
      "1=importe) 168\n",
      "(PRO 169\n",
      "2=où)) 167\n",
      ")\n",
      "(SENT 168\n",
      "(AP 169\n",
      "(ADJ 170\n",
      "0=Droit) 169\n",
      "(PP 170\n",
      "(P 171\n",
      "1=devant) 170\n",
      "(NP 171\n",
      "(PRO 172\n",
      "2=lui)))) 168\n",
      ")\n",
      "(SENT 169\n",
      "(ADV 170\n",
      "0=Alors) 169\n",
      "(NP-SUJ 170\n",
      "(DET 171\n",
      "1=le) 170\n",
      "(ADJ 171\n",
      "2=petit) 170\n",
      "(NC 171\n",
      "3=prince)) 169\n",
      "(VN 170\n",
      "(V 171\n",
      "4=remarqua)) 169\n",
      "(ADV 170\n",
      "5=gravement) 169\n",
      ")\n",
      "(SENT 170\n",
      "(NP-SUJ 171\n",
      "(PRO 172\n",
      "0=ça)) 170\n",
      "(VN 171\n",
      "(ADV 172\n",
      "1=ne) 171\n",
      "(V 172\n",
      "2=fait)) 170\n",
      "(NP-OBJ 171\n",
      "(PRO 172\n",
      "3=rien)) 170\n",
      " 170\n",
      "(Sint-MOD 171\n",
      "(VN 172\n",
      "(CLS-SUJ 173\n",
      "5=c') 172\n",
      "(V 173\n",
      "6=est)) 171\n",
      "(AP-ATS 172\n",
      "(ADV 173\n",
      "7=tellement) 172\n",
      "(ADJ 173\n",
      "8=petit)) 171\n",
      " 171\n",
      "(PP-MOD 172\n",
      "(P 173\n",
      "10=chez) 172\n",
      "(NP 173\n",
      "(PRO 174\n",
      "11=moi!)))))\n",
      "(SENT 175\n",
      "(COORD 176\n",
      "(CC 177\n",
      "0=Et) 176\n",
      "(Sint 177\n",
      " 177\n",
      "(PP-MOD 178\n",
      "(P 179\n",
      "2=avec) 178\n",
      "(NP 179\n",
      "(ADV+ 180\n",
      "(DET 181\n",
      "3=un) 180\n",
      "(ADV 181\n",
      "4=peu)) 179\n",
      "(P 180\n",
      "5=de) 179\n",
      "(NC 180\n",
      "6=mélancolie))) 177\n",
      " 177\n",
      "(ADV+ 178\n",
      "(V 179\n",
      "8=peut) 178\n",
      "(VINF 179\n",
      "9=être)) 177\n",
      " 177\n",
      "(VN 178\n",
      "(CLS-SUJ 179\n",
      "11=il) 178\n",
      "(V 179\n",
      "12=ajouta)))) 175\n",
      ")\n",
      "(SENT 176\n",
      "(AP-MOD 177\n",
      "(ADJ 178\n",
      "0=droit) 177\n",
      "(PP 178\n",
      "(P 179\n",
      "1=devant) 178\n",
      "(NP 179\n",
      "(PRO 180\n",
      "2=soi)))) 176\n",
      "(VN 177\n",
      "(CLS-SUJ 178\n",
      "3=on) 177\n",
      "(ADV 178\n",
      "4=ne) 177\n",
      "(V 178\n",
      "5=peut)) 176\n",
      "(ADV 177\n",
      "6=pas) 176\n",
      "(VPinf-OBJ 177\n",
      "(VN 178\n",
      "(VINF 179\n",
      "7=aller)) 177\n",
      "(AdP-MOD 178\n",
      "(ADV 179\n",
      "8=bien) 178\n",
      "(ADV 179\n",
      "9=loin))) 176\n",
      ")\n",
      " 175\n"
     ]
    }
   ],
   "source": [
    " with open(f\"/home/co/code/data/syntax_new_untested/run1_v2_0.25_0.5-tokenized.syntax.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Define the pattern to match substrings like (PONCT 3=,)\n",
    "pattern = r'\\(PONCT\\s\\d+[^)]*\\)'\n",
    "# Remove the substrings using re.sub()\n",
    "clean_text = re.sub(pattern, '', text)\n",
    "count_ouvr = 0\n",
    "with readfor tok in clean_text.split(' '):\n",
    "    if tok.__contains__('('):\n",
    "        count_ouvr+=1*tok.count('(')\n",
    "    elif tok.__contains__(')'):\n",
    "        count_ouvr-=1*tok.count(')')\n",
    "    print(tok,count_ouvr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572b284",
   "metadata": {},
   "source": [
    "### 0.5\n",
    "\n",
    "Just the evoked, for all conditions, all subjects:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb924f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It is currently being done by keeping all the epochs in memory: might want to do like in the #1, and generate the evo\n",
    "# or score from the epochs (for a subject), and from there try\n",
    "# To find a way to, starting with an array of evoked, average them!!!\n",
    "from dataset import read_raw, get_subjects, get_path, mne_events\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "# Dict init\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            dict_epochs[epoch_key] = [] \n",
    "            \n",
    "for subject in subjects[2:5]:\n",
    "    all_epochs = []\n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "\n",
    "        # Word end\n",
    "        meta['word_offset'] = True\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Sent stop\n",
    "        meta['next_word_id'] = meta['word_id'].shift(-1)\n",
    "        meta['sentence_offset'] = meta.apply(lambda x: True if x['word_id'] > x['next_word_id'] else False, axis=1)\n",
    "        meta['sentence_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_word_id', axis=1, inplace=True)\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: True if x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1 else False, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "\n",
    "        # Const stop\n",
    "        meta['next_closing'] = meta['n_closing'].shift(-1)\n",
    "        meta['constituent_offset'] = meta.apply(lambda x: True if x['n_closing'] > x['next_closing'] else False, axis=1)\n",
    "        meta['constituent_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_closing', axis=1, inplace=True)\n",
    "\n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            for level in ('sentence', 'constituent', 'word'):\n",
    "                # Select only the rows containing the True for the conditions (sentence_end, etc..)\n",
    "                sel = meta.query(f'{level}_{start}==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw), decim = 10,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop',\n",
    "                                            preload=True)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "            \n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "\n",
    "# Once we have the dict of epochs per condition full, we can concatenate them, and fix the dev_head             \n",
    "for start_ in ('onset', 'offset'): \n",
    "    for level_ in ('word', 'constituent', 'sentence'):\n",
    "        epoch_key = f'{level_}_{start_}'\n",
    "        all_epochs_chosen = dict_epochs[epoch_key]\n",
    "        # Concatenate epochs\n",
    "        for epo in all_epochs_chosen:\n",
    "            epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "        dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "            \n",
    "dict_evos = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "# Dict init\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            dict_evos[epoch_key] = [] \n",
    "\n",
    "# Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):  \n",
    "            epoch_key = f'{level}_{start}'\n",
    "            epochs = dict_epochs[epoch_key]\n",
    "            # mean\n",
    "            evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "            dict_evos[epoch_key] = evo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740163c2",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e5db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for level in ('word', 'constituent', 'sentence'):\n",
    "    for start in ('onset', 'offset'):        \n",
    "            epoch_key = f'{level}_{start}'\n",
    "            print(f\"Plotting for: {epoch_key}\")\n",
    "            dict_evos[epoch_key].plot(gfp=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb01a54",
   "metadata": {},
   "source": [
    "### #1\n",
    "First plot: 3x2 plot, that shows:\n",
    "- From the onset, and offset of {word, constituent, sentence}:\n",
    "\n",
    "The evoked potential linked to it, as well as the decoding of the word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38245f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mne_events(meta, raw, start, level):\n",
    "    if start=='onset':\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = meta.start * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "    elif start=='offset':\n",
    "        \"\"\"\n",
    "        It should generalize, no need for different cases?\n",
    "        if level == 'word':\n",
    "            events = np.ones((len(meta), 3), dtype=int)\n",
    "            events[:, 0] = (meta.start+meta.duration) * raw.info[\"sfreq\"]\n",
    "            return dict(events=events, metadata=meta.reset_index())\n",
    "        elif level == 'sentence':\n",
    "            events = np.ones((len(meta), 3), dtype=int)\n",
    "            events[:, 0] = (meta.start+meta.duration) * raw.info[\"sfreq\"]\n",
    "            return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "        else:\n",
    "            print('hi')\n",
    "            # Fill\n",
    "        \"\"\"\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = (meta.start+meta.duration) * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "        \n",
    "    else:\n",
    "        print('start should be either onset or offset')\n",
    "        return 0\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15915c86",
   "metadata": {},
   "source": [
    "# Test on words offset only # Done\n",
    "\n",
    "# Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6135d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/utils.py\u001b[0m(262)\u001b[0;36madd_syntax\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    260 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m    \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynt_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 262 \u001b[0;31m    \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    264 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_closing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XXX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(synt_tokens)\n",
      "1181\n",
      "ipdb> len(meta_tokens)\n",
      "1465\n",
      "ipdb> synt_tokens\n",
      "array(['lorsque', 'j', '', ..., 'aller', 'bien', 'loin'], dtype=object)\n",
      "ipdb> synt_tokens[:20]\n",
      "array(['lorsque', 'j', '', 'avais', 'six', 'ans', 'ça', 'représentait',\n",
      "       'un', 'serpent', 'boa', 'qui', 'avalait', 'un', 'fauve', 'voilà',\n",
      "       'la', 'copie', 'du', 'dessin'], dtype=object)\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fb212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "levels = ('word','constituent','sentence')\n",
    "starts = ('onset', 'offset')\n",
    "            \n",
    "for subject in subjects[2:6]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max() # TO Verify!\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max() # TO Verify!\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "\n",
    "        for start in starts: \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            # for level in ('sentence', 'constituent', 'word'):\n",
    "            for level in levels:\n",
    "                \n",
    "                # Select only the rows containing the True for the conditions\n",
    "                # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "                sel = meta.query(f'{level}_onset==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                # Making sure there is not hidden bug when matching\n",
    "                assert sel.shape[0] > 0.8 *  (meta.query(f'{level}_onset==True')).shape[0]\n",
    "\n",
    "                # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "                # Function will epoch on the offset of each level instead of the onset\n",
    "                # TODO: add adaptative baseline\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop', # check event repeated\n",
    "                                            preload=True,\n",
    "                                                baseline=None)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "\n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in starts: \n",
    "        for level_ in levels:\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "\n",
    "    # Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "    for start in starts: \n",
    "        for level in levels:\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            epochs = dict_epochs[epoch_key]\n",
    "            # mean\n",
    "            evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "            all_evos.append(dict(subject=subject, evo=evo, start=start, level=level))\n",
    "\n",
    "\n",
    "            # decoding word emb\n",
    "            epochs = epochs.load_data().pick_types(meg=True, stim=False, misc=False)\n",
    "            X = epochs.get_data()\n",
    "            embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "            embeddings = np.array([emb for emb in embeddings])\n",
    "            R_vec = decod_xy(X, embeddings)\n",
    "            scores = np.mean(R_vec, axis=1)\n",
    "\n",
    "            for t, score in enumerate(scores):\n",
    "                all_scores.append(dict(subject=subject, score=score, start=start, level=level, t=epochs.times[t]))\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "all_evos = pd.DataFrame(all_evos)\n",
    "\n",
    "all_scores.to_csv('./score.csv')\n",
    "all_evos.to_csv('./evos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e983491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(all_scores)\n",
    "all_evos = pd.DataFrame(all_evos)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(16, 10), dpi=80)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2)\n",
    "\n",
    "for axes_, level in zip( axes, levels):  \n",
    "    for ax, start in zip( axes_, starts):  \n",
    "        cond1 = all_scores.level==f'{level}'\n",
    "        cond2 = all_scores.start==f'{start}'\n",
    "        data = all_scores[ cond1 & cond2]\n",
    "        y = []\n",
    "        x = []\n",
    "        for s, t in data.groupby('t'):\n",
    "            score_avg = t.score.mean()\n",
    "            y.append(score_avg)\n",
    "            x.append(s)\n",
    "\n",
    "        ax.plot(x,y)\n",
    "        ax.set_title(f'{level} {start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67755eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel[['word','start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11151285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "\n",
    "            \n",
    "for subject in subjects[2]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,2):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max()\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max()\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "        print(meta.head(50))\n",
    "        \n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            # for level in ('sentence', 'constituent', 'word'):\n",
    "            level = 'word'\n",
    "                \n",
    "            # Select only the rows containing the True for the conditions\n",
    "            # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "            sel = meta.query(f'{level}_onset==True')\n",
    "            assert sel.shape[0] > 10  #\n",
    "            # TODO check variance as well for sentences\n",
    "            # Matchlist events and meta\n",
    "            # So that we can epoch now that's we've sliced our metadata\n",
    "            i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "            sel = sel.reset_index().loc[j]\n",
    "            # Making sure there is not hidden bug when matching\n",
    "            assert sel.shape[0] > 0.8 *  (meta.query(f'{level}_onset==True')).shape[0]\n",
    "\n",
    "            # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "            # Function will epoch on the offset of each level instead of the onset\n",
    "            # TODO: add adaptative baseline\n",
    "            epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                 tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                   tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                     event_repeated = 'drop', # check event repeated\n",
    "                                        preload=True,\n",
    "                                            baseline=None)  # n_words OR n_constitutent OR n_sentences\n",
    "            epoch_key = f'{level}_{start}'\n",
    "\n",
    "            dict_epochs[epoch_key].append(epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9906493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs.copy().pick_types(meg=True).average(method='median').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed860c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import read_raw, get_subjects, get_path, mne_events\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "\n",
    "            \n",
    "for subject in subjects[2:10]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: True if x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1 else False, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sequence\n",
    "        meta['sequence_id'] = np.cumsum(meta.is_last_word.shift(1, fill_value=False))\n",
    "        for s, d in meta.groupby('sequence_id'):\n",
    "            meta.loc[d.index, 'word_id'] = range(len(d))\n",
    "        \n",
    "\n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            for level in ('sentence', 'constituent', 'word'):\n",
    "                # Select only the rows containing the True for the conditions (sentence_end, etc..)\n",
    "                sel = meta.query(f'{level}_{start}==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw), decim = 100,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop', # check event repeated\n",
    "                                            preload=True)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "            \n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "        \n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in ('onset', 'offset'): \n",
    "        for level_ in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "\n",
    "    # Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):  \n",
    "                epoch_key = f'{level}_{start}'\n",
    "                epochs = dict_epochs[epoch_key]\n",
    "                # mean\n",
    "                evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "                all_evos.append(dict(subject=subject, evo=evo, start=start, level=level))\n",
    "\n",
    "\n",
    "                # decoding word emb\n",
    "                epochs = epochs.load_data().pick_types(meg=True, stim=False, misc=False)\n",
    "                X = epochs.get_data()\n",
    "                embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "                embeddings = np.array([emb for emb in embeddings])\n",
    "                R_vec = decod_xy(X, embeddings)\n",
    "                scores = np.mean(R_vec, axis=1)\n",
    "\n",
    "                for t, score in enumerate(scores):\n",
    "                    all_scores.append(dict(subject=subject, score=score, start=start, level=level, t=epochs.times[t]))\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores,index=False)\n",
    "all_evos = pd.DataFrame(all_evos,index=False)\n",
    "\n",
    "all_scores.to_csv('./score.csv')\n",
    "all_evos.to_csv('./evos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(all_scores)\n",
    "all_evos = pd.DataFrame(all_evos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.query('level==\"sentence\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9e041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(16, 10), dpi=80)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2)\n",
    "\n",
    "for axes_, level in zip(axes, ('word', 'constituent', 'sentence')):\n",
    "    for ax, start in zip( axes_, ('onset', 'offset')):  \n",
    "        cond1 = all_scores.level==f'{level}'\n",
    "        cond2 = all_scores.start==f'{start}'\n",
    "        data = all_scores[ cond1 & cond2]\n",
    "        print(data.shape)\n",
    "        x = data['t']\n",
    "        y = data['score']\n",
    "        \n",
    "        ax.plot(x,y)\n",
    "        ax.set_title(f'{level} {start}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd270ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67f9be",
   "metadata": {},
   "source": [
    "###  #3\n",
    "Now the same idea, but iterating on the targeted decoding: {word embedding, sentence embedding, etc..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34178be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b72a766",
   "metadata": {},
   "source": [
    "### #4 \n",
    "Now baselined on offset, no matter whether it's on onset or offset window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c77b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824fb580",
   "metadata": {},
   "source": [
    "### #5 \n",
    "Submitit-compatible version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1494a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install submitit\n",
    "import submitit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621358ab",
   "metadata": {},
   "source": [
    "# Jitter test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3507de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_bids\n",
    "import mne\n",
    "from pathlib import Path\n",
    "subject = '5'\n",
    "run_id = 1\n",
    "path = get_path(\"LPP_read\")\n",
    "task = \"read\"\n",
    "print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "events_  = events[:,0] / raw.info[\"sfreq\"]\n",
    "diffs = np.diff(events_)\n",
    "x,y = np.unique(diffs, return_counts=True)\n",
    "plt.plot(x,y)\n",
    "plt.xlim([0.2,0.3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa654f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.copy().pick_types(meg=False, stim=True).plot(start=50, duration=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566943",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel=\"STI002\", shortest_event=1)\n",
    "events_  = events[:,0] / raw.info[\"sfreq\"]\n",
    "diffs = np.diff(events_)\n",
    "x,y = np.unique(diffs, return_counts=True)\n",
    "plt.plot(x,y)\n",
    "plt.xlim([0.2,0.4])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "meta = epochs.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb0fef",
   "metadata": {},
   "source": [
    "# Testing decoding more and more difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import word_epochs_debug, get_path, get_subjects, sentence_epochs_debug\n",
    "from utils import decod\n",
    "from plot import plot_R\n",
    "import mne\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "subjects = subjects[:2]\n",
    "\n",
    "# WORDS\n",
    "all_epochs = []\n",
    "for sub in subjects:\n",
    "\n",
    "    epochs = sentence_epochs_debug(sub, 3)\n",
    "    all_epochs.append(epochs)\n",
    "\n",
    "for epo in all_epochs:\n",
    "    epo.info[\"dev_head_t\"] = all_epochs[1].info[\"dev_head_t\"]\n",
    "\n",
    "epochs = mne.concatenate_epochs(all_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "from utils import correlate\n",
    "\n",
    "def decod(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    # define data\n",
    "    model = make_pipeline(StandardScaler(), RidgeCV(alphas=np.logspace(-1, 6, 10)))\n",
    "    cv = KFold(15, shuffle=True, random_state=0)\n",
    "\n",
    "    # fit predict\n",
    "    n, n_chans, n_times = X.shape\n",
    "    if y.ndim == 1:\n",
    "        y = np.asarray(y).reshape(y.shape[0], 1)\n",
    "    R = np.zeros((n_times, y.shape[1]))\n",
    "\n",
    "    for t in range(n_times):\n",
    "        print(\".\", end=\"\")\n",
    "        rs = []\n",
    "        # y_pred = cross_val_predict(model, X[:, :, t], y, cv=cv)\n",
    "        for train, test in cv.split(X):\n",
    "            model.fit(X[train, :, t], y[train])\n",
    "            y_pred = model.predict(X[test, :, t])\n",
    "            r = correlate(y[test], y_pred)\n",
    "            rs.append(r)\n",
    "        R[t] = np.mean(rs)\n",
    "        # R[t] = correlate(y, y_pred)\n",
    "\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d520c21",
   "metadata": {},
   "source": [
    "# LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54996ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_code_path\n",
    "\n",
    "run_id = 1\n",
    "CHAPTERS = {\n",
    "1: \"1-3\",\n",
    "2: \"4-6\",\n",
    "3: \"7-9\",\n",
    "4: \"10-12\",\n",
    "5: \"13-14\",\n",
    "6: \"15-19\",\n",
    "7: \"20-22\",\n",
    "8: \"23-25\",\n",
    "9: \"26-27\",\n",
    "}\n",
    "\n",
    "meta = epochs.metadata\n",
    "\n",
    "# # laser embeddings information\n",
    "dim = 1024\n",
    "embeds = np.fromfile(\n",
    "    f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "    dtype=np.float32,\n",
    "    count=-1,\n",
    ")\n",
    "embeds.resize(embeds.shape[0] // dim, dim)\n",
    "print(meta.shape[0])\n",
    "embeds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23935db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = epochs[]\n",
    "X = epochs.get_data()\n",
    "y = epochs.metadata.word.apply(len)\n",
    "R_vec = decod(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0203d6",
   "metadata": {},
   "source": [
    "## Word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the STIM information before decoding it (or else we'll get a 100% accuracy since the word length info is in the STIM channels)\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "X = epochs.get_data()\n",
    "y = epochs.metadata.word.apply(len)\n",
    "R_vec = decod(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f798f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_R(R_vec.reshape(-1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf385dc",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becba2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "X = epochs.get_data()\n",
    "embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "embeddings = np.array([emb for emb in embeddings])\n",
    "R_vec = decod(X, embeddings)\n",
    "R_vec = np.mean(R_vec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_R(R_vec.reshape(-1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799fbc7",
   "metadata": {},
   "source": [
    "## Laser embeddings with JR baseline fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29290403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_stop_data.shape\n",
    "baseline_starts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_starts = epochs['word_id==0'].apply_baseline((-.300, 0.))\n",
    "sent_starts.average().plot()\n",
    "\n",
    "sent_stops = epochs['is_last_word']\n",
    "bsl = (epochs.times>-.300 )*(epochs.times<=0)\n",
    "baseline_starts = sent_starts.get_data()[:, :, bsl].mean(-2)\n",
    "\n",
    "sent_stop_data = sent_stops.get_data()\n",
    "n_sentences, n_channels, n_times = sent_stop_data.shape\n",
    "sent_stop_data -= baseline_starts[:, :, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c02e3a",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ce669",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metaepochs.metadata.word.apply(len)\n",
    "decoding_criterion = \"n_closing\"\n",
    "R_vec = decod(epochs, decoding_criterion)\n",
    "\n",
    "fig = plot_R(R_vec)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb3d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce49ba49",
   "metadata": {},
   "source": [
    "# Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, word_epochs, sentence_epochs\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import mne\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "mne.set_log_level(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = mne.Report()\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "evos = []\n",
    "\n",
    "# WORDS\n",
    "subjects = subjects[2]\n",
    "epochs = word_epochs(subjects)\n",
    "\n",
    "evo = epochs.average(method=\"median\")\n",
    "evos.append(evo)\n",
    "evo.plot(spatial_colors=True)\n",
    "report.add_evokeds(evo, titles=f\"Evoked for condition word  \")\n",
    "\n",
    "\n",
    "# SENTENCES\n",
    "epochs = sentence_epochs(subjects)\n",
    "\n",
    "evo = epochs.average(method=\"median\")\n",
    "evos.append(evo)\n",
    "evo.plot(spatial_colors=True)\n",
    "report.add_evokeds(evo, titles=f\"Evoked for condition sentence  \")\n",
    "\n",
    "\n",
    "evokeds = dict(sentence=evos[1], word=evos[0])\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\")\n",
    "\n",
    "report.add_figure(fig, title=\"Evoked response comparaison\")\n",
    "\n",
    "\n",
    "report.save(\n",
    "    f\"./figures/{task}_sentvsword_test.html\",\n",
    "    open_browser=False,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc17c75",
   "metadata": {},
   "source": [
    "# Test new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import word_epochs\n",
    "\n",
    "sub = '3'\n",
    "\n",
    "epochs = word_epochs(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca576c",
   "metadata": {},
   "source": [
    "\n",
    "# Debug events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8123ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mne\n",
    "from utils import match_list\n",
    "from dataset import mne_events\n",
    "from utils import add_syntax\n",
    "\n",
    "\n",
    "CHAPTERS = {\n",
    "    1: \"1-3\",\n",
    "    2: \"4-6\",\n",
    "    3: \"7-9\",\n",
    "    4: \"10-12\",\n",
    "    5: \"13-14\",\n",
    "    6: \"15-19\",\n",
    "    7: \"20-22\",\n",
    "    8: \"23-25\",\n",
    "    9: \"26-27\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fd7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "run_id = 1\n",
    "task = \"read\"\n",
    "subject = '3'\n",
    "baseline_min = -2.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "raw.load_data()\n",
    "raw = raw.filter(0.5, 20)\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "# read events\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_copy = meta.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_syntax = get_code_path() / \"data/syntax\"\n",
    "\n",
    "# Enriching the metadata with outside files:\n",
    "meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "\n",
    "# Enriching the metadata with simple operations:\n",
    "\n",
    "# end of sentence information\n",
    "end_of_sentence = [\n",
    "    True\n",
    "    if str(meta.word.iloc[i]).__contains__(\".\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"?\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"!\")\n",
    "    else False\n",
    "    for i, _ in enumerate(meta.values[:-1])\n",
    "]\n",
    "end_of_sentence.append(True)\n",
    "meta[\"sentence_end\"] = end_of_sentence\n",
    "\n",
    "# sentence start information\n",
    "list_word_start = [True]\n",
    "list_word_start_to_add = [\n",
    "    True if meta.sentence_end.iloc[i - 1] else False\n",
    "    for i in np.arange(1, meta.shape[0])\n",
    "]\n",
    "for boolean in list_word_start_to_add:\n",
    "    list_word_start.append(boolean)\n",
    "meta[\"sentence_start\"] = list_word_start\n",
    "\n",
    "# laser embeddings information\n",
    "dim = 1024\n",
    "embeds = np.fromfile(\n",
    "    f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "    dtype=np.float32,\n",
    "    count=-1,\n",
    ")\n",
    "embeds.resize(embeds.shape[0] // dim, dim)\n",
    "assert embeds.shape[0] == meta.shape[0]\n",
    "meta[\"laser\"] = [emb for emb in embeds]\n",
    "\n",
    "# constituent end information\n",
    "meta[\"constituent_end\"] = [\n",
    "        True if closing > 1 else False for i, closing in enumerate(meta.n_closing)]\n",
    "\n",
    "# constituent start information\n",
    "list_constituent_start = [True]\n",
    "list_constituent_start_to_add = [\n",
    "    True if meta.constituent_end.iloc[i - 1] else False\n",
    "    for i in np.arange(1, meta.shape[0])\n",
    "]\n",
    "for boolean in list_constituent_start_to_add:\n",
    "    list_constituent_start.append(boolean)\n",
    "meta[\"constituent_start\"] = list_constituent_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_length_meg = events[:, 2]\n",
    "word_len_meta = meta.word.apply(len)\n",
    "i, j = match_list(word_len_meta, word_length_meg)\n",
    "events = events[j]\n",
    "assert len(i) / meta.shape[0] > 0.8\n",
    "meta = meta.iloc[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c337c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"start\"] = events[:, 0] / raw.info[\"sfreq\"]\n",
    "meta[\"condition\"] = \"sentence\"\n",
    "meta = meta.sort_values(\"start\").reset_index(drop=True)\n",
    "meta[\"word_start\"] = meta[\"start\"]\n",
    "meta[\"word_end\"] = meta[\"word_start\"] + meta[\"duration\"]\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, **mne_events(meta, raw), decim=20, tmin=baseline_min, tmax=baseline_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feec9e4",
   "metadata": {},
   "source": [
    "# Plotting decoding info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743045da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plot import plot_subject\n",
    "\n",
    "from dataset import get_path, get_subjects, get_code_path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"read\"\n",
    "sub = 4\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "min = -4.0\n",
    "max = 0.5\n",
    "decoding_criterion = 'laser'\n",
    "path = get_code_path()\n",
    "# Format the file path\n",
    "\n",
    "# Open the pandas DataFrame containing the decoding values\n",
    "R = np.load(\n",
    "    (path) / f\"decoding/results/{task}/decoding_{decoding_criterion}_{epoch_on}_{reference}_{sub}.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad237f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(min, max, R.shape[0])  # To do better at generalizing\n",
    "fig, ax = plt.subplots(1, figsize=[6, 6])\n",
    "dec = plt.fill_between(times, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"read\"\n",
    "sub = 3\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "min = -4.0\n",
    "max = 0.5\n",
    "decoding_criterion = 'laser'\n",
    "plot = plot_subject(sub, decoding_criterion, task, reference, epoch_on, min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3cdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a76bc3",
   "metadata": {},
   "source": [
    "# Debugging ERP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be218",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "baseline_min = -1.0\n",
    "baseline_max = 1.0\n",
    "task = \"read\"\n",
    "\n",
    "subjects = subjects[10]\n",
    "epochs2 = epoch_subjects(\n",
    "    subjects, RUN, task, path, baseline_max=baseline_max, baseline_min=baseline_min\n",
    ")\n",
    "\n",
    "epochs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044bba4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_subjects, epochs_slice\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "mne.set_log_level(False)\n",
    "\n",
    "# Later: integrate Hydra here as well. For now, just simple plotting of ERPS\n",
    "\n",
    "report = mne.Report()\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "baseline_min = -1.0\n",
    "baseline_max = 1.0\n",
    "task = \"read\"\n",
    "print(\"\\nSubjects for which the plotting will be done: \\n\")\n",
    "print(subjects)\n",
    "\n",
    "# DEBUG\n",
    "subjects = subjects[4]\n",
    "epochs_ = epoch_subjects(\n",
    "    subjects, RUN, task, path, baseline_max=baseline_max, baseline_min=baseline_min\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = [\"sentence\", \"word\", \"constituent\"]\n",
    "cases = {\"start\", \"end\"}\n",
    "\n",
    "# Plotting and adding to the report, the averaged ERPs of:\n",
    "# words, sentences and constituents, centered at the beginning and end of each\n",
    "\n",
    "\n",
    "# Need to map for:\n",
    "# - end of word,\n",
    "# - beginning of sentence (epochs[i+1] !danger limits)\n",
    "# - beginning of constituent (epochs[i+1] !same danger)\n",
    "\n",
    "evos = []\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        # Slice the epochs based on the epoch_criterion:\n",
    "        column_to_slice_on = f\"{condi}_{case}\"\n",
    "        if condi == \"sentence\" or condi == \"word\":  # eg: {sentence}_{end} or {word}_{start}\n",
    "            epochs = epochs_slice(epochs_, column_to_slice_on)\n",
    "        elif condi == \"constituent\":\n",
    "            epochs = epochs_slice(epochs_, column_to_slice_on, value=2, equal='sup')\n",
    "        evo = epochs.average(method=\"median\")\n",
    "        evos.append(evo)\n",
    "        evo.plot(spatial_colors=True)\n",
    "        report.add_evokeds(evo, titles=f\"Evoked for condition {column_to_slice_on}  \")\n",
    "\n",
    "evokeds = dict(sentence=evos[0], word=evos[2], constituent=evos[4])\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\")\n",
    "\n",
    "report.add_figure(fig, title=\"Evoked response comparaison\")\n",
    "\n",
    "\n",
    "report.save(\n",
    "    f\"./figures/{task}_ERP_all_cond.html\",\n",
    "    open_browser=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b61d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0419c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = epochs_slice(epochs_, 'sentence_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ae1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_subject\n",
    "\n",
    "from dataset import get_path, get_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "run = 1\n",
    "task = \"read\"\n",
    "subject = '17'\n",
    "baseline_min = -2.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5143d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06188ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset import epoch_data\n",
    "epo = epoch_data(\n",
    "    subject,\n",
    "    run,\n",
    "    task,\n",
    "    path,\n",
    "    baseline_min,\n",
    "    baseline_max,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54047baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import epochs_slice\n",
    "epos = epochs_slice(epo, 'sentence_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794e34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epos.average(method=\"median\")\n",
    "evo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67a6a0",
   "metadata": {},
   "source": [
    "# GFP for sentence - epoching on sentence end and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_runs\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "\n",
    "# Tools\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "from utils import match_list, add_syntax\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 2\n",
    "task = \"read\"\n",
    "subject = subjects[1]\n",
    "baseline_min = -4.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1bca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(\n",
    "            subject,\n",
    "            RUN,\n",
    "            task,\n",
    "            path,\n",
    "            baseline_min,\n",
    "            baseline_max,\n",
    "            epoch_on=epoch_on,\n",
    "            reference=reference,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa8af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = 1\n",
    "from dataset import epoch_data\n",
    "epo = epoch_data(\n",
    "    subject,\n",
    "    run,\n",
    "    task,\n",
    "    path,\n",
    "    baseline_min=-0.2,\n",
    "    baseline_max=0.8,\n",
    "    filter=True,\n",
    "    epoch_on=\"word\",\n",
    "    reference=\"end\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06639bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = epo.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1596c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_code_path, get_path, mne_events\n",
    "\n",
    "run_id = RUN\n",
    "epoch_on = 'word'\n",
    "reference = \"start\"\n",
    "\n",
    "CHAPTERS = {\n",
    "    1: \"1-3\",\n",
    "    2: \"4-6\",\n",
    "    3: \"7-9\",\n",
    "    4: \"10-12\",\n",
    "    5: \"13-14\",\n",
    "    6: \"15-19\",\n",
    "    7: \"20-22\",\n",
    "    8: \"23-25\",\n",
    "    9: \"26-27\",\n",
    "}\n",
    "\n",
    "\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=RUN,\n",
    "    )\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "raw.load_data()\n",
    "raw = raw.filter(0.5, 20)\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "# read events\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "if (\n",
    "    bids_path.task == \"read\" and bids_path.subject == \"2\"\n",
    "):  # A trigger value bug for this subject\n",
    "    word_length_meg = (\n",
    "        events[:, 2] - 2048\n",
    "    )  # Remove first event: chapter start and remove offset\n",
    "else:\n",
    "    word_length_meg = events[:, 2]\n",
    "# Here, the trigger value encoded the word length\n",
    "# which helps us realign triggers\n",
    "# From the event file / from the MEG events\n",
    "word_len_meta = meta.word.apply(len)\n",
    "i, j = match_list(word_len_meta, word_length_meg)\n",
    "events = events[j]\n",
    "meta = meta.iloc[i].reset_index()\n",
    "print(meta.shape)\n",
    "# The start parameter will help us\n",
    "# keep the link between raw events and metadata\n",
    "meta[\"start\"] = events[:, 0] / raw.info[\"sfreq\"]\n",
    "meta[\"condition\"] = \"sentence\"\n",
    "meta = meta.sort_values(\"start\").reset_index(drop=True)\n",
    "\n",
    "# Raw LPP textual data\n",
    "path_txt = get_code_path() / \"data/txt_raw\"\n",
    "# LPP Syntax data\n",
    "path_syntax = get_code_path() / \"data/syntax\"\n",
    "\n",
    "# Enriching the metadata with outside files:\n",
    "meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "print(meta.shape)\n",
    "# Add the information on the sentence ending:\n",
    "# Only works for reading: TO FIX for listening... to see with Christophe\n",
    "# Also: only works for v2 (subject 1 (me) doesn't work )\n",
    "\n",
    "# Test 1\n",
    "# end_of_sentence = [\n",
    "#     True if meta.onset.iloc[i + 1] - meta.onset.iloc[i] > 0.7 else False\n",
    "#     for i, _ in enumerate(meta.values[:-1])\n",
    "# ]\n",
    "# end_of_sentence.append(True)\n",
    "\n",
    "# Test 2\n",
    "end_of_sentence = [\n",
    "    True\n",
    "    if str(meta.word.iloc[i]).__contains__(\".\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"?\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"!\")\n",
    "    else False\n",
    "    for i, _ in enumerate(meta.values[:-1])\n",
    "]\n",
    "end_of_sentence.append(True)\n",
    "meta[\"sentence_end\"] = end_of_sentence\n",
    "\n",
    "# We are considering different cases:\n",
    "# Are we epoching on words, sentences, or constituents?\n",
    "# Different epoching for different analysis\n",
    "if epoch_on == \"word\" and reference == \"start\":\n",
    "    # Default case, so nothing to change\n",
    "    # Could be removed but kept for easy of reading\n",
    "    happy = True\n",
    "# Word end\n",
    "if epoch_on == \"word\" and reference == \"end\":\n",
    "    # Little hack: not really pretty but does the job\n",
    "    # As epoching again uses the start column, we rename it like that\n",
    "    # But it should be meta[\"end\"] instead...\n",
    "    meta[\"start\"] = [row[\"start\"] + row[\"duration\"] for i, row in meta.iterrows()]\n",
    "\n",
    "# Sentence end\n",
    "elif epoch_on == \"sentence\" and reference == \"end\":\n",
    "    # Add a LASER embeddings column for decoding\n",
    "    dim = 1024\n",
    "    embeds = np.fromfile(\n",
    "        f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "        dtype=np.float32,\n",
    "        count=-1,\n",
    "    )\n",
    "    embeds.resize(embeds.shape[0] // dim, dim)\n",
    "    column = \"sentence_end\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "    # TODO: create a match list between the embeds sentence and the\n",
    "    print(embeds.shape[0], meta.shape[0])\n",
    "    assert embeds.shape[0] == meta.shape[0]\n",
    "    meta[\"laser\"] = [emb for emb in embeds]\n",
    "    print(\"Added embeddings\")\n",
    "# Sentence start\n",
    "elif epoch_on == \"sentence\" and reference == \"start\":\n",
    "    # Create a sentence-start column:\n",
    "    # list_word_start = [\n",
    "    #     True\n",
    "    #     for i, is_last_word in enumerate(meta.is_last_word[:-1])\n",
    "    #     if meta.is_last_word[i + 1]\n",
    "    # ]\n",
    "    list_word_start = [True]\n",
    "    list_word_start_to_add = [\n",
    "        True if meta.sentence_end[i - 1] else False\n",
    "        for i, _ in enumerate(meta.sentence_end[1:])\n",
    "    ]\n",
    "    for boolean in list_word_start_to_add:\n",
    "        list_word_start.append(boolean)\n",
    "    meta[\"sentence_start\"] = list_word_start\n",
    "    column = \"sentence_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "# Constituent start\n",
    "elif epoch_on == \"constituent\" and reference == \"start\":\n",
    "    # Create a constituent-start column:\n",
    "    meta[\"constituent_start\"] = [\n",
    "        True for i, _ in enumerate(meta.is_last_word[1:]) if meta.n_closing > 1\n",
    "    ]\n",
    "    column = \"constituent_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "# Constituent end\n",
    "elif epoch_on == \"constituent\" and reference == \"end\":\n",
    "    # Create a constituent-start column:\n",
    "    meta[\"constituent_start\"] = [\n",
    "        True for i, _ in enumerate(meta.is_last_word[1:]) if meta.n_closing > 1\n",
    "    ]\n",
    "    column = \"constituent_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "epochs = mne.Epochs(\n",
    "    raw, **mne_events(meta, raw), decim=20, tmin=baseline_min, tmax=baseline_max\n",
    ")\n",
    "# epochs = epochs['kind==\"word\"']\n",
    "# epochs.metadata[\"closing\"] = epochs.metadata.closing_.fillna(0)\n",
    "epochs.load_data()\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "data = epochs.get_data()\n",
    "\n",
    "# Scaling the data\n",
    "n_words, n_chans, n_times = data.shape\n",
    "vec = data.transpose(0, 2, 1).reshape(-1, n_chans)\n",
    "scaler = RobustScaler()\n",
    "idx = np.arange(len(vec))\n",
    "np.random.shuffle(idx)\n",
    "vec = scaler.fit(vec[idx[:20_000]]).transform(vec)\n",
    "# To try: sigmas = 7 or 15\n",
    "sigma = 7\n",
    "vec = np.clip(vec, -sigma, sigma)\n",
    "epochs._data[:, :, :] = (\n",
    "    scaler.inverse_transform(vec)\n",
    "    .reshape(n_words, n_times, n_chans)\n",
    "    .transpose(0, 2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad079b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_2 = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "events_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d315880",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbdc744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646dde6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d8b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a609b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995472f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255968bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785eb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c62475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a92e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52e158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685a43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d58005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import decod\n",
    "R_vec = decod(epochs, decoding_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905586b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.fill_between(epochs.times, R_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40765d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f47780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diff(epochs.metadata.onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8eb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e9edd",
   "metadata": {},
   "source": [
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482306bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.round(np.diff(epochs2.metadata.onset),3)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"{val} occurs {count} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.diff(epochs2.metadata.onset)>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cbf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcf368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d44ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f35cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9a8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dae2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_(epochs, column, value):\n",
    "    meta  = epochs.metadata\n",
    "    subset = meta[meta[column]==value].level_0\n",
    "    return epochs[subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs.metadata['n_closing'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69967734",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_(epochs,'is_last_word',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = {'sentence': {'column':'is_last_word','target':True},\n",
    "        'word': {'column':'kind','target':'word'},\n",
    "        'constituent': {'column':'n_closing','target':2}}\n",
    "\n",
    "cases = {'start', 'end'}\n",
    "\n",
    "i = 1\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        ep = epochs_(epochs, cond[condi]['column'], cond[condi]['target'])\n",
    "        ax = fig.add_subplot(3, 2, i)\n",
    "        #ep.average().plot(gfp='only')\n",
    "        evo = ep.average(method=\"median\")\n",
    "        evo.plot(spatial_colors=True)\n",
    "        i = i + 1\n",
    "        ax.set_title(f'Plot {cond}')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217312",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4 = epochs_(epochs, 'n_closing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4.average().plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs\n",
    "\n",
    "class CustomEpochs(Epochs):\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Parse the key into metadata field name and value\n",
    "        field, value = key.split('==')\n",
    "        field = field.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Get the indices of the epochs that match the metadata query\n",
    "        indices = [i for i, metadata in enumerate(self.metadata[field]) if metadata == value]\n",
    "\n",
    "        # Return a new Epochs object containing only the matching epochs\n",
    "        return self.__class__(self._data[indices], self.events[indices], self.event_id,\n",
    "                              tmin=self.tmin, tmax=self.tmax, baseline=self.baseline,\n",
    "                              metadata=self.metadata.iloc[indices], info=self.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs = CustomEpochs(epochs, epochs.events, \"1\", -0.2, 0.8, epochs.baseline, epochs.metadata)\n",
    "\n",
    "# Get all epochs where the 'kind' metadata field is 'word':\n",
    "word_epochs = custom_epochs['kind==word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07344132",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "def mne_events(meta):\n",
    "    events = np.ones((len(meta), 3), dtype=int)\n",
    "    events[:, 0] = meta.start*raw.info['sfreq']\n",
    "    return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "epochs = mne.Epochs(raw, **mne_events(meta), decim=20, tmin=-.2, tmax=1.5, preload=True)\n",
    "epochs = epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data, epoch_runs\n",
    "from utils import (\n",
    "    decod,\n",
    "    correlate,\n",
    "    match_list,\n",
    "    create_target,\n",
    "    analysis,\n",
    "    save_decoding_results,\n",
    ")\n",
    "from plot import plot_subject\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 9\n",
    "task = \"read\"\n",
    "subject = subjects[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856d515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs.metadata).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.load_data()\n",
    "epochs = epochs['kind==\"word\"']\n",
    "epochs[\"content_word == False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9cc25f465bce2bd58662313d1fe29f78ce66d40d6f2798a767eb1052c037478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
