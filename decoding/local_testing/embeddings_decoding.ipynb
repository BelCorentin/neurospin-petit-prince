{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550c03f6",
   "metadata": {},
   "source": [
    "# Decoding through the epoch's window time the sentence / constituent embeddings\n",
    "\n",
    "We:\n",
    "\n",
    "- Calculate the embeddings for each sentence / constituent\n",
    "\n",
    "- Decode it on the epoch window\n",
    "\n",
    "- Plot it for each condition (level / start)\n",
    "\n",
    "\n",
    "Todo: \n",
    "\n",
    "Integrate this:\n",
    "\n",
    "```sent_starts = epochs['word_id==0'].apply_baseline((-.300, 0.))\n",
    "sent_starts.average().plot()\n",
    "\n",
    "sent_stops = epochs['is_last_word']\n",
    "bsl = (epochs.times>-.300 )*(epochs.times<=0)\n",
    "baseline_starts = sent_starts.get_data()[:, :, bsl].mean(-2)\n",
    "\n",
    "sent_stop_data = sent_stops.get_data()\n",
    "n_sentences, n_channels, n_times = sent_stop_data.shape\n",
    "sent_stop_data -= baseline_starts[:, :, None]```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9282312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import read_raw, get_subjects, get_path, add_embeddings\n",
    "from utils import decod_xy, mne_events\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa4b4ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_scores(all_scores):\n",
    "    from matplotlib.pyplot import figure\n",
    "\n",
    "    figure(figsize=(16, 10), dpi=80)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2)\n",
    "\n",
    "    for axes_, level in zip( axes, levels):  \n",
    "        for ax, start in zip( axes_, starts):  \n",
    "            cond1 = all_scores.level==f'{level}'\n",
    "            cond2 = all_scores.start==f'{start}'\n",
    "            data = all_scores[ cond1 & cond2]\n",
    "            y = []\n",
    "            x = []\n",
    "            for s, t in data.groupby('t'):\n",
    "                score_avg = t.score.mean()\n",
    "                y.append(score_avg)\n",
    "                x.append(s)\n",
    "\n",
    "            ax.plot(x,y)\n",
    "            ax.set_title(f'{level} {start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db60cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_add_metadata(modality, subject, levels, starts, runs=9):\n",
    "    \"\"\"\n",
    "    Takes as input subject number, modality, levels of epoching wanted (word, sentence, constituent)\n",
    "    and starts (onset, offset) as well as the number of total runs (for debugging).\n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    A dict of epochs objects, concatenated on the key (levels x starts)\n",
    "    \n",
    "    e.g: {'word_onset': <Epochs 10000 objects>, 'sentence_offset': <Epochs 1000 objects> ....}\n",
    "    \"\"\"\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    \n",
    "    # Initialization of the dictionary\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "                \n",
    "    # Iterating on runs, building the metadata and re-epoching\n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True, modality=modality)\n",
    "        meta = meta_.copy()\n",
    "        \n",
    "        # Metadata update\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta['const_end'] = meta.constituent_onset.shift(-1)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            last_word_duration = meta.loc[d.index.max(), 'duration']\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max() + last_word_duration\n",
    "            # Todo: Add the last word duration ? \n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            last_word_duration = meta.loc[d.index.max(), 'duration']\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max() + last_word_duration\n",
    "\n",
    "        # Adding embeddings info\n",
    "        meta = add_embeddings(meta, run, 'constituent')\n",
    "        meta = add_embeddings(meta, run, 'sentence')\n",
    "        \n",
    "        embeddings = meta.word.apply(lambda word: nlp(word).vector).values\n",
    "        meta['embeds_word'] = embeddings\n",
    "        for start in starts: \n",
    "            for level in levels:\n",
    "                # Select only the rows containing the True for the conditions\n",
    "                # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "                sel = meta.query(f'{level}_onset==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "\n",
    "                # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "                # Function will epoch on the offset of each level instead of the onset\n",
    "                # TODO: add adaptative baseline\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop',\n",
    "                                            preload=True,\n",
    "                                                baseline=None)\n",
    "                epoch_key = f'{level}_{start}'\n",
    "\n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in starts: \n",
    "        for level_ in levels:\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "            \n",
    "    return dict_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06030f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_from_criterion(criterion, dict_epochs, starts, levels):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - criterion: the criterion on which the decoding will be done (embeddings, wlength, w_freq, etc..)\n",
    "    - dict_epochs: the dictionnary containing the epochs for each condition (starts x levels)\n",
    "    - starts: (onset, offset)\n",
    "    - levels: (word, sentence, constituent)\n",
    "    \n",
    "    Returns:\n",
    "    Two dataframes: \n",
    "    - all_scores: decoding scores for each subject / starts x levels\n",
    "    - all_evos: ERP plots for each subject / starts x levels\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    all_evos = []\n",
    "    all_scores = []\n",
    "    # All epochs -> Decoding and generate evoked potentials\n",
    "    for start in starts: \n",
    "        for level in levels:\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            epochs = dict_epochs[epoch_key]\n",
    "            # mean\n",
    "            evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "            all_evos.append(dict(subject=subject, evo=evo, start=start, level=level))\n",
    "\n",
    "\n",
    "            # decoding word emb\n",
    "            epochs = epochs.load_data().pick_types(meg=True, stim=False, misc=False)\n",
    "            X = epochs.get_data()\n",
    "            if criterion == 'emb_sentence' or criterion == 'emb_constituent':\n",
    "                embeddings = epochs.metadata[f'embeds_{level}']\n",
    "                embeddings = np.vstack(embeddings.values)\n",
    "                R_vec = decod_xy(X, embeddings)\n",
    "                scores = np.mean(R_vec, axis=1)\n",
    "            elif criterion == 'emb_word':\n",
    "                nlp = spacy.load(\"fr_core_news_sm\")\n",
    "                embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "                embeddings = np.array([emb for emb in embeddings])\n",
    "                R_vec = decod_xy(X, embeddings)\n",
    "                scores = np.mean(R_vec, axis=1)\n",
    "            elif criterion == 'wlength':\n",
    "                y = epochs.metadata.wlength\n",
    "                R_vec = decod_xy(X, y)\n",
    "                scores = R_vec\n",
    "\n",
    "            for t, score in enumerate(scores):\n",
    "                all_scores.append(dict(subject=subject, score=score, start=start, level=level, t=epochs.times[t]))\n",
    "    all_scores = pd.DataFrame(all_scores)\n",
    "    all_evos = pd.DataFrame(all_evos)\n",
    "    return all_scores, all_evos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9134443a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw files for modality: visual\n",
      "\n",
      " Epoching for run 1, subject: 3\n",
      "\n",
      "Opening raw data file /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 36000 ... 517999 =     36.000 ...   517.999 secs\n",
      "Ready.\n",
      "Reading events from /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: Omitted 81 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger channel has a non-zero initial value of 8 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1466 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "1684          rire\n",
      "1685          mais\n",
      "1686            où\n",
      "1687          veux\n",
      "1688            tu\n",
      "1689            qu\n",
      "1691            il\n",
      "1692         aille\n",
      "1693             n\n",
      "1695       importe\n",
      "1696            où\n",
      "1697         droit\n",
      "1698        devant\n",
      "1699           lui\n",
      "1700         alors\n",
      "1701            le\n",
      "1702         petit\n",
      "1703        prince\n",
      "1704      remarqua\n",
      "1705     gravement\n",
      "1706            ça\n",
      "1707            ne\n",
      "1708          fait\n",
      "1709          rien\n",
      "1710             c\n",
      "1712           est\n",
      "1713     tellement\n",
      "1714         petit\n",
      "1715          chez\n",
      "1716          moi!\n",
      "1717            et\n",
      "1718          avec\n",
      "1719            un\n",
      "1720           peu\n",
      "1721            de\n",
      "1722    mélancolie\n",
      "1723          peut\n",
      "1724          être\n",
      "1725            il\n",
      "1726        ajouta\n",
      "1727         droit\n",
      "1728        devant\n",
      "1729           soi\n",
      "1730            on\n",
      "1731            ne\n",
      "1732          peut\n",
      "1733           pas\n",
      "1734         aller\n",
      "1735          bien\n",
      "1736          loin\n",
      "Name: word, dtype: object 1540         éclat\n",
      "1541            de\n",
      "1542          rire\n",
      "1543          mais\n",
      "1544            où\n",
      "1545        veuxtu\n",
      "1546            qu\n",
      "1547            il\n",
      "1548         aille\n",
      "1549             n\n",
      "1550       importe\n",
      "1551            où\n",
      "1552         droit\n",
      "1553        devant\n",
      "1554           lui\n",
      "1555         alors\n",
      "1556            le\n",
      "1557         petit\n",
      "1558        prince\n",
      "1559      remarqua\n",
      "1560     gravement\n",
      "1561            ça\n",
      "1562            ne\n",
      "1563          fait\n",
      "1564          rien\n",
      "1565             c\n",
      "1566           est\n",
      "1567     tellement\n",
      "1568         petit\n",
      "1569          chez\n",
      "1570           moi\n",
      "1571            et\n",
      "1572          avec\n",
      "1573            un\n",
      "1574           peu\n",
      "1575            de\n",
      "1576    mélancolie\n",
      "1577      peutêtre\n",
      "1578            il\n",
      "1579        ajouta\n",
      "1580         droit\n",
      "1581        devant\n",
      "1582           soi\n",
      "1583            on\n",
      "1584            ne\n",
      "1585          peut\n",
      "1586           pas\n",
      "1587         aller\n",
      "1588          bien\n",
      "1589          loin\n",
      "Name: clean_word, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1571, 1572, 1573, 1574, 1575, 1576, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate on subjects to epochs, and mean later\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m subjects[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m5\u001b[39m]:\n\u001b[0;32m---> 21\u001b[0m     dict_epochs \u001b[38;5;241m=\u001b[39m epoch_add_metadata(modality, subject, levels, starts, runs)\n\u001b[1;32m     23\u001b[0m     all_scores, all_evos \u001b[38;5;241m=\u001b[39m decoding_from_criterion(decoding_criterion, dict_epochs, starts, levels)\n",
      "Cell \u001b[0;32mIn [3], line 22\u001b[0m, in \u001b[0;36mepoch_add_metadata\u001b[0;34m(modality, subject, levels, starts, runs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Iterating on runs, building the metadata and re-epoching\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,runs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     raw, meta_, events \u001b[38;5;241m=\u001b[39m \u001b[43mread_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents_return\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     meta \u001b[38;5;241m=\u001b[39m meta_\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Metadata update\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:79\u001b[0m, in \u001b[0;36mread_raw\u001b[0;34m(subject, run_id, events_return, modality)\u001b[0m\n\u001b[1;32m     76\u001b[0m path_syntax \u001b[38;5;241m=\u001b[39m get_code_path() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msyntax_new_no_punct\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# testing new syntax\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Send raw metadata\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43madd_new_syntax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# meta = add_syntax(meta, path_syntax, int(run_id))\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# add sentence and word positions\u001b[39;00m\n\u001b[1;32m     83\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(meta\u001b[38;5;241m.\u001b[39mis_last_word\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/utils.py:277\u001b[0m, in \u001b[0;36madd_new_syntax\u001b[0;34m(meta, syntax_path, run)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, default_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(n_closing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, is_last_word\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXXX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    276\u001b[0m     meta[key] \u001b[38;5;241m=\u001b[39m default_value\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m synt\u001b[38;5;241m.\u001b[39miloc[j][key]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    279\u001b[0m content_pos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVINF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVPP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_word\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m pos: pos \u001b[38;5;129;01min\u001b[39;00m content_pos \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pos, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    282\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:712\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 712\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:661\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m--> 661\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:799\u001b[0m, in \u001b[0;36m_LocationIndexer._convert_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m--> 799\u001b[0m         idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m         keyidx\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(keyidx)\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:1294\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inds\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1327\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1328\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1330\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1571, 1572, 1573, 1574, 1575, 1576, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589] not in index'"
     ]
    }
   ],
   "source": [
    "modality = \"visual\"\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "path = get_path(modality)\n",
    "subjects = get_subjects(path)\n",
    "runs = 9\n",
    "decoding_criterion = 'wlength'\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "levels = ('word','constituent','sentence')\n",
    "starts = ('onset', 'offset')\n",
    "\n",
    "if isinstance(levels, str):\n",
    "    levels = [levels]\n",
    "    \n",
    "if isinstance(starts, str):\n",
    "    starts = [starts]\n",
    "      \n",
    "# Iterate on subjects to epochs, and mean later\n",
    "for subject in subjects[2:5]:\n",
    "    dict_epochs = epoch_add_metadata(modality, subject, levels, starts, runs)\n",
    "    \n",
    "    all_scores, all_evos = decoding_from_criterion(decoding_criterion, dict_epochs, starts, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m(5859)\u001b[0;36m_raise_if_missing\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   5857 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5858 \u001b[0;31m            \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 5859 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5860 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5861 \u001b[0;31m    \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m(5796)\u001b[0;36m_get_indexer_strict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   5794 \u001b[0;31m            \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5795 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 5796 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5797 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5798 \u001b[0;31m        \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m(1330)\u001b[0;36m_get_listlike_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1328 \u001b[0;31m        \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1329 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1330 \u001b[0;31m        \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1331 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1332 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m(1294)\u001b[0;36m_convert_to_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1292 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1293 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1294 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1295 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1296 \u001b[0;31m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m(799)\u001b[0;36m_convert_tuple\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    797 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    798 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 799 \u001b[0;31m                \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    800 \u001b[0;31m                \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    801 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m(661)\u001b[0;36m_get_setitem_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    659 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    660 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 661 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    662 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    663 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m(712)\u001b[0;36m__setitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    710 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    711 \u001b[0;31m            \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 712 \u001b[0;31m        \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    713 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    714 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/utils.py\u001b[0m(277)\u001b[0;36madd_new_syntax\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    275 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_closing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XXX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    276 \u001b[0;31m        \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 277 \u001b[0;31m        \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    279 \u001b[0;31m    \u001b[0mcontent_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VINF\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VPP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"V\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "> \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py\u001b[0m(79)\u001b[0;36mread_raw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m    \u001b[0;31m# Send raw metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 79 \u001b[0;31m    \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_new_syntax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_syntax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     80 \u001b[0;31m    \u001b[0;31m# meta = add_syntax(meta, path_syntax, int(run_id))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     81 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> d\n",
      "> \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/utils.py\u001b[0m(277)\u001b[0;36madd_new_syntax\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    275 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_closing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XXX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    276 \u001b[0;31m        \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 277 \u001b[0;31m        \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msynt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    279 \u001b[0;31m    \u001b[0mcontent_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"NC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADJ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ADV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VINF\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VPP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"V\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> len(ià\n",
      "*** SyntaxError: '(' was never closed\n",
      "ipdb> len(i)\n",
      "1558\n",
      "ipdb> len(j)\n",
      "1558\n",
      "ipdb> meta_tokens\n",
      "0       lorsque\n",
      "1             j\n",
      "2         avais\n",
      "3           six\n",
      "4           ans\n",
      "         ...   \n",
      "1585       peut\n",
      "1586        pas\n",
      "1587      aller\n",
      "1588       bien\n",
      "1589       loin\n",
      "Name: clean_word, Length: 1590, dtype: object\n",
      "ipdb> synt_tokens\n",
      "0       lorsque\n",
      "1             j\n",
      "3         avais\n",
      "4           six\n",
      "5           ans\n",
      "         ...   \n",
      "1732       peut\n",
      "1733        pas\n",
      "1734      aller\n",
      "1735       bien\n",
      "1736       loin\n",
      "Name: word, Length: 1614, dtype: object\n",
      "ipdb> key\n",
      "'n_closing'\n",
      "ipdb> i\n",
      "array([   0,    1,    2, ..., 1587, 1588, 1589])\n",
      "ipdb> meta\n",
      "      Unnamed: 0      word  onset  duration  \\\n",
      "0              0   Lorsque    0.7      0.25   \n",
      "1              1   j'avais    1.0      0.25   \n",
      "2              2       six    1.3      0.25   \n",
      "3              3      ans,    1.6      0.25   \n",
      "4              4      j'ai    1.9      0.25   \n",
      "...          ...       ...    ...       ...   \n",
      "1460        1460      peut  509.2      0.25   \n",
      "1461        1461       pas  509.5      0.25   \n",
      "1462        1462     aller  509.8      0.25   \n",
      "1463        1463      bien  510.1      0.25   \n",
      "1464        1464  loin...\"  510.4      0.25   \n",
      "\n",
      "                               trial_type  wlength  n_closing  \n",
      "0     {'kind': 'word', 'word': 'Lorsque'}        7          1  \n",
      "1      {'kind': 'word', 'word': 'javais'}        7          1  \n",
      "2         {'kind': 'word', 'word': 'six'}        3          1  \n",
      "3         {'kind': 'word', 'word': 'ans'}        4          1  \n",
      "4         {'kind': 'word', 'word': 'jai'}        4          1  \n",
      "...                                   ...      ...        ...  \n",
      "1460     {'kind': 'word', 'word': 'peut'}        4          1  \n",
      "1461      {'kind': 'word', 'word': 'pas'}        3          1  \n",
      "1462    {'kind': 'word', 'word': 'aller'}        5          1  \n",
      "1463     {'kind': 'word', 'word': 'bien'}        4          1  \n",
      "1464     {'kind': 'word', 'word': 'loin'}        8          1  \n",
      "\n",
      "[1465 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f53b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_epochs['word_onset'].metadata.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc01ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
