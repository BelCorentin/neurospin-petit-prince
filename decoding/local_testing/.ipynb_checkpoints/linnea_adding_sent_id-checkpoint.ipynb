{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d383c5",
   "metadata": {},
   "source": [
    "# Adding sentence id / constituent id to events.tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0124cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neuro\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "# ML/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Tools\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "from utils import match_list, add_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6801aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_modify_events(subject, run_id, events_return=False, modality=\"visual\"):\n",
    "    print(f\"Reading raw files for modality: {modality}\")\n",
    "    path = get_path(modality)\n",
    "    task_map = {\"auditory\": \"listen\", \"visual\": \"read\", \"fmri\": \"listen\"}\n",
    "    task = task_map[modality]\n",
    "    print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    # read events\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "    \n",
    "    base_meta = meta.copy()\n",
    "\n",
    "    meta[\"wlength\"] = meta.word.apply(len)\n",
    "    # Enriching the metadata with outside files:\n",
    "    # path_syntax = get_code_path() / \"data/syntax\"\n",
    "    path_syntax = get_code_path() / \"data\" / \"syntax_new_no_punct\"  # testing new syntax\n",
    "\n",
    "    # Send raw metadata\n",
    "    meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "\n",
    "    # add sentence and word positions\n",
    "    meta[\"sequence_id\"] = np.cumsum(meta.is_last_word.shift(1, fill_value=False))\n",
    "    for s, d in meta.groupby(\"sequence_id\"):\n",
    "        meta.loc[d.index, \"word_id\"] = range(len(d))\n",
    "\n",
    "    meta['word_onset'] = True\n",
    "    meta['word_stop'] = meta.start + meta.duration\n",
    "    meta['sentence_onset'] = meta.word_id == 0\n",
    "    meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "    meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "    meta['constituent_onset'].fillna(False, inplace=True)\n",
    "    meta.drop('prev_closing', axis=1, inplace=True)\n",
    "\n",
    "    # Adding the sentence stop info\n",
    "    meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "    for s, d in meta.groupby('sentence_id'):\n",
    "        meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "        meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "        meta.loc[d.index, 'sentence_stop'] = d.start.max()\n",
    "\n",
    "    # Adding the constituents stop info\n",
    "    meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "    for s, d in meta.groupby('constituent_id'):\n",
    "        meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "        meta.loc[d.index, 'constituent_stop'] = d.start.max()\n",
    "        meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "        \n",
    "    base_meta['sentence_id'] = meta.sentence_id\n",
    "    base_meta['constituent_id'] = meta.constituent_id\n",
    "    return base_meta, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2822d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b469c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw files for modality: auditory\n",
      "\n",
      " Epoching for run 1, subject: 1\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m subject \u001b[38;5;241m=\u001b[39m subjects[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,runs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m         base_meta, meta \u001b[38;5;241m=\u001b[39m read_modify_events(subject, run, events_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, modality\u001b[38;5;241m=\u001b[39mmodality)\n",
      "Cell \u001b[0;32mIn [2], line 31\u001b[0m, in \u001b[0;36mread_modify_events\u001b[0;34m(subject, run_id, events_return, modality)\u001b[0m\n\u001b[1;32m     27\u001b[0m meta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(event_file, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m base_meta \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 31\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwlength\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Enriching the metadata with outside files:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# path_syntax = get_code_path() / \"data/syntax\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m path_syntax \u001b[38;5;241m=\u001b[39m get_code_path() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msyntax_new_no_punct\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# testing new syntax\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'word'"
     ]
    }
   ],
   "source": [
    "from dataset import read_raw, get_subjects, get_path, add_embeddings\n",
    "from utils import decod_xy, mne_events\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "\n",
    "modality = \"auditory\"\n",
    "\n",
    "path = get_path(modality)\n",
    "subjects = get_subjects(path)\n",
    "runs = 2\n",
    "subject = subjects[0]\n",
    "\n",
    "for run in range(1,runs+1):\n",
    "        base_meta, meta = read_modify_events(subject, run, events_return = True, modality=modality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/is153802/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m(5575)\u001b[0;36m__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   5573 \u001b[0;31m        ):\n",
      "\u001b[0m\u001b[0;32m   5574 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 5575 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5576 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   5577 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/tmp/ipykernel_626523/3697528078.py\u001b[0m(31)\u001b[0;36mread_modify_events\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     29 \u001b[0;31m    \u001b[0mbase_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m    \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wlength\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m    \u001b[0;31m# Enriching the metadata with outside files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m    \u001b[0;31m# path_syntax = get_code_path() / \"data/syntax\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> meta\n",
      "      Unnamed: 0   onset  duration                           trial_type\n",
      "0              0    3.05      0.37  {'kind': 'word', 'word': 'lorsque'}\n",
      "1              1    3.42      0.02        {'kind': 'word', 'word': 'j'}\n",
      "2              2    3.53      0.23    {'kind': 'word', 'word': 'avais'}\n",
      "3              3    3.93      0.25      {'kind': 'word', 'word': 'six'}\n",
      "4              4    4.18      0.18      {'kind': 'word', 'word': 'ans'}\n",
      "...          ...     ...       ...                                  ...\n",
      "1627        1627  609.51      0.14     {'kind': 'word', 'word': 'peut'}\n",
      "1628        1628  609.65      0.22      {'kind': 'word', 'word': 'pas'}\n",
      "1629        1629  609.87      0.17    {'kind': 'word', 'word': 'aller'}\n",
      "1630        1630  610.04      0.16     {'kind': 'word', 'word': 'bien'}\n",
      "1631        1631  610.20      0.18     {'kind': 'word', 'word': 'loin'}\n",
      "\n",
      "[1632 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd996e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
