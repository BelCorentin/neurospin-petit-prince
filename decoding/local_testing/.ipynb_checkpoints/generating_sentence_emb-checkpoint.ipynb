{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aebc7b4",
   "metadata": {},
   "source": [
    "# New Approach:\n",
    "\n",
    "For both:\n",
    "- Sentence embeddings\n",
    "- Constituent embeddings\n",
    "\n",
    "Generate the embedding by iterating through them, instead of generating it from the whole txt file and chunking after.\n",
    "\n",
    "In order to get the right chunking:\n",
    "- get the metadata format from a normal analysis,\n",
    "- get the frontiers of constituents / sentences from it, and generate the embeddings from there\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "It is working as of now. Question: calculating the embeddings constituent by constituent wouldn't be a problem as they lack the context around them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eec524",
   "metadata": {},
   "source": [
    "## Testing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee8a0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it a function:\n",
    "\n",
    "# Currently a notebook function (% and ! commands)\n",
    "\n",
    "from dataset import get_code_path\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def add_embeddings(meta, run, level):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function made to generate laser embeddings, store them,\n",
    "    and add them to the metadata \n",
    "\n",
    "    Does so for both constituent embeddings, and sentence ones\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Parse the metadata into constituents / sentences, \n",
    "    # and generate txt files for each constituents / sentence\n",
    "    # So that it can be parsed by LASER\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    meta['const_end'] = meta.constituent_onset.shift(-1)\n",
    "    for index, row in meta.iterrows():\n",
    "\n",
    "        # Append word to current sentence \n",
    "        current_sentence.append(row['word'])\n",
    "\n",
    "        # Check if end of sentence \n",
    "        if level == 'sentence' and row['is_last_word']:\n",
    "            # Join words into sentence string and append to list\n",
    "            sentences.append(' '.join(current_sentence)) \n",
    "            # Reset current sentence   \n",
    "            current_sentence = []\n",
    "            \n",
    "        if level == 'constituent' and row['const_end']:\n",
    "            # Join words into sentence string and append to list\n",
    "            sentences.append(' '.join(current_sentence)) \n",
    "            # Reset current sentence   \n",
    "            current_sentence = []\n",
    "\n",
    "    # Loop through sentences \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Get sentence number\n",
    "        sentence_num = i + 1\n",
    "\n",
    "        # Create file name\n",
    "        file_name = f'./embeds/txt/run{run}_{level}_{sentence_num}.txt'\n",
    "\n",
    "        # Open text file \n",
    "        with open(file_name, 'w') as f:\n",
    "            # Write sentence to file\n",
    "            f.write(sentence)\n",
    "            \n",
    "    # Run LASER using the run number\n",
    "    path = Path('/home/is153802/github/LASER/tasks/embed')\n",
    "    %env LASER=/home/is153802/github/LASER\n",
    "\n",
    "    for i, _ in enumerate(sentences):\n",
    "    # Get sentence number\n",
    "        sentence_num = i + 1\n",
    "\n",
    "        txt_file = f\"/home/is153802/code/decoding/local_testing/embeds/txt/run{run}_{level}_{sentence_num}.txt\"\n",
    "        emb_file = f\"/home/is153802/code/decoding/local_testing/embeds/emb/run{run}_{level}_{sentence_num}.bin\"\n",
    "        if os.path.exists(emb_file):\n",
    "            continue\n",
    "        else:\n",
    "            !bash /home/is153802/github/LASER/tasks/embed/embed.sh {txt_file} {emb_file}\n",
    "        \n",
    "    # Get the embeddings from the generated txt file, and add them to metadata\n",
    "    dim = 1024\n",
    "    embeddings = {}\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        embeds = np.fromfile(\n",
    "                f\"{get_code_path()}/decoding/local_testing/embeds/emb/run{run}_{level}_{index+1}.bin\",\n",
    "                dtype=np.float32,\n",
    "                count=-1,\n",
    "                )\n",
    "        embeds.resize(embeds.shape[0] // dim, dim)\n",
    "        embeds = embeds.reshape(-1)\n",
    "        embeddings[index] = embeds\n",
    "    sent_index = 0\n",
    "    embed_arrays = []\n",
    "    for index, row in meta.iterrows():\n",
    "        embed_arrays.append(embeddings[sent_index])\n",
    "        # Check if end of sentence \n",
    "        if row['is_last_word']:\n",
    "            sent_index += 1\n",
    "\n",
    "    meta[f'embed_{level}'] = embed_arrays\n",
    "    \n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ab2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to be integrated to utils.py\n",
    "\n",
    "# Make it a function:\n",
    "from dataset import get_code_path\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def add_embeddings(meta, run, level):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function made to generate laser embeddings, store them,\n",
    "    and add them to the metadata \n",
    "\n",
    "    Does so for both constituent embeddings, and sentence ones\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Parse the metadata into constituents / sentences, \n",
    "    # and generate txt files for each constituents / sentence\n",
    "    # So that it can be parsed by LASER\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    meta['const_end'] = meta.constituent_onset.shift(-1)\n",
    "    for index, row in meta.iterrows():\n",
    "\n",
    "        # Append word to current sentence \n",
    "        current_sentence.append(row['word'])\n",
    "\n",
    "        # Check if end of sentence \n",
    "        if level == 'sentence' and row['is_last_word']:\n",
    "            # Join words into sentence string and append to list\n",
    "            sentences.append(' '.join(current_sentence)) \n",
    "            # Reset current sentence   \n",
    "            current_sentence = []\n",
    "            \n",
    "        if level == 'constituent' and row['const_end']:\n",
    "            # Join words into sentence string and append to list\n",
    "            sentences.append(' '.join(current_sentence)) \n",
    "            # Reset current sentence   \n",
    "            current_sentence = []\n",
    "\n",
    "    # Loop through sentences \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Get sentence number\n",
    "        sentence_num = i + 1\n",
    "\n",
    "        # Create file name\n",
    "        file_name = f'./embeds/txt/run{run}_{level}_{sentence_num}.txt'\n",
    "\n",
    "        # Open text file \n",
    "        with open(file_name, 'w') as f:\n",
    "            # Write sentence to file\n",
    "            f.write(sentence)\n",
    "            \n",
    "    # Run LASER using the run number\n",
    "    path = Path('/home/is153802/github/LASER/tasks/embed')\n",
    "    os.environ['LASER'] = '/home/is153802/github/LASER'\n",
    "\n",
    "    for i, _ in enumerate(sentences):\n",
    "    # Get sentence number\n",
    "        sentence_num = i + 1\n",
    "\n",
    "        txt_file = f\"/home/is153802/code/decoding/local_testing/embeds/txt/run{run}_{level}_{sentence_num}.txt\"\n",
    "        emb_file = f\"/home/is153802/code/decoding/local_testing/embeds/emb/run{run}_{level}_{sentence_num}.bin\"\n",
    "        if os.path.exists(emb_file):\n",
    "            continue\n",
    "        else:\n",
    "            subprocess.run(['/bin/bash', '/home/is153802/github/LASER/tasks/embed/embed.sh', txt_file, emb_file])\n",
    "        \n",
    "    # Get the embeddings from the generated txt file, and add them to metadata\n",
    "    dim = 1024\n",
    "    embeddings = {}\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        embeds = np.fromfile(\n",
    "                f\"{get_code_path()}/decoding/local_testing/embeds/emb/run{run}_{level}_{index+1}.bin\",\n",
    "                dtype=np.float32,\n",
    "                count=-1,\n",
    "                )\n",
    "        embeds.resize(embeds.shape[0] // dim, dim)\n",
    "        embeds = embeds.reshape(-1)\n",
    "        embeddings[index] = embeds\n",
    "    sent_index = 0\n",
    "    embed_arrays = []\n",
    "    for index, row in meta.iterrows():\n",
    "        embed_arrays.append(embeddings[sent_index])\n",
    "        # Check if end of sentence \n",
    "        if row['is_last_word']:\n",
    "            sent_index += 1\n",
    "\n",
    "    meta[f'embed_{level}'] = embed_arrays\n",
    "    \n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9eb95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw files for modality: auditory\n",
      "\n",
      " Epoching for run 1, subject: 3\n",
      "\n",
      "Opening raw data file /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 28000 ... 658999 =     28.000 ...   658.999 secs\n",
      "Ready.\n",
      "Reading events from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-01_events.tsv.\n",
      "Reading channel info from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954 events found\n",
      "Event IDs: [  1 129]\n",
      "Reading 0 ... 630999  =      0.000 ...   630.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LASER=/home/is153802/github/LASER\n",
      "env: LASER=/home/is153802/github/LASER\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "1597 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1597 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "484 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 484 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "155 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 155 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "1597 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1597 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "484 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 484 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "155 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 155 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Reading raw files for modality: auditory\n",
      "\n",
      " Epoching for run 2, subject: 3\n",
      "\n",
      "Opening raw data file /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-02_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 120000 ... 772999 =    120.000 ...   772.999 secs\n",
      "Ready.\n",
      "Reading events from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-02_events.tsv.\n",
      "Reading channel info from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-02_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 events found\n",
      "Event IDs: [  1 129]\n",
      "Reading 0 ... 652999  =      0.000 ...   652.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LASER=/home/is153802/github/LASER\n",
      "env: LASER=/home/is153802/github/LASER\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "1765 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1765 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "510 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 510 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "141 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 141 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "1765 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1765 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "510 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 510 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 30 columns\n",
      "141 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 141 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_251725/3348043598.py:98: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Reading raw files for modality: auditory\n",
      "\n",
      " Epoching for run 3, subject: 3\n",
      "\n",
      "Opening raw data file /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-03_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 226000 ... 941999 =    226.000 ...   941.999 secs\n",
      "Ready.\n",
      "Reading events from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-03_events.tsv.\n",
      "Reading channel info from /home/is153802/data/LPP_MEG_auditory/sub-3/ses-01/meg/sub-3_ses-01_task-listen_run-03_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:53: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862 events found\n",
      "Event IDs: [  1 129]\n",
      "Reading 0 ... 715999  =      0.000 ...   715.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LASER=/home/is153802/github/LASER\n",
      "2023-06-09 11:21:13,742 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:13,742 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:13,742 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:14,273 | INFO | preprocess | SPM processing run3_constituent_1.txt  \n",
      "2023-06-09 11:21:14,400 | INFO | embed | encoding /tmp/tmp2rnf7a3t/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_1.bin\n",
      "2023-06-09 11:21:14,415 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:17,489 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:17,490 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:17,490 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:18,019 | INFO | preprocess | SPM processing run3_constituent_2.txt  \n",
      "2023-06-09 11:21:18,136 | INFO | embed | encoding /tmp/tmpo3qj175q/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_2.bin\n",
      "2023-06-09 11:21:18,153 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:21,586 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:21,586 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:21,586 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:22,119 | INFO | preprocess | SPM processing run3_constituent_3.txt  \n",
      "2023-06-09 11:21:22,232 | INFO | embed | encoding /tmp/tmpsgdva1pm/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_3.bin\n",
      "2023-06-09 11:21:22,242 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:25,543 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:25,543 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:25,543 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:26,076 | INFO | preprocess | SPM processing run3_constituent_4.txt  \n",
      "2023-06-09 11:21:26,193 | INFO | embed | encoding /tmp/tmpnmw4yujn/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_4.bin\n",
      "2023-06-09 11:21:26,208 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:29,463 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:29,463 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:29,463 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:30,007 | INFO | preprocess | SPM processing run3_constituent_5.txt  \n",
      "2023-06-09 11:21:30,119 | INFO | embed | encoding /tmp/tmpqrizu4au/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_5.bin\n",
      "2023-06-09 11:21:30,133 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:33,294 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:33,294 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:33,294 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:33,832 | INFO | preprocess | SPM processing run3_constituent_6.txt  \n",
      "2023-06-09 11:21:33,954 | INFO | embed | encoding /tmp/tmpdr31w54i/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_6.bin\n",
      "2023-06-09 11:21:33,965 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:37,245 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:37,245 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:37,245 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:37,779 | INFO | preprocess | SPM processing run3_constituent_7.txt  \n",
      "2023-06-09 11:21:37,894 | INFO | embed | encoding /tmp/tmp9kh4xyab/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_7.bin\n",
      "2023-06-09 11:21:37,912 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:41,242 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:41,242 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:41,242 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:41,792 | INFO | preprocess | SPM processing run3_constituent_8.txt  \n",
      "2023-06-09 11:21:41,904 | INFO | embed | encoding /tmp/tmpq9ej7bko/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_8.bin\n",
      "2023-06-09 11:21:41,916 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:45,222 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:45,223 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:45,223 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:45,807 | INFO | preprocess | SPM processing run3_constituent_9.txt  \n",
      "2023-06-09 11:21:45,914 | INFO | embed | encoding /tmp/tmp3lwryssv/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_9.bin\n",
      "2023-06-09 11:21:45,936 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:49,324 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:49,324 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:49,324 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:49,855 | INFO | preprocess | SPM processing run3_constituent_10.txt  \n",
      "2023-06-09 11:21:49,963 | INFO | embed | encoding /tmp/tmpiboxq2qs/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_10.bin\n",
      "2023-06-09 11:21:49,974 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:53,129 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:53,129 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:53,129 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:53,682 | INFO | preprocess | SPM processing run3_constituent_11.txt  \n",
      "2023-06-09 11:21:53,813 | INFO | embed | encoding /tmp/tmpk4cil6sl/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_11.bin\n",
      "2023-06-09 11:21:53,827 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:21:56,915 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:21:56,916 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:21:56,916 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:21:57,458 | INFO | preprocess | SPM processing run3_constituent_12.txt  \n",
      "2023-06-09 11:21:57,571 | INFO | embed | encoding /tmp/tmpdwu888zq/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_12.bin\n",
      "2023-06-09 11:21:57,584 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:00,802 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:00,802 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:00,802 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:01,358 | INFO | preprocess | SPM processing run3_constituent_13.txt  \n",
      "2023-06-09 11:22:01,470 | INFO | embed | encoding /tmp/tmpn6fig72u/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_13.bin\n",
      "2023-06-09 11:22:01,483 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:04,760 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:04,760 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:04,760 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:05,298 | INFO | preprocess | SPM processing run3_constituent_14.txt  \n",
      "2023-06-09 11:22:05,411 | INFO | embed | encoding /tmp/tmprpj06wqz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_14.bin\n",
      "2023-06-09 11:22:05,422 | INFO | embed | encoded 1 sentences in 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-09 11:22:08,528 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:08,528 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:08,528 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:09,077 | INFO | preprocess | SPM processing run3_constituent_15.txt  \n",
      "2023-06-09 11:22:09,192 | INFO | embed | encoding /tmp/tmpwou5vslk/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_15.bin\n",
      "2023-06-09 11:22:09,204 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:12,245 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:12,245 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:12,245 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:12,769 | INFO | preprocess | SPM processing run3_constituent_16.txt  \n",
      "2023-06-09 11:22:12,875 | INFO | embed | encoding /tmp/tmpgoid4k6n/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_16.bin\n",
      "2023-06-09 11:22:12,889 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:15,901 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:15,901 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:15,901 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:16,428 | INFO | preprocess | SPM processing run3_constituent_17.txt  \n",
      "2023-06-09 11:22:16,529 | INFO | embed | encoding /tmp/tmpbbmcbbss/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_17.bin\n",
      "2023-06-09 11:22:16,545 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:19,526 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:19,526 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:19,526 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:20,051 | INFO | preprocess | SPM processing run3_constituent_18.txt  \n",
      "2023-06-09 11:22:20,160 | INFO | embed | encoding /tmp/tmp1erw86m2/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_18.bin\n",
      "2023-06-09 11:22:20,173 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:23,197 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:23,197 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:23,197 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:23,725 | INFO | preprocess | SPM processing run3_constituent_19.txt  \n",
      "2023-06-09 11:22:23,835 | INFO | embed | encoding /tmp/tmp_ghfnzqv/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_19.bin\n",
      "2023-06-09 11:22:23,848 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:26,883 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:26,883 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:26,883 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:27,413 | INFO | preprocess | SPM processing run3_constituent_20.txt  \n",
      "2023-06-09 11:22:27,517 | INFO | embed | encoding /tmp/tmpyi1k6m6b/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_20.bin\n",
      "2023-06-09 11:22:27,529 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:30,547 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:30,547 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:30,548 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:31,073 | INFO | preprocess | SPM processing run3_constituent_21.txt  \n",
      "2023-06-09 11:22:31,180 | INFO | embed | encoding /tmp/tmp8w5esh92/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_21.bin\n",
      "2023-06-09 11:22:31,191 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:34,453 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:34,453 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:34,453 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:35,025 | INFO | preprocess | SPM processing run3_constituent_22.txt  \n",
      "2023-06-09 11:22:35,146 | INFO | embed | encoding /tmp/tmpx511vhy_/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_22.bin\n",
      "2023-06-09 11:22:35,160 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:38,414 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:38,414 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:38,414 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:38,955 | INFO | preprocess | SPM processing run3_constituent_23.txt  \n",
      "2023-06-09 11:22:39,075 | INFO | embed | encoding /tmp/tmpv6iqmj0r/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_23.bin\n",
      "2023-06-09 11:22:39,090 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:42,250 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:42,250 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:42,250 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:42,805 | INFO | preprocess | SPM processing run3_constituent_24.txt  \n",
      "2023-06-09 11:22:42,925 | INFO | embed | encoding /tmp/tmpev9rm7lr/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_24.bin\n",
      "2023-06-09 11:22:42,938 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:46,061 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:46,061 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:46,061 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:46,599 | INFO | preprocess | SPM processing run3_constituent_25.txt  \n",
      "2023-06-09 11:22:46,726 | INFO | embed | encoding /tmp/tmp1wr22ap_/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_25.bin\n",
      "2023-06-09 11:22:46,738 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:49,792 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:49,792 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:49,792 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:50,320 | INFO | preprocess | SPM processing run3_constituent_26.txt  \n",
      "2023-06-09 11:22:50,438 | INFO | embed | encoding /tmp/tmp5cb3aa1u/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_26.bin\n",
      "2023-06-09 11:22:50,450 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:53,547 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:53,547 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:53,547 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:54,080 | INFO | preprocess | SPM processing run3_constituent_27.txt  \n",
      "2023-06-09 11:22:54,194 | INFO | embed | encoding /tmp/tmpwthu0o6q/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_27.bin\n",
      "2023-06-09 11:22:54,206 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:22:57,393 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:22:57,393 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:22:57,393 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:22:57,921 | INFO | preprocess | SPM processing run3_constituent_28.txt  \n",
      "2023-06-09 11:22:58,034 | INFO | embed | encoding /tmp/tmpbst9rlbj/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_28.bin\n",
      "2023-06-09 11:22:58,046 | INFO | embed | encoded 1 sentences in 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-09 11:23:01,274 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:01,274 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:01,274 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:01,820 | INFO | preprocess | SPM processing run3_constituent_29.txt  \n",
      "2023-06-09 11:23:01,927 | INFO | embed | encoding /tmp/tmpt9yd61en/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_29.bin\n",
      "2023-06-09 11:23:01,938 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:05,355 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:05,355 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:05,355 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:05,890 | INFO | preprocess | SPM processing run3_constituent_30.txt  \n",
      "2023-06-09 11:23:06,006 | INFO | embed | encoding /tmp/tmpcm8v_zis/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_30.bin\n",
      "2023-06-09 11:23:06,018 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:09,343 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:09,344 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:09,344 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:09,875 | INFO | preprocess | SPM processing run3_constituent_31.txt  \n",
      "2023-06-09 11:23:09,988 | INFO | embed | encoding /tmp/tmpidc4smc4/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_31.bin\n",
      "2023-06-09 11:23:09,999 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:13,219 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:13,219 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:13,219 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:13,748 | INFO | preprocess | SPM processing run3_constituent_32.txt  \n",
      "2023-06-09 11:23:13,864 | INFO | embed | encoding /tmp/tmpq7bcc2pw/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_32.bin\n",
      "2023-06-09 11:23:13,880 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:17,058 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:17,058 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:17,058 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:17,586 | INFO | preprocess | SPM processing run3_constituent_33.txt  \n",
      "2023-06-09 11:23:17,699 | INFO | embed | encoding /tmp/tmpwefvgrok/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_33.bin\n",
      "2023-06-09 11:23:17,713 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:20,959 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:20,959 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:20,959 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:21,487 | INFO | preprocess | SPM processing run3_constituent_34.txt  \n",
      "2023-06-09 11:23:21,596 | INFO | embed | encoding /tmp/tmp0f6jhtz4/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_34.bin\n",
      "2023-06-09 11:23:21,609 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:24,683 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:24,684 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:24,684 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:25,212 | INFO | preprocess | SPM processing run3_constituent_35.txt  \n",
      "2023-06-09 11:23:25,326 | INFO | embed | encoding /tmp/tmpv8enrldz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_35.bin\n",
      "2023-06-09 11:23:25,340 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:28,482 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:28,482 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:28,483 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:29,011 | INFO | preprocess | SPM processing run3_constituent_36.txt  \n",
      "2023-06-09 11:23:29,127 | INFO | embed | encoding /tmp/tmprvb41eiz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_36.bin\n",
      "2023-06-09 11:23:29,141 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:32,254 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:32,255 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:32,255 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:32,785 | INFO | preprocess | SPM processing run3_constituent_37.txt  \n",
      "2023-06-09 11:23:32,897 | INFO | embed | encoding /tmp/tmp58w3euiz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_37.bin\n",
      "2023-06-09 11:23:32,910 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:36,220 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:36,220 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:36,220 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:36,777 | INFO | preprocess | SPM processing run3_constituent_38.txt  \n",
      "2023-06-09 11:23:36,916 | INFO | embed | encoding /tmp/tmprb2o256e/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_38.bin\n",
      "2023-06-09 11:23:36,935 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:40,237 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:40,237 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:40,237 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:40,782 | INFO | preprocess | SPM processing run3_constituent_39.txt  \n",
      "2023-06-09 11:23:40,897 | INFO | embed | encoding /tmp/tmpjmdmfv4u/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_39.bin\n",
      "2023-06-09 11:23:40,909 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:44,049 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:44,049 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:44,049 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:44,611 | INFO | preprocess | SPM processing run3_constituent_40.txt  \n",
      "2023-06-09 11:23:44,720 | INFO | embed | encoding /tmp/tmpctoyhknc/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_40.bin\n",
      "2023-06-09 11:23:44,730 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:48,311 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:48,311 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:48,311 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:48,852 | INFO | preprocess | SPM processing run3_constituent_41.txt  \n",
      "2023-06-09 11:23:48,960 | INFO | embed | encoding /tmp/tmphb00ejov/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_41.bin\n",
      "2023-06-09 11:23:48,975 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:52,230 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:52,231 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:52,231 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:52,768 | INFO | preprocess | SPM processing run3_constituent_42.txt  \n",
      "2023-06-09 11:23:52,875 | INFO | embed | encoding /tmp/tmpwrrwlav5/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_42.bin\n",
      "2023-06-09 11:23:52,887 | INFO | embed | encoded 1 sentences in 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-09 11:23:55,913 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:55,913 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:55,913 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:23:56,443 | INFO | preprocess | SPM processing run3_constituent_43.txt  \n",
      "2023-06-09 11:23:56,546 | INFO | embed | encoding /tmp/tmpuxgej85j/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_43.bin\n",
      "2023-06-09 11:23:56,557 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:23:59,569 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:23:59,569 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:23:59,569 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:00,096 | INFO | preprocess | SPM processing run3_constituent_44.txt  \n",
      "2023-06-09 11:24:00,226 | INFO | embed | encoding /tmp/tmpwfc1hyk2/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_44.bin\n",
      "2023-06-09 11:24:00,238 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:03,370 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:03,370 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:03,370 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:03,901 | INFO | preprocess | SPM processing run3_constituent_45.txt  \n",
      "2023-06-09 11:24:03,991 | INFO | embed | encoding /tmp/tmpqd88ywaz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_45.bin\n",
      "2023-06-09 11:24:04,005 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:07,150 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:07,150 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:07,150 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:07,682 | INFO | preprocess | SPM processing run3_constituent_46.txt  \n",
      "2023-06-09 11:24:07,788 | INFO | embed | encoding /tmp/tmpfgs21uzz/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_46.bin\n",
      "2023-06-09 11:24:07,801 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:10,905 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:10,905 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:10,905 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:11,467 | INFO | preprocess | SPM processing run3_constituent_47.txt  \n",
      "2023-06-09 11:24:11,584 | INFO | embed | encoding /tmp/tmp_xphpc_a/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_47.bin\n",
      "2023-06-09 11:24:11,595 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:14,819 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:14,819 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:14,819 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:15,352 | INFO | preprocess | SPM processing run3_constituent_48.txt  \n",
      "2023-06-09 11:24:15,481 | INFO | embed | encoding /tmp/tmp4rmpm7k1/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_48.bin\n",
      "2023-06-09 11:24:15,495 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:18,589 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:18,589 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:18,589 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:19,134 | INFO | preprocess | SPM processing run3_constituent_49.txt  \n",
      "2023-06-09 11:24:19,243 | INFO | embed | encoding /tmp/tmpdwctg7l2/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_49.bin\n",
      "2023-06-09 11:24:19,257 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:22,306 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:22,306 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:22,306 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:22,837 | INFO | preprocess | SPM processing run3_constituent_50.txt  \n",
      "2023-06-09 11:24:22,947 | INFO | embed | encoding /tmp/tmp2c4oazj4/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_50.bin\n",
      "2023-06-09 11:24:22,961 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:25,976 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:25,976 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:25,976 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:26,499 | INFO | preprocess | SPM processing run3_constituent_51.txt  \n",
      "2023-06-09 11:24:26,614 | INFO | embed | encoding /tmp/tmpsgh3wqem/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_51.bin\n",
      "2023-06-09 11:24:26,628 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:29,731 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:29,731 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:29,731 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:30,268 | INFO | preprocess | SPM processing run3_constituent_52.txt  \n",
      "2023-06-09 11:24:30,380 | INFO | embed | encoding /tmp/tmp0iqzgy0v/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_52.bin\n",
      "2023-06-09 11:24:30,393 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:33,510 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:33,510 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:33,510 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:34,055 | INFO | preprocess | SPM processing run3_constituent_53.txt  \n",
      "2023-06-09 11:24:34,184 | INFO | embed | encoding /tmp/tmp2e99cstp/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_53.bin\n",
      "2023-06-09 11:24:34,200 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:37,603 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:37,603 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:37,603 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:38,139 | INFO | preprocess | SPM processing run3_constituent_54.txt  \n",
      "2023-06-09 11:24:38,254 | INFO | embed | encoding /tmp/tmp2jc318a9/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_54.bin\n",
      "2023-06-09 11:24:38,266 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:41,323 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:41,324 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:41,324 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:41,866 | INFO | preprocess | SPM processing run3_constituent_55.txt  \n",
      "2023-06-09 11:24:41,982 | INFO | embed | encoding /tmp/tmpozf44zz_/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_55.bin\n",
      "2023-06-09 11:24:41,997 | INFO | embed | encoded 1 sentences in 0s\n",
      "2023-06-09 11:24:45,120 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:45,120 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:45,120 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:45,647 | INFO | preprocess | SPM processing run3_constituent_56.txt  \n",
      "2023-06-09 11:24:45,765 | INFO | embed | encoding /tmp/tmpbk9sy6_d/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_56.bin\n",
      "2023-06-09 11:24:45,782 | INFO | embed | encoded 1 sentences in 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-09 11:24:48,800 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-06-09 11:24:48,800 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-06-09 11:24:48,800 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-06-09 11:24:49,327 | INFO | preprocess | SPM processing run3_constituent_57.txt  \n",
      "2023-06-09 11:24:49,456 | INFO | embed | encoding /tmp/tmp9n2edxc1/spm to /home/is153802/code/decoding/local_testing/embeds/emb/run3_constituent_57.bin\n",
      "2023-06-09 11:24:49,471 | INFO | embed | encoded 1 sentences in 0s\n"
     ]
    }
   ],
   "source": [
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy, mne_events\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "\n",
    "modality = \"auditory\"\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "path = get_path(modality)\n",
    "subjects = get_subjects(path)\n",
    "runs = 9\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "levels = ('word','constituent','sentence')\n",
    "starts = ('onset', 'offset')\n",
    "      \n",
    "# Iterate on subjects to epochs, and mean later\n",
    "for subject in subjects[2:3]:\n",
    "    \n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    \n",
    "    # Initialization of the dictionary\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "                \n",
    "    # Iterating on runs, building the metadata and re-epoching\n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True, modality=modality)\n",
    "        meta = meta_.copy()\n",
    "        \n",
    "        # Metadata update\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max()\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max()\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "        \n",
    "        # Adding embeddings info\n",
    "        meta = add_embeddings(meta, run, 'constituent')\n",
    "        meta = add_embeddings(meta, run, 'sentence')\n",
    "        for start in starts: \n",
    "            for level in levels:\n",
    "                # Select only the rows containing the True for the conditions\n",
    "                # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "                start = 'onset' # DEBUG\n",
    "                sel = meta.query(f'{level}_{start}==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                \n",
    "                # Do we need to do that ???\n",
    "                \"\"\"\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                if modality == 'auditory':\n",
    "                    word_events = events[events[:, 2] > 1]\n",
    "                    meg_delta = np.round(np.diff(word_events[:, 0]/raw.info['sfreq']))\n",
    "                    meta_delta = np.round(np.diff(sel.onset.values))\n",
    "                    i, j = match_list(meg_delta, meta_delta)\n",
    "\n",
    "                # For auditory, we match on the time difference between triggers\n",
    "                elif modality == \"visual\":\n",
    "\n",
    "                    i, j = match_list(events[:, 2], sel.wlength)\n",
    "                    assert len(i) > (0.9 * len(events))\n",
    "                    assert (events[i, 2] == sel.loc[j].wlength).mean() > 0.95\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                # Making sure there is not hidden bug when matching\n",
    "                assert sel.shape[0] > 0.5 *  (meta.query(f'{level}_onset==True')).shape[0]\n",
    "                \"\"\"\n",
    "                \n",
    "                # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "                # Function will epoch on the offset of each level instead of the onset\n",
    "                # TODO: add adaptative baseline\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop',\n",
    "                                            preload=True,\n",
    "                                                baseline=None)\n",
    "                epoch_key = f'{level}_{start}'\n",
    "\n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in starts: \n",
    "        for level_ in levels:\n",
    "            start_ = 'onset' # DEBUG\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e2ed09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[['word','embed']][:50].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d90e41",
   "metadata": {},
   "source": [
    "# Previous Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7019f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: generate the run{i}.txt file to input to LASER\n",
    "\n",
    "# What was done previously: chunk the txt file raw by actual sentence (based on ., ?, !, etc..)\n",
    "# Problem: the metadata in epochs (sentence_end calculated using the word onset difference) doesn't match, as there are\n",
    "# Offsets that happen sometimes not at the end of sentences\n",
    "\n",
    "# Solution: temporary: generate the line chunking for LASER by word onset difference from the metadata file\n",
    "# Final: it will only work for read modality: for audio, an option could be to replicate the metadata file\n",
    "# => supposing the shape of both metadata files are the same, we can add the sentence_end column to the audio one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Open the events files to get the metadata, and then generate the txt file from there\n",
    "for run in np.arange(1,10):\n",
    "\n",
    "    file = f'/home/co/data/BIDS_lecture/sub-{sub}/ses-01/meg/sub-{sub}_ses-01_task-read_run-0{run}_events.tsv'\n",
    "\n",
    "\n",
    "\n",
    "    # Load the TSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    # Keep track of the previous onset value\n",
    "    prev_onset = None\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(f'run{run}.txt', 'w') as output_file:\n",
    "\n",
    "        # Loop through each row in the DataFrame\n",
    "        for i, row in df.iterrows():\n",
    "\n",
    "            # Get the onset value for this row\n",
    "            onset = row['onset']\n",
    "\n",
    "            # If this is the first row, or the onset difference with the previous row is less than 0.7, append the current column to the output\n",
    "            if ((row.word).__contains__(\".\")\n",
    "                or (row.word).__contains__(\"?\")\n",
    "                or (row.word).__contains__(\"!\")):\n",
    "                output_file.write(row['word'] +'\\n')\n",
    "                \n",
    "\n",
    "            # Otherwise, start a new line in the output file\n",
    "            else:\n",
    "                \n",
    "                output_file.write(row['word'] + ' ')\n",
    "\n",
    "            # Remember the onset value for the next iteration\n",
    "            prev_onset = onset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "path = Path('/home/is153802/github/LASER/tasks/embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LASER=/home/is153802/github/LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAPTERS = {\n",
    "        1: \"1-3\",\n",
    "        2: \"4-6\",\n",
    "        3: \"7-9\",\n",
    "        4: \"10-12\",\n",
    "        5: \"13-14\",\n",
    "        6: \"15-19\",\n",
    "        7: \"20-22\",\n",
    "        8: \"23-25\",\n",
    "        9: \"26-27\",\n",
    "    }\n",
    "\n",
    "for run in np.arange(1,10):\n",
    "    ch = CHAPTERS[run]\n",
    "    txt_file = f\"/home/is153802/code/data/txt_laser/run{run}.txt\"\n",
    "    emb_file = f\"/home/is153802/code/data/laser_embeddings/emb_{ch}.bin\"\n",
    "    !bash /home/is153802/github/LASER/tasks/embed/embed.sh {txt_file} {emb_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3719b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
