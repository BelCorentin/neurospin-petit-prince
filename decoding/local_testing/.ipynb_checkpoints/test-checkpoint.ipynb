{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1f3dcf",
   "metadata": {},
   "source": [
    "## TODO important\n",
    "\n",
    "### General\n",
    "\n",
    "- Check that the dataset is complete\n",
    "\n",
    "- Add the IBC subjects to a new dataset, and to the listening one\n",
    "\n",
    "### This notebook \n",
    "- NEw parser: integrate only the correct closing nodes, and remove the rest\n",
    "\n",
    "- Redo the way the constituent id is calculated to handle cases where two consecutive n_closing is 2 2\n",
    "\n",
    "- Understand the problem with sentence decoding\n",
    "\n",
    "\n",
    "\n",
    "Ideas:\n",
    "Décoder un mot s'il est à la fin d'un constituant ou pas, est-ce que leur décodage drop plus rapidement ou pas ?\n",
    "\n",
    "\n",
    "Décoder pendant toute la durée du constituant le label de la catégorie en epochant sur ton offset\n",
    ":::: vérifier le nombre de catégorie totale (pour qu'il n'y ait pas de groupe trop peu populated)\n",
    "\n",
    "\n",
    "TODO another time:\n",
    "- investigate the events_repeated\n",
    "- train on subset for words, and decode on other modalities ?\n",
    "- If the script runs correctly on Jean Zay, add other decoding modalities, and run them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710b125",
   "metadata": {},
   "source": [
    "# Testing new syntactic parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503ab83",
   "metadata": {},
   "source": [
    "### Removing regex punct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec905615",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/co/code/data/syntax_new_no_punct/run1_v2_0.25_0.5-tokenized.syntax.txt\", \"r\") as file:\n",
    "        txt = file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04c91f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For value: \n",
      "  h\n",
      "h (SENT (Ssub-MOD (CS 0=Lorsque) (Sint (VN (CLS-SUJ 1=j') (V 2=avais)) (NP-OBJ (DET 3=six) (NC 4=ans))))  (VN (CLS-SUJ 6=j') (V 7=ai) (VPP 8=vu))  (NP-MOD (DET 10=une) (NC 11=fois))  (NP-OBJ (DET 13=une) (ADJ 14=magnifique) (NC 15=image))  (PP-MOD (P 17=dans) (NP (DET 18=un) (NC 19=livre) (PP (P 20=sur) (NP (DET 21=la) (NC 22=forêt) (AP (ADJ 23=vierge)))) (Srel (NP-SUJ (PROREL 24=qui)) (VN (CLR 25=s') (V 26=appelait)) (NP-ATS (NC 27=histoires) (VPpart (VPP 28=vécues)))))) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=les) (NC 1=serpents) (ADJ 2=boas)) (VN (V 3=avalent)) (NP-OBJ (DET 4=leur) (NC 5=proie)) (AP-MOD (ADV 6=tout) (ADJ 7=entière))  (PP-MOD (P 9=sans) (VPinf (VN (CLO-OBJ 10=la) (VINF 11=mâcher)))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=J') (V 1=ai) (ADV 2=alors) (ADV 3=beaucoup) (VPP 4=réfléchi)) (PP-MOD (P 5=sur) (NP (DET 6=les) (NC 7=aventures) (PP (P 8=de) (NP (DET 9=la) (NC 10=jungle))))) (COORD (CC 11=et) (Sint  (ADV+ (P 13=à) (DET 14=mon) (NC 15=tour))  (VN (CLS-SUJ 17=j') (V 18=ai) (VPP 19=réussi))  (PP-MOD (P 21=avec) (NP (DET 22=un) (NC 23=crayon) (PP (P 24=de) (NP (NC 25=couleur)))))  (PP-OBJ (P 27=à) (VPinf (VN (VINF 28=tracer)) (NP-OBJ (DET 29=mon) (ADJ 30=premier) (NC 31=dessin)))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=j') (V 1=ai) (VPP 2=montré)) (NP-OBJ (DET 3=mon) (NC+ (NC 4=chef) (P 5=d') (NC 6=oeuvre))) (PP-A_OBJ (P+D 7=aux) (NP (ADJ 8=grandes) (NC 9=personnes))) (COORD (CC 10=et) (Sint (VN (CLS-SUJ 11=je) (CLO-A_OBJ 12=leur) (V 13=ai) (VPP 14=demandé)) (Ssub-OBJ (CS 15=si) (Sint (NP-SUJ (DET 16=mon) (NC 17=dessin)) (VN (CLO-A_OBJ 18=leur) (V 19=faisait)) (NP-OBJ (NC 20=peur)))))) )\n",
      "\n",
      "h (SENT (ADVWH-MOD 0=pourquoi) (NP-SUJ (DET 1=un) (NC 2=chapeau)) (VN (V 3=ferait) (CLS-SUJ 4=il)) (NP-OBJ (NC 5=peur)) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=Mon) (NC 1=dessin)) (VN (ADV 2=ne) (V 3=représentait)) (ADV 4=pas) (NP-OBJ (DET 5=un) (NC 6=chapeau)) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Il) (V 1=représentait)) (NP-OBJ (DET 2=un) (NC 3=serpent) (NC 4=boa) (Srel (NP-SUJ (PROREL 5=qui)) (VN (V 6=digérait)) (NP-OBJ (DET 7=un) (NC 8=éléphant)))) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=les) (ADJ 1=grandes) (NC 2=personnes)) (VN (CLO-A_OBJ 3=m') (V 4=ont) (VPP 5=conseillé)) (PP-OBJ (P 6=de) (VPinf (VN (VINF 7=laisser)) (ADV+ (P 8=de) (NP (NC 9=côté))) (NP-OBJ (DET 10=les) (NC 11=dessins) (PP (P 12=de) (NP (NC+ (NC 13=serpents) (ET 14=boas)) (AP (ADJ 15=ouverts) (COORD (CC 16=ou) (AP (ADJ 17=fermés))))))))  (COORD (CC 19=et) (PP (P 20=de) (VPinf (VN (CLR-OBJ 21=m') (VINF 22=intéresser)) (ADV 23=plutôt) (PP-A_OBJ (P 24=à) (NP (DET 25=la) (NC 26=géographie)) (COORD  (PP (P 28=à) (NP (DET 29=l') (NC 30=histoire)))) (COORD  (PP (P+D 32=au) (NP (NC 33=calcul)))) (COORD (CC 34=et) (PP (P 35=à) (NP (DET 36=la) (NC 37=grammaire))))))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=J') (V 1=ai) (ADV 2=donc) (VPP 3=dû)) (VPinf-OBJ (VN (VINF 4=choisir)) (NP-OBJ (DET 5=un) (ADJ 6=autre) (NC 7=métier))) (COORD (CC 8=et) (Sint (VN (CLS-SUJ 9=j') (V 10=ai) (VPP 11=appris)) (PP-OBJ (P 12=à) (VPinf (VN (VINF 13=piloter)) (NP-OBJ (DET 14=des) (NC 15=avions)))))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Et) (Sint (NP-SUJ (DET 1=la) (NC 2=géographie))  (Sint-MOD (VN (CLS-SUJ 4=c') (V 5=est)) (AP-ATS (ADJ 6=exact)))  (VN (CLO-A_OBJ 8=m') (V 9=a) (ADV 10=beaucoup) (VPP 11=servi)))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Je) (V 1=savais)) (VPinf-OBJ (VN (VINF 2=reconnaître))  (PP-MOD (P+D 4=du) (NP (ADJ 5=premier) (NC+ (NC 6=coup) (P 7=d') (NC 8=oeil))))  (NP-OBJ (DET 10=la) (NC 11=chine) (PP (P 12=de) (NP (DET 13=l') (NPP 14=arizona))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=J') (V 1=ai) (ADV 2=beaucoup) (VPP 3=vécu)) (PP-P_OBJ (P 4=chez) (NP (DET 5=les) (ADJ 6=grandes) (NC 7=personnes))) )\n",
      "\n",
      "h (SENT (Ssub-MOD (Ssub-MOD (CS 0=Quand) (Sint (VN (CLS-SUJ 1=j') (CLO-OBJ 2=en) (V 3=rencontrais)) (NP-OBJ (PRO 4=une) (Srel (NP-SUJ (PROREL 5=qui)) (VN (CLO-A_OBJ 6=me) (V 7=paraissait)) (AP-ATS (ADV+ (DET 8=un) (ADV 9=peu)) (ADJ 10=lucide)))))) ) (VN (CLS-SUJ 12=je) (V 13=faisais)) (NP-OBJ (DET 14=l') (NC 15=expérience) (PP (P 16=sur) (NP (PRO 17=elle))) (PP (P 18=de) (NP (DET 19=mon) (NC 20=dessin) (NC+ (NC 21=numéro) (ADJ 22=1)) (Srel (NP-OBJ (PROREL 23=que)) (VN (CLS-SUJ 24=j') (V 25=ai) (ADV 26=toujours) (VPP 27=conservé)))))) (Sint-MOD (VN (CLS-SUJ 28=je) (V 29=voulais)) (VPinf-OBJ (VN (VINF 30=savoir)) (Ssub-OBJ (CS 31=si) (Sint (VN (CLS-SUJ 32=elle) (V 33=était)) (ADV 34=vraiment) (AP-ATS (ADJ 35=compréhensive)))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=c') (V 1=est)) (NP-ATS (DET 2=un) (NC 3=chapeau)) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Et) (Sint (NP-SUJ (DET 1=la) (ADJ 2=grande) (NC 3=personne)) (VN (V 4=était)) (AP-ATS (ADV 5=bien) (ADJ 6=contente) (PP (P 7=de) (VPinf (VN (VINF 8=connaître)) (NP-OBJ (DET 9=un) (NC 10=homme) (AP (ADV 11=aussi) (ADJ 12=raisonnable)))))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=J') (V 1=ai) (ADV 2=ainsi) (VPP 3=vécu)) (AP-ATS (ADJ 4=seul))  (PP-MOD (P 6=sans) (NP (NC 7=personne) (Srel (PP-MOD (P 8=avec) (NP (PROREL 9=qui))) (VN (VINF 10=parler)) (ADV 11=véritablement))))  (PP-MOD (P+ (P 13=jusqu') (P 14=à)) (NP (DET 15=une) (NC 16=panne))) (PP-MOD (P 17=dans) (NP (DET 18=le) (NC 19=désert) (PP (P+D 20=du) (NP (NPP 21=sahara)))))  (PP-MOD (P+ (CLS 23=il) (CLO 24=y) (V 25=a)) (NP (DET 26=six) (NC 27=ans))) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=Quelque) (NC 1=chose)) (VN (CLR 2=s') (V 3=était) (VPP 4=cassé)) (PP-MOD (P 5=dans) (NP (DET 6=mon) (NC 7=moteur))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=J') (V 1=avais)) (ADV+ (P 2=à) (NC 3=peine)) (NP-OBJ (DET+ (P 4=de) (DET 5=l')) (NC 6=eau) (PP (P 7=à) (VPinf (VN (VINF 8=boire))))) (PP-MOD (P 9=pour) (NP (DET 10=huit) (NC 11=jours))) )\n",
      "\n",
      "h (SENT (NP-MOD (DET 0=Le) (ADJ 1=premier) (NC 2=soir)) (VN (CLS-SUJ 3=je) (CLR 4=me) (V 5=suis) (ADV 6=donc) (VPP 7=endormi)) (PP-MOD (P 8=sur) (NP (DET 9=le) (NC 10=sable))) (PP-MOD (P 11=à) (NP (DET 12=mille) (NC 13=milles) (PP (P 14=de) (NP (DET 15=toute) (NC 16=terre) (VPpart (VPP 17=habitée)))))) )\n",
      "\n",
      "h (SENT (I 0=hein) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Et) (Sint (VN (CLS-SUJ 1=j') (V 2=ai) (VPP 3=vu)) (NP-OBJ (DET 4=un) (ADJ 5=petit) (NC 6=bonhomme) (AP (ADV+ (ADV 7=tout) (P 8=à) (NC 9=fait)) (ADJ 10=extraordinaire)) (Srel (NP-SUJ (PROREL 11=qui)) (VN (CLO-OBJ 12=me) (V 13=considérait)) (ADV 14=gravement))))) )\n",
      "\n",
      "h (SENT (VN (ADV 0=N') (VIMP 1=oubliez)) (ADV 2=pas) (Ssub-OBJ (CS 3=que) (Sint (VN (CLS-SUJ 4=je) (CLR 5=me) (V 6=trouvais)) (PP-P_OBJ.O (P 7=à) (NP (DET 8=mille) (NC 9=milles) (PP (P 10=de) (NP (DET 11=toute) (NC 12=région) (VPpart (VPP 13=habitée)))))))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Or) (Sint (NP-SUJ (DET 1=mon) (ADJ 2=petit) (NC 3=bonhomme)) (VN (ADV 4=ne) (CLO-A_OBJ 5=me) (V 6=semblait)) (COORD-OBJ (CC 7=ni) (AP (ADJ 8=égaré)))  (COORD (CC 10=ni) (VPpart (VPP 11=mort) (PP-DE_OBJ (P 12=de) (NP (NC 13=fatigue)))))  (COORD (CC 15=ni) (VPpart (VPP 16=mort) (PP-DE_OBJ (P 17=de) (NP (NC 18=faim)))))  (COORD (CC 20=ni) (VPpart (VPP 21=mort) (PP-DE_OBJ (P 22=de) (NP (NC 23=soif)))))  (COORD-MOD (CC 25=ni) (VPpart (VPP 26=mort) (PP-DE_OBJ (P 27=de) (NP (NC 28=peur))))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Il) (ADV 1=n') (V 2=avait)) (PP-MOD (P 3=en) (PRO 4=rien)) (NP-OBJ (DET 5=l') (NC 6=apparence) (PP (P 7=d') (NP (DET 8=un) (NC 9=enfant) (VPpart (VPP 10=perdu) (PP (P+D+ (P+D 11=au) (NC 12=milieu) (P+D 13=du)) (NP (NC 14=désert)))  (PP (P 16=à) (NP (DET 17=mille) (NC 18=milles) (PP (P 19=de) (NP (DET 20=toute) (NC 21=région) (VPpart (VPP 22=habitée)))))))))) )\n",
      "\n",
      "h (SENT (CC 0=Et) (Sint (VN (CLS-SUJ 1=il) (CLO-A_OBJ 2=me) (V 3=répéta)) (ADV 4=alors)  (AdP-MOD (ADV 6=tout) (ADV 7=doucement))  (PP-MOD (P 9=comme) (NP (DET 10=une) (NC 11=chose) (AP (ADV 12=très) (ADJ 13=sérieuse))))) )\n",
      "\n",
      "h (SENT (AP-MOD (ADV 0=Aussi) (ADJ 1=absurde) (Ssub (CS 2=que) (Sint (NP-SUJ (PRO 3=cela)) (VN (CLO-A_OBJ 4=me) (V 5=semblât)) (PP-ATS (P 6=à) (NP (DET 7=mille) (NC 8=milles) (PP (P 9=de) (NP (ADJ 10=tous) (DET 11=les) (NC 12=endroits) (AP (ADJ 13=habités))))) (COORD (CC 14=et) (PP (P 15=en) (NP (NC 16=danger) (PP (P 17=de) (NP (NC 18=mort))))))))))  (VN (CLS-SUJ 20=je) (V 21=sortis)) (PP-DE_OBJ (P 22=de) (NP (DET 23=ma) (NC 24=poche))) (NP-OBJ (DET 25=une) (NC 26=feuille) (PP (P 27=de) (NP (NC 28=papier))) (COORD (CC 29=et) (NP (DET 30=un) (NC 31=stylographe)))) )\n",
      "\n",
      "h (SENT (COORD (COORD (CC 0=Mais) (Sint (VN (CLS-SUJ 1=je) (CLR 2=me) (V 3=rappelai)) (ADV 4=alors) (Ssub-OBJ (CS 5=que) (Sint (VN (CLS-SUJ 6=j') (V 7=avais) (ADV 8=surtout) (VPP 9=étudié)) (NP-OBJ (DET 10=la) (NC 11=géographie) (COORD  (NP (DET 13=l') (NC 14=histoire))) (COORD  (NP (DET 16=le) (NC 17=calcul))) (COORD (CC 18=et) (NP (DET 19=la) (NC 20=grammaire)))))))) (COORD (CC 21=et) (Sint (VN (CLS-SUJ 22=je) (V 23=dis)) (PP-A_OBJ (P+D 24=au) (NP (ADJ 25=petit) (NC 26=bonhomme))) (PP-MOD (P 27=avec) (NP (ADV+ (DET 28=un) (NC 29=peu)) (P 30=de) (ADJ 31=mauvaise) (NC 32=humeur))) (Ssub-OBJ (CS 33=que) (Sint (VN (CLS-SUJ 34=je) (ADV 35=ne) (V 36=savais)) (ADV 37=pas) (VPinf-OBJ (VN (VINF 38=dessiner)))))))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Et) (Sint (VN (CLS-SUJ 1=je) (V 2=fus)) (AP-ATS (ADJ 3=stupéfait) (PP (P 4=d') (VPinf (VN (VINF 5=entendre)) (NP-OBJ (DET 6=le) (ADJ 7=petit) (NC 8=bonhomme)) (VN (CLO-A_OBJ 9=me) (VINF 10=répondre))))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Je) (ADV 1=ne) (V 2=veux)) (ADV 3=pas) (PP-DE_OBJ (P 4=d') (NP (DET 5=un) (NC 6=éléphant))) (PP-MOD (P 7=dans) (NP (DET 8=un) (NC 9=boa))) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=Un) (NC 1=boa)) (VN (CLS-SUJ 2=c') (V 3=est)) (AP-ATS (ADV 4=très) (ADJ 5=dangereux))  (COORD (CC 7=et) (NP (DET 8=un) (NC 9=éléphant)) (VN (CLS-SUJ 10=c') (V 11=est)) (AP-ATS (ADV 12=très) (ADJ 13=encombrant))) )\n",
      "\n",
      "h (SENT (PP-MOD (P 0=Chez) (NP (PRO 1=moi))) (VN (CLS-SUJ 2=c') (V 3=est)) (AP-ATS (ADV 4=tout) (ADJ 5=petit)) )\n",
      "\n",
      "h (SENT (ADV 0=Alors)  (PP-MOD (P+ (NC 2=faute) (P 3=de)) (NP (NC 4=patience)))  (Ssub-MOD (CS 6=comme) (Sint (VN (CLS-SUJ 7=j') (V 8=avais)) (NP-OBJ (NC 9=hâte)) (PP-DE_OBJ (P 10=de) (VPinf (VN (VINF 11=commencer)) (NP-OBJ (DET 12=le) (NC 13=démontage) (PP (P 14=de) (NP (DET 15=mon) (NC 16=moteur))))))))  (VN (CLS-SUJ 18=je) (V 19=griffonnai)) (NP-OBJ (DET 20=ce) (NC 21=dessin) (ADV 22=ci:)))\n",
      "\n",
      "h (SENT (VN (V 0=Crois) (CLS-SUJ 1=tu)) (Ssub-OBJ (CS 2=qu') (Sint (VN (CLS-SUJ 3=il) (VS 4=faille)) (NP-OBJ (ADV 5=beaucoup) (P 6=d') (NC 7=herbe)) (PP-A_OBJ (P 8=à) (NP (DET 9=ce) (NC 10=mouton))))) )\n",
      "\n",
      "h (SENT (Ssub (CS+ (CS 0=parce) (CS 1=que)) (Sint (PP-MOD (P 2=chez) (NP (PRO 3=moi))) (VN (CLS-SUJ 4=c') (V 5=est)) (AP-ATS (ADV 6=tout) (ADJ 7=petit)))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Il) (V 1=pencha)) (NP-OBJ (DET 2=la) (NC 3=tête)) (PP-P_OBJ.O (P 4=vers) (NP (DET 5=le) (NC 6=dessin))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Ce) (V 1=sont)) (NP-ATS (DET 2=des) (NC 3=mots) (VPpart (VPP 4=prononcés) (ADV+ (P 5=par) (NP (NC 6=hasard)))) (Srel (NP-SUJ (PROREL 7=qui))  (ADV+ (ADV 9=peu) (P 10=à) (ADV 11=peu))  (VN (CLO-A_OBJ 13=m') (V 14=ont) (NP-OBJ (PRO 15=tout)) (VPP 16=révélé)))) )\n",
      "\n",
      "h (SENT (NP-ATS (PROWH 0=qu')) (VN (V 1=est) (CLS-SUJ 2=ce)) (Srel-MOD.CLEFT (NP-ATS (PROREL 3=que)) (VN (CLS-SUJ 4=c') (V 5=est)) (Ssub-ATS (CS 6=que) (NP (DET 7=cette) (NC 8=chose) (ADV 9=là)))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=ce) (ADV 1=n') (V 2=est)) (ADV 3=pas) (NP-ATS (DET 4=une) (NC 5=chose)) )\n",
      "\n",
      "h (SENT (I 0=ah) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Je) (V 1=désire)) (Ssub-OBJ (CS 2=que) (Sint (VN (CLS-SUJ 3=l'on) (VS 4=prenne)) (NP-OBJ (DET 5=mes) (NC 6=malheurs)) (PP-P_OBJ.O (P+D 7=au) (AP (ADJ 8=sérieux))))) )\n",
      "\n",
      "h (SENT (VN (CLS-SUJ 0=Il) (V 1=hochait)) (NP-OBJ (DET 2=la) (NC 3=tête)) (ADV 4=doucement) (PP-MOD (ADV 5=tout) (P 6=en) (VPpart (VN (VPR 7=regardant)) (NP-OBJ (DET 8=mon) (NC 9=avion)))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Puis) (Sint  (VPpart-MOD (VN (VPR 2=sortant)) (NP-OBJ (DET 3=mon) (NC 4=mouton)) (PP-DE_OBJ (P 5=de) (NP (DET 6=sa) (NC 7=poche))))  (VN (CLS-SUJ 9=il) (CLR 10=se) (V 11=plongea)) (PP-P_OBJ.O (P 12=dans) (NP (DET 13=la) (NC 14=contemplation) (PP (P 15=de) (NP (DET 16=son) (NC 17=trésor))))))) )\n",
      "\n",
      "h (SENT (PP-P_OBJ.DLOC (P 0=d') (ADVWH 1=où)) (VN (V 2=viens) (CLS-SUJ 3=tu))  (NP-MOD (DET 5=mon) (ADJ 6=petit) (NC 7=bonhomme)) )\n",
      "\n",
      "h (SENT (ADVWH-P_OBJ.LOC 0=Où) (VN (V 1=est) (CLS-SUJ 2=ce)) (PP-MOD.LOC (P 3=chez) (NP (PRO 4=toi))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=Et) (Sint (Ssub-MOD (CS 1=si) (Sint (VN (CLS-SUJ 2=tu) (V 3=es)) (AP-ATS (ADJ 4=gentil))))  (VN (CLS-SUJ 6=je) (CLO-A_OBJ 7=te) (V 8=donnerai)) (ADV 9=aussi) (NP-OBJ (DET 10=une) (NC 11=corde) (PP (P 12=pour) (VPinf (VN (CLO-OBJ 13=l') (VINF 14=attacher)) (PP-MOD (P 15=pendant) (NP (DET 16=le) (NC 17=jour)))))))) )\n",
      "\n",
      "h (SENT (NP-SUJ (DET 0=La) (NC 1=proposition)) (VN (V 2=parut)) (VPinf-ATS (VN (VINF 3=choquer)) (NP-OBJ (DET 4=le) (ADJ 5=petit) (NC 6=prince))) )\n",
      "\n",
      "h (SENT (VPinf (VN (CLO-OBJ 0=l') (VINF 1=attacher))) )\n",
      "\n",
      "h (SENT (COORD (CC 0=mais) (Sint (Ssub-MOD (CS 1=si) (Sint (VN (CLS-SUJ 2=tu) (ADV 3=ne) (CLO-OBJ 4=l') (V 5=attaches)) (ADV 6=pas)))  (VN (CLS-SUJ 8=il) (V 9=ira)) (ADV+ (ADV 10=n') (V 11=importe) (ADV 12=où))  (COORD (CC 14=et) (Sint (VN (CLS-SUJ 15=il) (CLR-OBJ 16=se) (V 17=perdra)))))) )\n",
      "\n",
      "h (SENT (NP-SUJ (PRO 0=ça)) (VN (ADV 1=ne) (V 2=fait)) (NP-OBJ (PRO 3=rien))  (Sint-MOD (VN (CLS-SUJ 5=c') (V 6=est)) (AP-ATS (ADV 7=tellement) (ADJ 8=petit))  (PP-MOD (P 10=chez) (NP (PRO 11=moi!)))))\n",
      "\n",
      "For value: \n",
      "  mort\n"
     ]
    }
   ],
   "source": [
    "for value in const_length[10]:\n",
    "    print(\"For value: \\n \", str(value[0]))\n",
    "    value = str(value)[0]\n",
    "    for line in txt:\n",
    "        if line.__contains__(value):\n",
    "            print(value, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f17f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ans'] 4\n",
      "['vu'] 2\n",
      "['fois'] 2\n",
      "['image'] 2\n",
      "['vécues'] 6\n",
      "['Ça'] 2\n",
      "['représentait'] 2\n",
      "['fauve'] 4\n",
      "['Voilà'] 2\n",
      "['dessin'] 4\n",
      "['disait'] 2\n",
      "['livre'] 3\n",
      "['boas'] 2\n",
      "['avalent'] 2\n",
      "['proie'] 2\n",
      "['entière'] 2\n",
      "['mâcher'] 4\n",
      "['Ensuite'] 1\n",
      "['peuvent'] 2\n",
      "['plus'] 1\n",
      "['bouger'] 3\n",
      "['digestion'] 7\n",
      "['réfléchi'] 2\n",
      "['jungle'] 5\n",
      "['dessin'] 6\n",
      "['1'] 3\n",
      "['était'] 2\n",
      "['ça'] 3\n",
      "['montré'] 2\n",
      "['oeuvre'] 3\n",
      "['personnes'] 3\n",
      "['peur'] 6\n",
      "['répondu'] 2\n",
      "['pourquoi'] 1\n",
      "['chapeau'] 2\n",
      "['il'] 2\n",
      "['peur'] 2\n",
      "['dessin'] 2\n",
      "['représentait'] 2\n",
      "['pas'] 1\n",
      "['chapeau'] 2\n",
      "['représentait'] 2\n",
      "['éléphant'] 4\n",
      "['dessiné'] 2\n",
      "['boa'] 4\n",
      "['comprendre'] 5\n",
      "['ont'] 2\n",
      "['toujours'] 1\n",
      "['besoin'] 2\n",
      "['explications'] 3\n",
      "['2'] 3\n",
      "['était'] 2\n",
      "['ça'] 3\n",
      "['personnes'] 2\n",
      "['conseillé'] 2\n",
      "['grammaire'] 9\n",
      "['est'] 2\n",
      "['ainsi'] 1\n",
      "['peintre'] 5\n",
      "['découragé'] 2\n",
      "['2'] 8\n",
      "['personnes'] 2\n",
      "['comprennent'] 2\n",
      "['jamais'] 1\n",
      "['rien'] 2\n",
      "['seules'] 2\n",
      "['explications'] 6\n",
      "['dû'] 2\n",
      "['métier'] 3\n",
      "['avions'] 6\n",
      "['volé'] 2\n",
      "['monde'] 4\n",
      "['servi'] 4\n",
      "['savais'] 2\n",
      "['arizona'] 5\n",
      "['est'] 2\n",
      "['utile'] 2\n",
      "['nuit'] 5\n",
      "['eu'] 2\n",
      "['vie'] 3\n",
      "['sérieux'] 7\n",
      "['vécu'] 2\n",
      "['personnes'] 3\n",
      "['vues'] 2\n",
      "['près'] 3\n",
      "['Ça'] 2\n",
      "['amélioré'] 2\n",
      "['opinion'] 2\n",
      "['faisais'] 2\n",
      "['conservé'] 6\n",
      "['compréhensive'] 6\n",
      "['répondait'] 4\n",
      "['est'] 2\n",
      "['chapeau'] 2\n",
      "['Alors'] 1\n",
      "['parlais'] 2\n",
      "['boas'] 4\n",
      "['vierges'] 5\n",
      "['étoiles'] 4\n",
      "['mettais'] 2\n",
      "['portée'] 3\n",
      "['parlais'] 2\n",
      "['cravates'] 5\n",
      "['raisonnable'] 8\n",
      "['vécu'] 2\n",
      "['seul'] 2\n",
      "['véritablement'] 4\n",
      "['panne'] 3\n",
      "['sahara'] 5\n",
      "['ans'] 3\n",
      "['chose'] 2\n",
      "['cassé'] 2\n",
      "['moteur'] 3\n",
      "['difficile'] 9\n",
      "['était'] 2\n",
      "['moi'] 3\n",
      "['mort'] 6\n",
      "['avais'] 2\n",
      "['peine'] 2\n",
      "['boire'] 5\n",
      "['jours'] 3\n",
      "['soir'] 2\n",
      "['endormi'] 2\n",
      "['sable'] 3\n",
      "['habitée'] 6\n",
      "['étais'] 2\n",
      "['océan'] 5\n",
      "['Alors'] 1\n",
      "['imaginez'] 2\n",
      "['surprise'] 2\n",
      "['jour'] 4\n",
      "['réveillé'] 4\n",
      "['disait'] 2\n",
      "['plaît'] 4\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['hein'] 1\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['sauté'] 2\n",
      "['pieds'] 3\n",
      "['foudre'] 5\n",
      "['frotté'] 2\n",
      "['yeux'] 2\n",
      "['regardé'] 2\n",
      "['gravement'] 5\n",
      "['Voilà'] 2\n",
      "['réussi'] 4\n",
      "['modèle'] 6\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['faute'] 2\n",
      "['découragé'] 2\n",
      "['peintre'] 5\n",
      "['personnes'] 3\n",
      "['ans'] 5\n",
      "['ouverts'] 8\n",
      "['regardai'] 2\n",
      "['donc'] 1\n",
      "['apparition'] 2\n",
      "['étonnement'] 6\n",
      "['oubliez'] 2\n",
      "['pas'] 1\n",
      "['habitée'] 8\n",
      "['peur'] 7\n",
      "['avait'] 2\n",
      "['rien'] 2\n",
      "['habitée'] 10\n",
      "['dis'] 2\n",
      "[\"Qu'\"] 2\n",
      "['ce'] 2\n",
      "['là'] 2\n",
      "['Et'] 1\n",
      "['sérieuse'] 5\n",
      "['plaît'] 4\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['impressionnant'] 4\n",
      "['ose'] 2\n",
      "['pas'] 1\n",
      "['désobéir'] 3\n",
      "['mort'] 10\n",
      "['sortis'] 2\n",
      "['poche'] 3\n",
      "['stylographe'] 4\n",
      "['dessiner'] 8\n",
      "['répondit'] 2\n",
      "['ça'] 2\n",
      "['fait'] 2\n",
      "['rien'] 2\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['mouton'] 4\n",
      "['refis'] 2\n",
      "['lui'] 3\n",
      "['étais'] 6\n",
      "['fermé'] 3\n",
      "['répondre'] 7\n",
      "['non'] 1\n",
      "['Non'] 1\n",
      "['veux'] 2\n",
      "['pas'] 1\n",
      "['éléphant'] 3\n",
      "['boa'] 3\n",
      "['boa'] 2\n",
      "['est'] 2\n",
      "['dangereux'] 2\n",
      "['encombrant'] 3\n",
      "['moi'] 3\n",
      "['est'] 2\n",
      "['petit'] 2\n",
      "['besoin'] 3\n",
      "['mouton'] 3\n",
      "['moi'] 2\n",
      "['mouton'] 2\n",
      "['Alors'] 1\n",
      "['dessiné'] 2\n",
      "['regarda'] 2\n",
      "['attentivement'] 1\n",
      "['non'] 1\n",
      "['là'] 3\n",
      "['est'] 2\n",
      "['malade'] 2\n",
      "['en'] 2\n",
      "['autre'] 2\n",
      "['Je'] 1\n",
      "['ami'] 2\n",
      "['sourit'] 2\n",
      "['gentiment'] 1\n",
      "['indulgence'] 3\n",
      "['vois'] 2\n",
      "['bien'] 1\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['mouton'] 2\n",
      "['bélier'] 3\n",
      "['a'] 2\n",
      "['cornes'] 2\n",
      "['refis'] 2\n",
      "['donc'] 1\n",
      "['encore'] 1\n",
      "['dessin'] 2\n",
      "['là'] 3\n",
      "['est'] 2\n",
      "['vieux'] 2\n",
      "['veux'] 2\n",
      "['longtemps'] 3\n",
      "['Alors'] 1\n",
      "['patience'] 3\n",
      "['moteur'] 8\n",
      "['griffonnai'] 2\n",
      "['lançai'] 3\n",
      "['ça'] 2\n",
      "['est'] 2\n",
      "['caisse'] 2\n",
      "['veux'] 4\n",
      "['est'] 2\n",
      "['dedans'] 1\n",
      "['juge'] 9\n",
      "['fait'] 3\n",
      "['ça'] 3\n",
      "['voulais'] 3\n",
      "['tu'] 2\n",
      "['mouton'] 5\n",
      "['pourquoi'] 1\n",
      "['petit'] 4\n",
      "['ça'] 2\n",
      "['suffira'] 2\n",
      "['sûrement'] 1\n",
      "['donné'] 2\n",
      "['mouton'] 2\n",
      "['pencha'] 2\n",
      "['tête'] 2\n",
      "['dessin'] 3\n",
      "['ça'] 4\n",
      "['Tiens'] 1\n",
      "['endormi'] 2\n",
      "['prince'] 6\n",
      "['fallut'] 2\n",
      "['longtemps'] 1\n",
      "['venait'] 5\n",
      "['questions'] 4\n",
      "['semblait'] 2\n",
      "['jamais'] 1\n",
      "['miennes'] 3\n",
      "['sont'] 2\n",
      "['révélé'] 4\n",
      "['Ainsi'] 1\n",
      "['avion'] 4\n",
      "['dessinerai'] 2\n",
      "['pas'] 1\n",
      "['avion'] 2\n",
      "['moi'] 6\n",
      "['demanda'] 2\n",
      "[\"qu'\"] 2\n",
      "['ce'] 2\n",
      "['là'] 4\n",
      "['est'] 2\n",
      "['pas'] 1\n",
      "['chose'] 2\n",
      "['Ça'] 2\n",
      "['vole'] 2\n",
      "['est'] 2\n",
      "['avion'] 2\n",
      "['est'] 2\n",
      "['avion'] 2\n",
      "['volais'] 9\n",
      "['Alors'] 1\n",
      "['comment'] 1\n",
      "['tombé'] 2\n",
      "['ciel'] 3\n",
      "['oui'] 1\n",
      "['je'] 2\n",
      "['modestement'] 1\n",
      "['ah'] 1\n",
      "['Ça'] 2\n",
      "['est'] 2\n",
      "['drôle'] 2\n",
      "['beaucoup'] 5\n",
      "['désire'] 2\n",
      "['sérieux'] 5\n",
      "['ajouta'] 3\n",
      "['alors'] 1\n",
      "['aussi'] 2\n",
      "['viens'] 2\n",
      "['ciel'] 3\n",
      "['planète'] 3\n",
      "['tu'] 2\n",
      "['entrevis'] 2\n",
      "['aussitôt'] 1\n",
      "['lueur'] 2\n",
      "['présence'] 5\n",
      "['brusquement'] 3\n",
      "['viens'] 2\n",
      "['donc'] 1\n",
      "['planète'] 3\n",
      "['pas'] 3\n",
      "['hochait'] 2\n",
      "['tête'] 2\n",
      "['doucement'] 1\n",
      "['avion'] 4\n",
      "['est'] 2\n",
      "['vrai'] 2\n",
      "['loin'] 6\n",
      "['longtemps'] 5\n",
      "['trésor'] 7\n",
      "['imaginez'] 2\n",
      "['planètes'] 7\n",
      "['efforçai'] 2\n",
      "['donc'] 1\n",
      "['long'] 4\n",
      "['où'] 2\n",
      "['tu'] 2\n",
      "['bonhomme'] 2\n",
      "['Où'] 1\n",
      "['ce'] 2\n",
      "['toi'] 3\n",
      "['mouton'] 3\n",
      "['tu'] 2\n",
      "['répondit'] 2\n",
      "['méditatif'] 4\n",
      "['ce'] 1\n",
      "['bien'] 2\n",
      "['donnée'] 5\n",
      "['est'] 2\n",
      "['maison'] 5\n",
      "['sûr'] 2\n",
      "['jour'] 8\n",
      "['Et'] 1\n",
      "['piquet'] 2\n",
      "['proposition'] 2\n",
      "['parut'] 2\n",
      "['prince'] 3\n",
      "['attacher'] 3\n",
      "['idée'] 2\n",
      "['perdra'] 6\n",
      "['rire'] 5\n",
      "['aille'] 6\n",
      "['où'] 2\n",
      "['lui'] 4\n",
      "['Alors'] 1\n",
      "['prince'] 2\n",
      "['remarqua'] 2\n",
      "['gravement'] 1\n",
      "['ça'] 2\n",
      "['fait'] 2\n",
      "['rien'] 2\n",
      "['ajouta'] 4\n",
      "['soi'] 4\n",
      "['peut'] 2\n",
      "['pas'] 1\n",
      "['loin'] 3\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "const_length = {}\n",
    "for line in txt:\n",
    "    count = 0\n",
    "    for tok in line.split(' '):\n",
    "        if tok.__contains__('('):\n",
    "            count+=1*tok.count('(')\n",
    "            \n",
    "        elif tok.__contains__(')'):\n",
    "            count-=1*tok.count(')')\n",
    "        if count==1:\n",
    "            pattern = r'=(.*?)\\)'\n",
    "            matches = re.findall(pattern, tok)\n",
    "\n",
    "            sub_tok = matches\n",
    "            if sub_tok!=[]:\n",
    "                print(sub_tok,tok.count(')'))\n",
    "                try:\n",
    "                    const_length[tok.count(')')].append(sub_tok)\n",
    "\n",
    "                except: \n",
    "                    const_length[tok.count(')')] = sub_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1eb3139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: ['ans',\n",
       "  ['fauve'],\n",
       "  ['dessin'],\n",
       "  ['mâcher'],\n",
       "  ['éléphant'],\n",
       "  ['boa'],\n",
       "  ['monde'],\n",
       "  ['servi'],\n",
       "  ['répondait'],\n",
       "  ['boas'],\n",
       "  ['étoiles'],\n",
       "  ['véritablement'],\n",
       "  ['jour'],\n",
       "  ['réveillé'],\n",
       "  ['plaît'],\n",
       "  ['réussi'],\n",
       "  ['plaît'],\n",
       "  ['impressionnant'],\n",
       "  ['stylographe'],\n",
       "  ['mouton'],\n",
       "  ['veux'],\n",
       "  ['petit'],\n",
       "  ['ça'],\n",
       "  ['questions'],\n",
       "  ['révélé'],\n",
       "  ['avion'],\n",
       "  ['là'],\n",
       "  ['avion'],\n",
       "  ['long'],\n",
       "  ['méditatif'],\n",
       "  ['lui'],\n",
       "  ['ajouta'],\n",
       "  ['soi']],\n",
       " 2: ['vu',\n",
       "  ['fois'],\n",
       "  ['image'],\n",
       "  ['Ça'],\n",
       "  ['représentait'],\n",
       "  ['Voilà'],\n",
       "  ['disait'],\n",
       "  ['boas'],\n",
       "  ['avalent'],\n",
       "  ['proie'],\n",
       "  ['entière'],\n",
       "  ['peuvent'],\n",
       "  ['réfléchi'],\n",
       "  ['était'],\n",
       "  ['montré'],\n",
       "  ['répondu'],\n",
       "  ['chapeau'],\n",
       "  ['il'],\n",
       "  ['peur'],\n",
       "  ['dessin'],\n",
       "  ['représentait'],\n",
       "  ['chapeau'],\n",
       "  ['représentait'],\n",
       "  ['dessiné'],\n",
       "  ['ont'],\n",
       "  ['besoin'],\n",
       "  ['était'],\n",
       "  ['personnes'],\n",
       "  ['conseillé'],\n",
       "  ['est'],\n",
       "  ['découragé'],\n",
       "  ['personnes'],\n",
       "  ['comprennent'],\n",
       "  ['rien'],\n",
       "  ['seules'],\n",
       "  ['dû'],\n",
       "  ['volé'],\n",
       "  ['savais'],\n",
       "  ['est'],\n",
       "  ['utile'],\n",
       "  ['eu'],\n",
       "  ['vécu'],\n",
       "  ['vues'],\n",
       "  ['Ça'],\n",
       "  ['amélioré'],\n",
       "  ['opinion'],\n",
       "  ['faisais'],\n",
       "  ['est'],\n",
       "  ['chapeau'],\n",
       "  ['parlais'],\n",
       "  ['mettais'],\n",
       "  ['parlais'],\n",
       "  ['vécu'],\n",
       "  ['seul'],\n",
       "  ['chose'],\n",
       "  ['cassé'],\n",
       "  ['était'],\n",
       "  ['avais'],\n",
       "  ['peine'],\n",
       "  ['soir'],\n",
       "  ['endormi'],\n",
       "  ['étais'],\n",
       "  ['imaginez'],\n",
       "  ['surprise'],\n",
       "  ['disait'],\n",
       "  ['moi'],\n",
       "  ['mouton'],\n",
       "  ['moi'],\n",
       "  ['mouton'],\n",
       "  ['sauté'],\n",
       "  ['frotté'],\n",
       "  ['yeux'],\n",
       "  ['regardé'],\n",
       "  ['Voilà'],\n",
       "  ['est'],\n",
       "  ['faute'],\n",
       "  ['découragé'],\n",
       "  ['regardai'],\n",
       "  ['apparition'],\n",
       "  ['oubliez'],\n",
       "  ['avait'],\n",
       "  ['rien'],\n",
       "  ['dis'],\n",
       "  [\"Qu'\"],\n",
       "  ['ce'],\n",
       "  ['là'],\n",
       "  ['moi'],\n",
       "  ['mouton'],\n",
       "  ['ose'],\n",
       "  ['sortis'],\n",
       "  ['répondit'],\n",
       "  ['ça'],\n",
       "  ['fait'],\n",
       "  ['rien'],\n",
       "  ['moi'],\n",
       "  ['mouton'],\n",
       "  ['refis'],\n",
       "  ['veux'],\n",
       "  ['boa'],\n",
       "  ['est'],\n",
       "  ['dangereux'],\n",
       "  ['est'],\n",
       "  ['petit'],\n",
       "  ['moi'],\n",
       "  ['mouton'],\n",
       "  ['dessiné'],\n",
       "  ['regarda'],\n",
       "  ['est'],\n",
       "  ['malade'],\n",
       "  ['en'],\n",
       "  ['autre'],\n",
       "  ['ami'],\n",
       "  ['sourit'],\n",
       "  ['vois'],\n",
       "  ['est'],\n",
       "  ['mouton'],\n",
       "  ['a'],\n",
       "  ['cornes'],\n",
       "  ['refis'],\n",
       "  ['dessin'],\n",
       "  ['est'],\n",
       "  ['vieux'],\n",
       "  ['veux'],\n",
       "  ['griffonnai'],\n",
       "  ['ça'],\n",
       "  ['est'],\n",
       "  ['caisse'],\n",
       "  ['est'],\n",
       "  ['tu'],\n",
       "  ['ça'],\n",
       "  ['suffira'],\n",
       "  ['donné'],\n",
       "  ['mouton'],\n",
       "  ['pencha'],\n",
       "  ['tête'],\n",
       "  ['endormi'],\n",
       "  ['fallut'],\n",
       "  ['semblait'],\n",
       "  ['sont'],\n",
       "  ['dessinerai'],\n",
       "  ['avion'],\n",
       "  ['demanda'],\n",
       "  [\"qu'\"],\n",
       "  ['ce'],\n",
       "  ['est'],\n",
       "  ['chose'],\n",
       "  ['Ça'],\n",
       "  ['vole'],\n",
       "  ['est'],\n",
       "  ['avion'],\n",
       "  ['est'],\n",
       "  ['avion'],\n",
       "  ['tombé'],\n",
       "  ['je'],\n",
       "  ['Ça'],\n",
       "  ['est'],\n",
       "  ['drôle'],\n",
       "  ['désire'],\n",
       "  ['aussi'],\n",
       "  ['viens'],\n",
       "  ['tu'],\n",
       "  ['entrevis'],\n",
       "  ['lueur'],\n",
       "  ['viens'],\n",
       "  ['hochait'],\n",
       "  ['tête'],\n",
       "  ['est'],\n",
       "  ['vrai'],\n",
       "  ['imaginez'],\n",
       "  ['efforçai'],\n",
       "  ['où'],\n",
       "  ['tu'],\n",
       "  ['bonhomme'],\n",
       "  ['ce'],\n",
       "  ['tu'],\n",
       "  ['répondit'],\n",
       "  ['bien'],\n",
       "  ['est'],\n",
       "  ['sûr'],\n",
       "  ['piquet'],\n",
       "  ['proposition'],\n",
       "  ['parut'],\n",
       "  ['idée'],\n",
       "  ['où'],\n",
       "  ['prince'],\n",
       "  ['remarqua'],\n",
       "  ['ça'],\n",
       "  ['fait'],\n",
       "  ['rien'],\n",
       "  ['peut']],\n",
       " 6: ['vécues',\n",
       "  ['dessin'],\n",
       "  ['peur'],\n",
       "  ['explications'],\n",
       "  ['avions'],\n",
       "  ['conservé'],\n",
       "  ['compréhensive'],\n",
       "  ['mort'],\n",
       "  ['habitée'],\n",
       "  ['modèle'],\n",
       "  ['étonnement'],\n",
       "  ['étais'],\n",
       "  ['prince'],\n",
       "  ['moi'],\n",
       "  ['loin'],\n",
       "  ['perdra'],\n",
       "  ['aille']],\n",
       " 3: ['livre',\n",
       "  ['bouger'],\n",
       "  ['1'],\n",
       "  ['ça'],\n",
       "  ['oeuvre'],\n",
       "  ['personnes'],\n",
       "  ['explications'],\n",
       "  ['2'],\n",
       "  ['ça'],\n",
       "  ['métier'],\n",
       "  ['vie'],\n",
       "  ['personnes'],\n",
       "  ['près'],\n",
       "  ['portée'],\n",
       "  ['panne'],\n",
       "  ['ans'],\n",
       "  ['moteur'],\n",
       "  ['moi'],\n",
       "  ['jours'],\n",
       "  ['sable'],\n",
       "  ['pieds'],\n",
       "  ['personnes'],\n",
       "  ['désobéir'],\n",
       "  ['poche'],\n",
       "  ['lui'],\n",
       "  ['fermé'],\n",
       "  ['éléphant'],\n",
       "  ['boa'],\n",
       "  ['encombrant'],\n",
       "  ['moi'],\n",
       "  ['besoin'],\n",
       "  ['mouton'],\n",
       "  ['là'],\n",
       "  ['indulgence'],\n",
       "  ['bélier'],\n",
       "  ['là'],\n",
       "  ['longtemps'],\n",
       "  ['patience'],\n",
       "  ['lançai'],\n",
       "  ['fait'],\n",
       "  ['ça'],\n",
       "  ['voulais'],\n",
       "  ['dessin'],\n",
       "  ['miennes'],\n",
       "  ['ciel'],\n",
       "  ['ajouta'],\n",
       "  ['ciel'],\n",
       "  ['planète'],\n",
       "  ['brusquement'],\n",
       "  ['planète'],\n",
       "  ['pas'],\n",
       "  ['toi'],\n",
       "  ['mouton'],\n",
       "  ['prince'],\n",
       "  ['attacher'],\n",
       "  ['loin']],\n",
       " 1: ['Ensuite',\n",
       "  ['plus'],\n",
       "  ['pourquoi'],\n",
       "  ['pas'],\n",
       "  ['toujours'],\n",
       "  ['ainsi'],\n",
       "  ['jamais'],\n",
       "  ['Alors'],\n",
       "  ['Alors'],\n",
       "  ['hein'],\n",
       "  ['pas'],\n",
       "  ['donc'],\n",
       "  ['pas'],\n",
       "  ['Et'],\n",
       "  ['pas'],\n",
       "  ['non'],\n",
       "  ['Non'],\n",
       "  ['pas'],\n",
       "  ['Alors'],\n",
       "  ['attentivement'],\n",
       "  ['non'],\n",
       "  ['Je'],\n",
       "  ['gentiment'],\n",
       "  ['bien'],\n",
       "  ['pas'],\n",
       "  ['donc'],\n",
       "  ['encore'],\n",
       "  ['Alors'],\n",
       "  ['dedans'],\n",
       "  ['pourquoi'],\n",
       "  ['sûrement'],\n",
       "  ['Tiens'],\n",
       "  ['longtemps'],\n",
       "  ['jamais'],\n",
       "  ['Ainsi'],\n",
       "  ['pas'],\n",
       "  ['pas'],\n",
       "  ['Alors'],\n",
       "  ['comment'],\n",
       "  ['oui'],\n",
       "  ['modestement'],\n",
       "  ['ah'],\n",
       "  ['alors'],\n",
       "  ['aussitôt'],\n",
       "  ['donc'],\n",
       "  ['doucement'],\n",
       "  ['donc'],\n",
       "  ['Où'],\n",
       "  ['ce'],\n",
       "  ['Et'],\n",
       "  ['Alors'],\n",
       "  ['gravement'],\n",
       "  ['pas']],\n",
       " 7: ['digestion',\n",
       "  ['sérieux'],\n",
       "  ['peur'],\n",
       "  ['répondre'],\n",
       "  ['trésor'],\n",
       "  ['planètes']],\n",
       " 5: ['jungle',\n",
       "  ['comprendre'],\n",
       "  ['peintre'],\n",
       "  ['arizona'],\n",
       "  ['nuit'],\n",
       "  ['vierges'],\n",
       "  ['cravates'],\n",
       "  ['sahara'],\n",
       "  ['boire'],\n",
       "  ['océan'],\n",
       "  ['foudre'],\n",
       "  ['gravement'],\n",
       "  ['peintre'],\n",
       "  ['ans'],\n",
       "  ['sérieuse'],\n",
       "  ['mouton'],\n",
       "  ['venait'],\n",
       "  ['beaucoup'],\n",
       "  ['sérieux'],\n",
       "  ['présence'],\n",
       "  ['longtemps'],\n",
       "  ['donnée'],\n",
       "  ['maison'],\n",
       "  ['rire']],\n",
       " 9: ['grammaire', ['difficile'], ['juge'], ['volais']],\n",
       " 8: ['2',\n",
       "  ['raisonnable'],\n",
       "  ['ouverts'],\n",
       "  ['habitée'],\n",
       "  ['dessiner'],\n",
       "  ['moteur'],\n",
       "  ['jour']],\n",
       " 10: ['habitée', ['mort']]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e70af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(1,10):\n",
    "    \n",
    "    # Read the contents of the text file\n",
    "    with open(f\"/home/co/code/data/syntax_new_untested/run{i}_v2_0.25_0.5-tokenized.syntax.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Define the pattern to match substrings like (PONCT 3=,)\n",
    "    pattern = r'\\(PONCT\\s\\d+[^)]*\\)'\n",
    "    # Remove the substrings using re.sub()\n",
    "    clean_text = re.sub(pattern, '', text)\n",
    "\n",
    "    clean_text\n",
    "    # Write the cleaned text back to the file\n",
    "    with open(f\"/home/co/code/data/syntax_new_no_punct/run{i}_v2_0.25_0.5-tokenized.syntax.txt\", \"w\") as file:\n",
    "        file.write(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4704fdf",
   "metadata": {},
   "source": [
    "# Testing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4454fd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoching for run 1, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 89000 ... 554999 =     89.000 ...   554.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Reading 0 ... 465999  =      0.000 ...   465.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "def mne_events(meta, raw, start, level):\n",
    "    if start=='onset':\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = meta.start * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "    elif start=='offset':\n",
    "        events = np.ones((len(meta), 3), dtype=int)\n",
    "        events[:, 0] = (meta.start+meta.duration) * raw.info[\"sfreq\"]\n",
    "        return dict(events=events, metadata=meta.reset_index())\n",
    "        \n",
    "    else:\n",
    "        print('start should be either onset or offset')\n",
    "        return 0\n",
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 1\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "levels = ('word')\n",
    "starts = ('onset')\n",
    "            \n",
    "for subject in subjects[2:3]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max() # TO Verify!\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max() # TO Verify!\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799f565",
   "metadata": {},
   "source": [
    "# Initial Plotting for ERPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a572b284",
   "metadata": {},
   "source": [
    "### 0.5\n",
    "\n",
    "Just the evoked, for all conditions, all subjects:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb924f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It is currently being done by keeping all the epochs in memory: might want to do like in the #1, and generate the evo\n",
    "# or score from the epochs (for a subject), and from there try\n",
    "# To find a way to, starting with an array of evoked, average them!!!\n",
    "from dataset import read_raw, get_subjects, get_path, mne_events\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "# Dict init\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            dict_epochs[epoch_key] = [] \n",
    "            \n",
    "for subject in subjects[2:5]:\n",
    "    all_epochs = []\n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "\n",
    "        # Word end\n",
    "        meta['word_offset'] = True\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Sent stop\n",
    "        meta['next_word_id'] = meta['word_id'].shift(-1)\n",
    "        meta['sentence_offset'] = meta.apply(lambda x: True if x['word_id'] > x['next_word_id'] else False, axis=1)\n",
    "        meta['sentence_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_word_id', axis=1, inplace=True)\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: True if x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1 else False, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "\n",
    "        # Const stop\n",
    "        meta['next_closing'] = meta['n_closing'].shift(-1)\n",
    "        meta['constituent_offset'] = meta.apply(lambda x: True if x['n_closing'] > x['next_closing'] else False, axis=1)\n",
    "        meta['constituent_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_closing', axis=1, inplace=True)\n",
    "\n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            for level in ('sentence', 'constituent', 'word'):\n",
    "                # Select only the rows containing the True for the conditions (sentence_end, etc..)\n",
    "                sel = meta.query(f'{level}_{start}==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw), decim = 10,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop',\n",
    "                                            preload=True)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "            \n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "\n",
    "# Once we have the dict of epochs per condition full, we can concatenate them, and fix the dev_head             \n",
    "for start_ in ('onset', 'offset'): \n",
    "    for level_ in ('word', 'constituent', 'sentence'):\n",
    "        epoch_key = f'{level_}_{start_}'\n",
    "        all_epochs_chosen = dict_epochs[epoch_key]\n",
    "        # Concatenate epochs\n",
    "        for epo in all_epochs_chosen:\n",
    "            epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "        dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "            \n",
    "dict_evos = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "# Dict init\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            dict_evos[epoch_key] = [] \n",
    "\n",
    "# Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "for start in ('onset', 'offset'): \n",
    "        for level in ('word', 'constituent', 'sentence'):  \n",
    "            epoch_key = f'{level}_{start}'\n",
    "            epochs = dict_epochs[epoch_key]\n",
    "            # mean\n",
    "            evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "            dict_evos[epoch_key] = evo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740163c2",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e5db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for level in ('word', 'constituent', 'sentence'):\n",
    "    for start in ('onset', 'offset'):        \n",
    "            epoch_key = f'{level}_{start}'\n",
    "            print(f\"Plotting for: {epoch_key}\")\n",
    "            dict_evos[epoch_key].plot(gfp=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb01a54",
   "metadata": {},
   "source": [
    "### #1\n",
    "First plot: 3x2 plot, that shows:\n",
    "- From the onset, and offset of {word, constituent, sentence}:\n",
    "\n",
    "The evoked potential linked to it, as well as the decoding of the word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15915c86",
   "metadata": {},
   "source": [
    "# Test on words offset only # Done\n",
    "\n",
    "# Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07fb212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoching for run 1, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 89000 ... 554999 =     89.000 ...   554.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Reading 0 ... 465999  =      0.000 ...   465.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1407 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1407 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "434 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 434 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "132 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 132 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1407 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1407 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "434 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 434 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "132 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 132 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "\n",
      " Epoching for run 2, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-02_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 8000 ... 514999 =      8.000 ...   514.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-02_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-02_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 134 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Reading 0 ... 506999  =      0.000 ...   506.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1559 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1559 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "456 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 456 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "123 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 123 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1559 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1559 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "456 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 456 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "123 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 123 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 3, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-03_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 7000 ... 567999 =      7.000 ...   567.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-03_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-03_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 130 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Reading 0 ... 560999  =      0.000 ...   560.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1653 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1653 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "505 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 505 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "155 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 155 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1653 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1653 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "505 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 505 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "155 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 155 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 4, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-04_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 9000 ... 500999 =      9.000 ...   500.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-04_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-04_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19]\n",
      "Reading 0 ... 491999  =      0.000 ...   491.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1437 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1437 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "440 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 440 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "131 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 131 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1437 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1437 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "440 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 440 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "131 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 131 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 5, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-05_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 14000 ... 469999 =     14.000 ...   469.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-05_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-05_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 136 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 20]\n",
      "Reading 0 ... 455999  =      0.000 ...   455.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1334 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1334 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "395 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 395 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "149 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 149 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1334 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1334 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "395 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 395 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "149 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 149 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 6, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-06_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 7000 ... 575999 =      7.000 ...   575.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-06_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-06_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 134 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1699 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Reading 0 ... 568999  =      0.000 ...   568.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "1695 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1695 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "488 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 488 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "179 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 179 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "1695 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1695 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "488 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 488 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "179 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 179 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 7, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-07_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 12000 ... 529999 =     12.000 ...   529.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-07_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-07_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 133 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Reading 0 ... 517999  =      0.000 ...   517.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "1552 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1552 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "493 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 493 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "173 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 173 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "1552 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1552 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "493 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 493 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 28 columns\n",
      "173 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 173 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 8, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-08_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 8000 ... 460999 =      8.000 ...   460.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-08_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-08_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 106 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 19 21]\n",
      "Reading 0 ... 452999  =      0.000 ...   452.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1311 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1311 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "399 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 399 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "119 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 119 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1311 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1311 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "399 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 399 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "119 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 119 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "\n",
      " Epoching for run 9, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-09_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 8000 ... 551999 =      8.000 ...   551.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-09_events.tsv.\n",
      "Reading channel info from /home/co/data/LPP_MEG_visual/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-09_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Omitted 151 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "Reading 0 ... 543999  =      0.000 ...   543.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1570 matching events found\n",
      "-0.3 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-300.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1570 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "496 matching events found\n",
      "-0.5 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-500.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 496 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "157 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 157 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "1570 matching events found\n",
      "-1.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-1000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1570 events and 1301 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "496 matching events found\n",
      "-2.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-2000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 496 events and 2501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n",
      "Multiple event values for single event times found. Keeping the first occurrence and dropping all others.\n",
      "Adding metadata with 28 columns\n",
      "157 matching events found\n",
      "-4.0 1000.0\n",
      "<class 'float'> <class 'float'>\n",
      "-4000.0\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 157 events and 5001 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/miniconda3/envs/meg-masc/lib/python3.10/site-packages/pandas/core/series.py:893: RuntimeWarning: invalid value encountered in cast\n",
      "  return np.asarray(self._values, dtype)\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
      "/tmp/ipykernel_52686/2944078471.py:86: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=100 parameter will result in a sampling frequency of 10.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "13511 matching events found\n",
      "-0.3 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-3.0\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "4099 matching events found\n",
      "-0.5 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-5.0\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "1308 matching events found\n",
      "-1.0 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-10.0\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "13511 matching events found\n",
      "-1.0 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-10.0\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "4099 matching events found\n",
      "-2.0 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-20.0\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52686/2944078471.py:107: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 28 columns\n",
      "1308 matching events found\n",
      "-4.0 10.0\n",
      "<class 'numpy.float64'> <class 'float'>\n",
      "-40.0\n",
      "No baseline correction applied\n",
      "............................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mword\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m word: nlp(word)\u001b[38;5;241m.\u001b[39mvector)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    123\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([emb \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m embeddings])\n\u001b[0;32m--> 124\u001b[0m R_vec \u001b[38;5;241m=\u001b[39m \u001b[43mdecod_xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(R_vec, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(scores):\n",
      "File \u001b[0;32m~/workspace_LPP/code/neurospin-petit-prince/decoding/local_testing/utils.py:492\u001b[0m, in \u001b[0;36mdecod_xy\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# y_pred = cross_val_predict(model, X[:, :, t], y, cv=cv)\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X):\n\u001b[0;32m--> 492\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X[test, :, t])\n\u001b[1;32m    494\u001b[0m     r \u001b[38;5;241m=\u001b[39m correlate(y[test], y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2169\u001b[0m, in \u001b[0;36m_BaseRidgeCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2159\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m _RidgeGCV(\n\u001b[1;32m   2160\u001b[0m         alphas,\n\u001b[1;32m   2161\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m         alpha_per_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_per_target,\n\u001b[1;32m   2168\u001b[0m     )\n\u001b[0;32m-> 2169\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39malpha_\n\u001b[1;32m   2171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2010\u001b[0m, in \u001b[0;36m_RidgeGCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2007\u001b[0m best_coef, best_score, best_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas)):\n\u001b[0;32m-> 2010\u001b[0m     G_inverse_diag, c \u001b[38;5;241m=\u001b[39m \u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqrt_sw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecomposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m   2012\u001b[0m         squared_errors \u001b[38;5;241m=\u001b[39m (c \u001b[38;5;241m/\u001b[39m G_inverse_diag) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1919\u001b[0m, in \u001b[0;36m_RidgeGCV._solve_svd_design_matrix\u001b[0;34m(self, alpha, y, sqrt_sw, X_mean, singvals_sq, U, UT_y)\u001b[0m\n\u001b[1;32m   1917\u001b[0m     w[intercept_dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1918\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(U, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diag_dot(w, UT_y)) \u001b[38;5;241m+\u001b[39m (alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m y\n\u001b[0;32m-> 1919\u001b[0m G_inverse_diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decomp_diag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;66;03m# handle case where y is 2-d\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m     G_inverse_diag \u001b[38;5;241m=\u001b[39m G_inverse_diag[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1619\u001b[0m, in \u001b[0;36m_RidgeGCV._decomp_diag\u001b[0;34m(v_prime, Q)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decomp_diag\u001b[39m(v_prime, Q):\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;66;03m# compute diagonal of the matrix: dot(Q, dot(diag(v_prime), Q^T))\u001b[39;00m\n\u001b[0;32m-> 1619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mv_prime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy, mne_events\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "levels = ('word','constituent','sentence')\n",
    "starts = ('onset', 'offset')\n",
    "            \n",
    "for subject in subjects[2:6]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in starts: \n",
    "            for level in levels:\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_start'] = meta.start\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max() # TO Verify!\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max() # TO Verify!\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "\n",
    "        for start in starts: \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            # for level in ('sentence', 'constituent', 'word'):\n",
    "            for level in levels:\n",
    "                \n",
    "                # Select only the rows containing the True for the conditions\n",
    "                # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "                sel = meta.query(f'{level}_onset==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                # Making sure there is not hidden bug when matching\n",
    "                assert sel.shape[0] > 0.8 *  (meta.query(f'{level}_onset==True')).shape[0]\n",
    "\n",
    "                # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "                # Function will epoch on the offset of each level instead of the onset\n",
    "                # TODO: add adaptative baseline\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop', # check event repeated\n",
    "                                            preload=True,\n",
    "                                                baseline=None)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "\n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in starts: \n",
    "        for level_ in levels:\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "\n",
    "    # Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "    for start in starts: \n",
    "        for level in levels:\n",
    "            epoch_key = f'{level}_{start}'\n",
    "            epochs = dict_epochs[epoch_key]\n",
    "            # mean\n",
    "            evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "            all_evos.append(dict(subject=subject, evo=evo, start=start, level=level))\n",
    "\n",
    "\n",
    "            # decoding word emb\n",
    "            epochs = epochs.load_data().pick_types(meg=True, stim=False, misc=False)\n",
    "            X = epochs.get_data()\n",
    "            embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "            embeddings = np.array([emb for emb in embeddings])\n",
    "            R_vec = decod_xy(X, embeddings)\n",
    "            scores = np.mean(R_vec, axis=1)\n",
    "\n",
    "            for t, score in enumerate(scores):\n",
    "                all_scores.append(dict(subject=subject, score=score, start=start, level=level, t=epochs.times[t]))\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores)\n",
    "all_evos = pd.DataFrame(all_evos)\n",
    "\n",
    "all_scores.to_csv('./score.csv')\n",
    "all_evos.to_csv('./evos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e983491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(all_scores)\n",
    "all_evos = pd.DataFrame(all_evos)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(16, 10), dpi=80)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2)\n",
    "\n",
    "for axes_, level in zip( axes, levels):  \n",
    "    for ax, start in zip( axes_, starts):  \n",
    "        cond1 = all_scores.level==f'{level}'\n",
    "        cond2 = all_scores.start==f'{start}'\n",
    "        data = all_scores[ cond1 & cond2]\n",
    "        y = []\n",
    "        x = []\n",
    "        for s, t in data.groupby('t'):\n",
    "            score_avg = t.score.mean()\n",
    "            y.append(score_avg)\n",
    "            x.append(s)\n",
    "\n",
    "        ax.plot(x,y)\n",
    "        ax.set_title(f'{level} {start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67755eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel[['word','start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11151285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import read_raw, get_subjects, get_path\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 9\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "\n",
    "            \n",
    "for subject in subjects[2]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,2):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "        meta['word_stop'] = meta.start + meta.duration\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "        \n",
    "        # Adding the sentence stop info\n",
    "        meta['sentence_id'] = np.cumsum(meta.sentence_onset)\n",
    "        for s, d in meta.groupby('sentence_id'):\n",
    "            meta.loc[d.index, 'sent_word_id'] = range(len(d))\n",
    "            meta.loc[d.index, 'sentence_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'sentence_stop'] = d.start.max()\n",
    "            \n",
    "        # Adding the constituents stop info\n",
    "        meta['constituent_id'] = np.cumsum(meta.constituent_onset)\n",
    "        for s, d in meta.groupby('constituent_id'):\n",
    "            meta.loc[d.index, 'constituent_start'] = d.start.min()\n",
    "            meta.loc[d.index, 'constituent_stop'] = d.start.max()\n",
    "            meta.loc[d.index, 'const_word_id'] = range(len(d))\n",
    "        print(meta.head(50))\n",
    "        \n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            # for level in ('sentence', 'constituent', 'word'):\n",
    "            level = 'word'\n",
    "                \n",
    "            # Select only the rows containing the True for the conditions\n",
    "            # Simplified to only get for the onset: sentence onset epochs, constituent onset epochs,etc\n",
    "            sel = meta.query(f'{level}_onset==True')\n",
    "            assert sel.shape[0] > 10  #\n",
    "            # TODO check variance as well for sentences\n",
    "            # Matchlist events and meta\n",
    "            # So that we can epoch now that's we've sliced our metadata\n",
    "            i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "            sel = sel.reset_index().loc[j]\n",
    "            # Making sure there is not hidden bug when matching\n",
    "            assert sel.shape[0] > 0.8 *  (meta.query(f'{level}_onset==True')).shape[0]\n",
    "\n",
    "            # Epoching from the metadata having all onset events: if the start=Offset, the mne events\n",
    "            # Function will epoch on the offset of each level instead of the onset\n",
    "            # TODO: add adaptative baseline\n",
    "            epochs = mne.Epochs(raw, **mne_events(sel, raw ,start=start, level=level), decim = 100,\n",
    "                                 tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                   tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                     event_repeated = 'drop', # check event repeated\n",
    "                                        preload=True,\n",
    "                                            baseline=None)  # n_words OR n_constitutent OR n_sentences\n",
    "            epoch_key = f'{level}_{start}'\n",
    "\n",
    "            dict_epochs[epoch_key].append(epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9906493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72a766",
   "metadata": {},
   "source": [
    "### #4 \n",
    "Now baselined on offset, no matter whether it's on onset or offset window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c77b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824fb580",
   "metadata": {},
   "source": [
    "### #5 \n",
    "Submitit-compatible version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1494a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install submitit\n",
    "import submitit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621358ab",
   "metadata": {},
   "source": [
    "# Jitter test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3507de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_bids\n",
    "import mne\n",
    "from pathlib import Path\n",
    "subject = '5'\n",
    "run_id = 1\n",
    "path = get_path(\"LPP_read\")\n",
    "task = \"read\"\n",
    "print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "events_  = events[:,0] / raw.info[\"sfreq\"]\n",
    "diffs = np.diff(events_)\n",
    "x,y = np.unique(diffs, return_counts=True)\n",
    "plt.plot(x,y)\n",
    "plt.xlim([0.2,0.3])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa654f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.copy().pick_types(meg=False, stim=True).plot(start=50, duration=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566943",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw, stim_channel=\"STI002\", shortest_event=1)\n",
    "events_  = events[:,0] / raw.info[\"sfreq\"]\n",
    "diffs = np.diff(events_)\n",
    "x,y = np.unique(diffs, return_counts=True)\n",
    "plt.plot(x,y)\n",
    "plt.xlim([0.2,0.4])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "meta = epochs.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb0fef",
   "metadata": {},
   "source": [
    "# Testing decoding more and more difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import word_epochs_debug, get_path, get_subjects, sentence_epochs_debug\n",
    "from utils import decod\n",
    "from plot import plot_R\n",
    "import mne\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "subjects = subjects[:2]\n",
    "\n",
    "# WORDS\n",
    "all_epochs = []\n",
    "for sub in subjects:\n",
    "\n",
    "    epochs = sentence_epochs_debug(sub, 3)\n",
    "    all_epochs.append(epochs)\n",
    "\n",
    "for epo in all_epochs:\n",
    "    epo.info[\"dev_head_t\"] = all_epochs[1].info[\"dev_head_t\"]\n",
    "\n",
    "epochs = mne.concatenate_epochs(all_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "from utils import correlate\n",
    "\n",
    "def decod(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    # define data\n",
    "    model = make_pipeline(StandardScaler(), RidgeCV(alphas=np.logspace(-1, 6, 10)))\n",
    "    cv = KFold(15, shuffle=True, random_state=0)\n",
    "\n",
    "    # fit predict\n",
    "    n, n_chans, n_times = X.shape\n",
    "    if y.ndim == 1:\n",
    "        y = np.asarray(y).reshape(y.shape[0], 1)\n",
    "    R = np.zeros((n_times, y.shape[1]))\n",
    "\n",
    "    for t in range(n_times):\n",
    "        print(\".\", end=\"\")\n",
    "        rs = []\n",
    "        # y_pred = cross_val_predict(model, X[:, :, t], y, cv=cv)\n",
    "        for train, test in cv.split(X):\n",
    "            model.fit(X[train, :, t], y[train])\n",
    "            y_pred = model.predict(X[test, :, t])\n",
    "            r = correlate(y[test], y_pred)\n",
    "            rs.append(r)\n",
    "        R[t] = np.mean(rs)\n",
    "        # R[t] = correlate(y, y_pred)\n",
    "\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d520c21",
   "metadata": {},
   "source": [
    "# LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54996ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_code_path\n",
    "\n",
    "run_id = 1\n",
    "CHAPTERS = {\n",
    "1: \"1-3\",\n",
    "2: \"4-6\",\n",
    "3: \"7-9\",\n",
    "4: \"10-12\",\n",
    "5: \"13-14\",\n",
    "6: \"15-19\",\n",
    "7: \"20-22\",\n",
    "8: \"23-25\",\n",
    "9: \"26-27\",\n",
    "}\n",
    "\n",
    "meta = epochs.metadata\n",
    "\n",
    "# # laser embeddings information\n",
    "dim = 1024\n",
    "embeds = np.fromfile(\n",
    "    f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "    dtype=np.float32,\n",
    "    count=-1,\n",
    ")\n",
    "embeds.resize(embeds.shape[0] // dim, dim)\n",
    "print(meta.shape[0])\n",
    "embeds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23935db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = epochs[]\n",
    "X = epochs.get_data()\n",
    "y = epochs.metadata.word.apply(len)\n",
    "R_vec = decod(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0203d6",
   "metadata": {},
   "source": [
    "## Word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cdd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the STIM information before decoding it (or else we'll get a 100% accuracy since the word length info is in the STIM channels)\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "X = epochs.get_data()\n",
    "y = epochs.metadata.word.apply(len)\n",
    "R_vec = decod(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f798f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_R(R_vec.reshape(-1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf385dc",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becba2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "X = epochs.get_data()\n",
    "embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "embeddings = np.array([emb for emb in embeddings])\n",
    "R_vec = decod(X, embeddings)\n",
    "R_vec = np.mean(R_vec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_R(R_vec.reshape(-1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799fbc7",
   "metadata": {},
   "source": [
    "## Laser embeddings with JR baseline fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29290403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_stop_data.shape\n",
    "baseline_starts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_starts = epochs['word_id==0'].apply_baseline((-.300, 0.))\n",
    "sent_starts.average().plot()\n",
    "\n",
    "sent_stops = epochs['is_last_word']\n",
    "bsl = (epochs.times>-.300 )*(epochs.times<=0)\n",
    "baseline_starts = sent_starts.get_data()[:, :, bsl].mean(-2)\n",
    "\n",
    "sent_stop_data = sent_stops.get_data()\n",
    "n_sentences, n_channels, n_times = sent_stop_data.shape\n",
    "sent_stop_data -= baseline_starts[:, :, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c02e3a",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ce669",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metaepochs.metadata.word.apply(len)\n",
    "decoding_criterion = \"n_closing\"\n",
    "R_vec = decod(epochs, decoding_criterion)\n",
    "\n",
    "fig = plot_R(R_vec)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb3d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce49ba49",
   "metadata": {},
   "source": [
    "# Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, word_epochs, sentence_epochs\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import mne\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "mne.set_log_level(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = mne.Report()\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "evos = []\n",
    "\n",
    "# WORDS\n",
    "subjects = subjects[2]\n",
    "epochs = word_epochs(subjects)\n",
    "\n",
    "evo = epochs.average(method=\"median\")\n",
    "evos.append(evo)\n",
    "evo.plot(spatial_colors=True)\n",
    "report.add_evokeds(evo, titles=f\"Evoked for condition word  \")\n",
    "\n",
    "\n",
    "# SENTENCES\n",
    "epochs = sentence_epochs(subjects)\n",
    "\n",
    "evo = epochs.average(method=\"median\")\n",
    "evos.append(evo)\n",
    "evo.plot(spatial_colors=True)\n",
    "report.add_evokeds(evo, titles=f\"Evoked for condition sentence  \")\n",
    "\n",
    "\n",
    "evokeds = dict(sentence=evos[1], word=evos[0])\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\")\n",
    "\n",
    "report.add_figure(fig, title=\"Evoked response comparaison\")\n",
    "\n",
    "\n",
    "report.save(\n",
    "    f\"./figures/{task}_sentvsword_test.html\",\n",
    "    open_browser=False,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc17c75",
   "metadata": {},
   "source": [
    "# Test new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import word_epochs\n",
    "\n",
    "sub = '3'\n",
    "\n",
    "epochs = word_epochs(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca576c",
   "metadata": {},
   "source": [
    "\n",
    "# Debug events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8123ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mne\n",
    "from utils import match_list\n",
    "from dataset import mne_events\n",
    "from utils import add_syntax\n",
    "\n",
    "\n",
    "CHAPTERS = {\n",
    "    1: \"1-3\",\n",
    "    2: \"4-6\",\n",
    "    3: \"7-9\",\n",
    "    4: \"10-12\",\n",
    "    5: \"13-14\",\n",
    "    6: \"15-19\",\n",
    "    7: \"20-22\",\n",
    "    8: \"23-25\",\n",
    "    9: \"26-27\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fd7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "run_id = 1\n",
    "task = \"read\"\n",
    "subject = '3'\n",
    "baseline_min = -2.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "print(f\"\\n Epoching for run {run_id}, subject: {subject}\\n\")\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "raw.load_data()\n",
    "raw = raw.filter(0.5, 20)\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "# read events\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_copy = meta.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_syntax = get_code_path() / \"data/syntax\"\n",
    "\n",
    "# Enriching the metadata with outside files:\n",
    "meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "\n",
    "# Enriching the metadata with simple operations:\n",
    "\n",
    "# end of sentence information\n",
    "end_of_sentence = [\n",
    "    True\n",
    "    if str(meta.word.iloc[i]).__contains__(\".\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"?\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"!\")\n",
    "    else False\n",
    "    for i, _ in enumerate(meta.values[:-1])\n",
    "]\n",
    "end_of_sentence.append(True)\n",
    "meta[\"sentence_end\"] = end_of_sentence\n",
    "\n",
    "# sentence start information\n",
    "list_word_start = [True]\n",
    "list_word_start_to_add = [\n",
    "    True if meta.sentence_end.iloc[i - 1] else False\n",
    "    for i in np.arange(1, meta.shape[0])\n",
    "]\n",
    "for boolean in list_word_start_to_add:\n",
    "    list_word_start.append(boolean)\n",
    "meta[\"sentence_start\"] = list_word_start\n",
    "\n",
    "# laser embeddings information\n",
    "dim = 1024\n",
    "embeds = np.fromfile(\n",
    "    f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "    dtype=np.float32,\n",
    "    count=-1,\n",
    ")\n",
    "embeds.resize(embeds.shape[0] // dim, dim)\n",
    "assert embeds.shape[0] == meta.shape[0]\n",
    "meta[\"laser\"] = [emb for emb in embeds]\n",
    "\n",
    "# constituent end information\n",
    "meta[\"constituent_end\"] = [\n",
    "        True if closing > 1 else False for i, closing in enumerate(meta.n_closing)]\n",
    "\n",
    "# constituent start information\n",
    "list_constituent_start = [True]\n",
    "list_constituent_start_to_add = [\n",
    "    True if meta.constituent_end.iloc[i - 1] else False\n",
    "    for i in np.arange(1, meta.shape[0])\n",
    "]\n",
    "for boolean in list_constituent_start_to_add:\n",
    "    list_constituent_start.append(boolean)\n",
    "meta[\"constituent_start\"] = list_constituent_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_length_meg = events[:, 2]\n",
    "word_len_meta = meta.word.apply(len)\n",
    "i, j = match_list(word_len_meta, word_length_meg)\n",
    "events = events[j]\n",
    "assert len(i) / meta.shape[0] > 0.8\n",
    "meta = meta.iloc[i].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c337c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"start\"] = events[:, 0] / raw.info[\"sfreq\"]\n",
    "meta[\"condition\"] = \"sentence\"\n",
    "meta = meta.sort_values(\"start\").reset_index(drop=True)\n",
    "meta[\"word_start\"] = meta[\"start\"]\n",
    "meta[\"word_end\"] = meta[\"word_start\"] + meta[\"duration\"]\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw, **mne_events(meta, raw), decim=20, tmin=baseline_min, tmax=baseline_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feec9e4",
   "metadata": {},
   "source": [
    "# Plotting decoding info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743045da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plot import plot_subject\n",
    "\n",
    "from dataset import get_path, get_subjects, get_code_path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"read\"\n",
    "sub = 4\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "min = -4.0\n",
    "max = 0.5\n",
    "decoding_criterion = 'laser'\n",
    "path = get_code_path()\n",
    "# Format the file path\n",
    "\n",
    "# Open the pandas DataFrame containing the decoding values\n",
    "R = np.load(\n",
    "    (path) / f\"decoding/results/{task}/decoding_{decoding_criterion}_{epoch_on}_{reference}_{sub}.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42da6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad237f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(min, max, R.shape[0])  # To do better at generalizing\n",
    "fig, ax = plt.subplots(1, figsize=[6, 6])\n",
    "dec = plt.fill_between(times, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"read\"\n",
    "sub = 3\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\"\n",
    "min = -4.0\n",
    "max = 0.5\n",
    "decoding_criterion = 'laser'\n",
    "plot = plot_subject(sub, decoding_criterion, task, reference, epoch_on, min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3cdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a76bc3",
   "metadata": {},
   "source": [
    "# Debugging ERP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be218",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "baseline_min = -1.0\n",
    "baseline_max = 1.0\n",
    "task = \"read\"\n",
    "\n",
    "subjects = subjects[10]\n",
    "epochs2 = epoch_subjects(\n",
    "    subjects, RUN, task, path, baseline_max=baseline_max, baseline_min=baseline_min\n",
    ")\n",
    "\n",
    "epochs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044bba4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_subjects, epochs_slice\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "mne.set_log_level(False)\n",
    "\n",
    "# Later: integrate Hydra here as well. For now, just simple plotting of ERPS\n",
    "\n",
    "report = mne.Report()\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "baseline_min = -1.0\n",
    "baseline_max = 1.0\n",
    "task = \"read\"\n",
    "print(\"\\nSubjects for which the plotting will be done: \\n\")\n",
    "print(subjects)\n",
    "\n",
    "# DEBUG\n",
    "subjects = subjects[4]\n",
    "epochs_ = epoch_subjects(\n",
    "    subjects, RUN, task, path, baseline_max=baseline_max, baseline_min=baseline_min\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = [\"sentence\", \"word\", \"constituent\"]\n",
    "cases = {\"start\", \"end\"}\n",
    "\n",
    "# Plotting and adding to the report, the averaged ERPs of:\n",
    "# words, sentences and constituents, centered at the beginning and end of each\n",
    "\n",
    "\n",
    "# Need to map for:\n",
    "# - end of word,\n",
    "# - beginning of sentence (epochs[i+1] !danger limits)\n",
    "# - beginning of constituent (epochs[i+1] !same danger)\n",
    "\n",
    "evos = []\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        # Slice the epochs based on the epoch_criterion:\n",
    "        column_to_slice_on = f\"{condi}_{case}\"\n",
    "        if condi == \"sentence\" or condi == \"word\":  # eg: {sentence}_{end} or {word}_{start}\n",
    "            epochs = epochs_slice(epochs_, column_to_slice_on)\n",
    "        elif condi == \"constituent\":\n",
    "            epochs = epochs_slice(epochs_, column_to_slice_on, value=2, equal='sup')\n",
    "        evo = epochs.average(method=\"median\")\n",
    "        evos.append(evo)\n",
    "        evo.plot(spatial_colors=True)\n",
    "        report.add_evokeds(evo, titles=f\"Evoked for condition {column_to_slice_on}  \")\n",
    "\n",
    "evokeds = dict(sentence=evos[0], word=evos[2], constituent=evos[4])\n",
    "\n",
    "fig = mne.viz.plot_compare_evokeds(evokeds, combine=\"mean\")\n",
    "\n",
    "report.add_figure(fig, title=\"Evoked response comparaison\")\n",
    "\n",
    "\n",
    "report.save(\n",
    "    f\"./figures/{task}_ERP_all_cond.html\",\n",
    "    open_browser=False,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b61d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0419c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = epochs_slice(epochs_, 'sentence_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ae1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_subject\n",
    "\n",
    "from dataset import get_path, get_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "run = 1\n",
    "task = \"read\"\n",
    "subject = '17'\n",
    "baseline_min = -2.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5143d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06188ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset import epoch_data\n",
    "epo = epoch_data(\n",
    "    subject,\n",
    "    run,\n",
    "    task,\n",
    "    path,\n",
    "    baseline_min,\n",
    "    baseline_max,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54047baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import epochs_slice\n",
    "epos = epochs_slice(epo, 'sentence_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794e34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epos.average(method=\"median\")\n",
    "evo.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67a6a0",
   "metadata": {},
   "source": [
    "# GFP for sentence - epoching on sentence end and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_runs\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "\n",
    "# Tools\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "from utils import match_list, add_syntax\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 2\n",
    "task = \"read\"\n",
    "subject = subjects[1]\n",
    "baseline_min = -4.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1bca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(\n",
    "            subject,\n",
    "            RUN,\n",
    "            task,\n",
    "            path,\n",
    "            baseline_min,\n",
    "            baseline_max,\n",
    "            epoch_on=epoch_on,\n",
    "            reference=reference,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa8af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = 1\n",
    "from dataset import epoch_data\n",
    "epo = epoch_data(\n",
    "    subject,\n",
    "    run,\n",
    "    task,\n",
    "    path,\n",
    "    baseline_min=-0.2,\n",
    "    baseline_max=0.8,\n",
    "    filter=True,\n",
    "    epoch_on=\"word\",\n",
    "    reference=\"end\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06639bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = epo.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1596c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_code_path, get_path, mne_events\n",
    "\n",
    "run_id = RUN\n",
    "epoch_on = 'word'\n",
    "reference = \"start\"\n",
    "\n",
    "CHAPTERS = {\n",
    "    1: \"1-3\",\n",
    "    2: \"4-6\",\n",
    "    3: \"7-9\",\n",
    "    4: \"10-12\",\n",
    "    5: \"13-14\",\n",
    "    6: \"15-19\",\n",
    "    7: \"20-22\",\n",
    "    8: \"23-25\",\n",
    "    9: \"26-27\",\n",
    "}\n",
    "\n",
    "\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=RUN,\n",
    "    )\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.del_proj()  # To fix proj issues\n",
    "raw.pick_types(meg=True, stim=True)\n",
    "raw.load_data()\n",
    "raw = raw.filter(0.5, 20)\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "# read events\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "events = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "if (\n",
    "    bids_path.task == \"read\" and bids_path.subject == \"2\"\n",
    "):  # A trigger value bug for this subject\n",
    "    word_length_meg = (\n",
    "        events[:, 2] - 2048\n",
    "    )  # Remove first event: chapter start and remove offset\n",
    "else:\n",
    "    word_length_meg = events[:, 2]\n",
    "# Here, the trigger value encoded the word length\n",
    "# which helps us realign triggers\n",
    "# From the event file / from the MEG events\n",
    "word_len_meta = meta.word.apply(len)\n",
    "i, j = match_list(word_len_meta, word_length_meg)\n",
    "events = events[j]\n",
    "meta = meta.iloc[i].reset_index()\n",
    "print(meta.shape)\n",
    "# The start parameter will help us\n",
    "# keep the link between raw events and metadata\n",
    "meta[\"start\"] = events[:, 0] / raw.info[\"sfreq\"]\n",
    "meta[\"condition\"] = \"sentence\"\n",
    "meta = meta.sort_values(\"start\").reset_index(drop=True)\n",
    "\n",
    "# Raw LPP textual data\n",
    "path_txt = get_code_path() / \"data/txt_raw\"\n",
    "# LPP Syntax data\n",
    "path_syntax = get_code_path() / \"data/syntax\"\n",
    "\n",
    "# Enriching the metadata with outside files:\n",
    "meta = add_syntax(meta, path_syntax, int(run_id))\n",
    "print(meta.shape)\n",
    "# Add the information on the sentence ending:\n",
    "# Only works for reading: TO FIX for listening... to see with Christophe\n",
    "# Also: only works for v2 (subject 1 (me) doesn't work )\n",
    "\n",
    "# Test 1\n",
    "# end_of_sentence = [\n",
    "#     True if meta.onset.iloc[i + 1] - meta.onset.iloc[i] > 0.7 else False\n",
    "#     for i, _ in enumerate(meta.values[:-1])\n",
    "# ]\n",
    "# end_of_sentence.append(True)\n",
    "\n",
    "# Test 2\n",
    "end_of_sentence = [\n",
    "    True\n",
    "    if str(meta.word.iloc[i]).__contains__(\".\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"?\")\n",
    "    or str(meta.word.iloc[i]).__contains__(\"!\")\n",
    "    else False\n",
    "    for i, _ in enumerate(meta.values[:-1])\n",
    "]\n",
    "end_of_sentence.append(True)\n",
    "meta[\"sentence_end\"] = end_of_sentence\n",
    "\n",
    "# We are considering different cases:\n",
    "# Are we epoching on words, sentences, or constituents?\n",
    "# Different epoching for different analysis\n",
    "if epoch_on == \"word\" and reference == \"start\":\n",
    "    # Default case, so nothing to change\n",
    "    # Could be removed but kept for easy of reading\n",
    "    happy = True\n",
    "# Word end\n",
    "if epoch_on == \"word\" and reference == \"end\":\n",
    "    # Little hack: not really pretty but does the job\n",
    "    # As epoching again uses the start column, we rename it like that\n",
    "    # But it should be meta[\"end\"] instead...\n",
    "    meta[\"start\"] = [row[\"start\"] + row[\"duration\"] for i, row in meta.iterrows()]\n",
    "\n",
    "# Sentence end\n",
    "elif epoch_on == \"sentence\" and reference == \"end\":\n",
    "    # Add a LASER embeddings column for decoding\n",
    "    dim = 1024\n",
    "    embeds = np.fromfile(\n",
    "        f\"{get_code_path()}/data/laser_embeddings/emb_{CHAPTERS[int(run_id)]}.bin\",\n",
    "        dtype=np.float32,\n",
    "        count=-1,\n",
    "    )\n",
    "    embeds.resize(embeds.shape[0] // dim, dim)\n",
    "    column = \"sentence_end\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "    # TODO: create a match list between the embeds sentence and the\n",
    "    print(embeds.shape[0], meta.shape[0])\n",
    "    assert embeds.shape[0] == meta.shape[0]\n",
    "    meta[\"laser\"] = [emb for emb in embeds]\n",
    "    print(\"Added embeddings\")\n",
    "# Sentence start\n",
    "elif epoch_on == \"sentence\" and reference == \"start\":\n",
    "    # Create a sentence-start column:\n",
    "    # list_word_start = [\n",
    "    #     True\n",
    "    #     for i, is_last_word in enumerate(meta.is_last_word[:-1])\n",
    "    #     if meta.is_last_word[i + 1]\n",
    "    # ]\n",
    "    list_word_start = [True]\n",
    "    list_word_start_to_add = [\n",
    "        True if meta.sentence_end[i - 1] else False\n",
    "        for i, _ in enumerate(meta.sentence_end[1:])\n",
    "    ]\n",
    "    for boolean in list_word_start_to_add:\n",
    "        list_word_start.append(boolean)\n",
    "    meta[\"sentence_start\"] = list_word_start\n",
    "    column = \"sentence_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "# Constituent start\n",
    "elif epoch_on == \"constituent\" and reference == \"start\":\n",
    "    # Create a constituent-start column:\n",
    "    meta[\"constituent_start\"] = [\n",
    "        True for i, _ in enumerate(meta.is_last_word[1:]) if meta.n_closing > 1\n",
    "    ]\n",
    "    column = \"constituent_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "# Constituent end\n",
    "elif epoch_on == \"constituent\" and reference == \"end\":\n",
    "    # Create a constituent-start column:\n",
    "    meta[\"constituent_start\"] = [\n",
    "        True for i, _ in enumerate(meta.is_last_word[1:]) if meta.n_closing > 1\n",
    "    ]\n",
    "    column = \"constituent_start\"\n",
    "    value = True\n",
    "    meta = meta[meta[column] == value]\n",
    "epochs = mne.Epochs(\n",
    "    raw, **mne_events(meta, raw), decim=20, tmin=baseline_min, tmax=baseline_max\n",
    ")\n",
    "# epochs = epochs['kind==\"word\"']\n",
    "# epochs.metadata[\"closing\"] = epochs.metadata.closing_.fillna(0)\n",
    "epochs.load_data()\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False)\n",
    "data = epochs.get_data()\n",
    "\n",
    "# Scaling the data\n",
    "n_words, n_chans, n_times = data.shape\n",
    "vec = data.transpose(0, 2, 1).reshape(-1, n_chans)\n",
    "scaler = RobustScaler()\n",
    "idx = np.arange(len(vec))\n",
    "np.random.shuffle(idx)\n",
    "vec = scaler.fit(vec[idx[:20_000]]).transform(vec)\n",
    "# To try: sigmas = 7 or 15\n",
    "sigma = 7\n",
    "vec = np.clip(vec, -sigma, sigma)\n",
    "epochs._data[:, :, :] = (\n",
    "    scaler.inverse_transform(vec)\n",
    "    .reshape(n_words, n_times, n_chans)\n",
    "    .transpose(0, 2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad079b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_2 = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "events_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d315880",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbdc744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646dde6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d8b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a609b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995472f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255968bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785eb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c62475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a92e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52e158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685a43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d58005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import decod\n",
    "R_vec = decod(epochs, decoding_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905586b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.fill_between(epochs.times, R_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40765d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f47780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diff(epochs.metadata.onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8eb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e9edd",
   "metadata": {},
   "source": [
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482306bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.round(np.diff(epochs2.metadata.onset),3)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"{val} occurs {count} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.diff(epochs2.metadata.onset)>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cbf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcf368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d44ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f35cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9a8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dae2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_(epochs, column, value):\n",
    "    meta  = epochs.metadata\n",
    "    subset = meta[meta[column]==value].level_0\n",
    "    return epochs[subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs.metadata['n_closing'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69967734",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_(epochs,'is_last_word',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = {'sentence': {'column':'is_last_word','target':True},\n",
    "        'word': {'column':'kind','target':'word'},\n",
    "        'constituent': {'column':'n_closing','target':2}}\n",
    "\n",
    "cases = {'start', 'end'}\n",
    "\n",
    "i = 1\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        ep = epochs_(epochs, cond[condi]['column'], cond[condi]['target'])\n",
    "        ax = fig.add_subplot(3, 2, i)\n",
    "        #ep.average().plot(gfp='only')\n",
    "        evo = ep.average(method=\"median\")\n",
    "        evo.plot(spatial_colors=True)\n",
    "        i = i + 1\n",
    "        ax.set_title(f'Plot {cond}')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217312",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4 = epochs_(epochs, 'n_closing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4.average().plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs\n",
    "\n",
    "class CustomEpochs(Epochs):\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Parse the key into metadata field name and value\n",
    "        field, value = key.split('==')\n",
    "        field = field.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Get the indices of the epochs that match the metadata query\n",
    "        indices = [i for i, metadata in enumerate(self.metadata[field]) if metadata == value]\n",
    "\n",
    "        # Return a new Epochs object containing only the matching epochs\n",
    "        return self.__class__(self._data[indices], self.events[indices], self.event_id,\n",
    "                              tmin=self.tmin, tmax=self.tmax, baseline=self.baseline,\n",
    "                              metadata=self.metadata.iloc[indices], info=self.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs = CustomEpochs(epochs, epochs.events, \"1\", -0.2, 0.8, epochs.baseline, epochs.metadata)\n",
    "\n",
    "# Get all epochs where the 'kind' metadata field is 'word':\n",
    "word_epochs = custom_epochs['kind==word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07344132",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "def mne_events(meta):\n",
    "    events = np.ones((len(meta), 3), dtype=int)\n",
    "    events[:, 0] = meta.start*raw.info['sfreq']\n",
    "    return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "epochs = mne.Epochs(raw, **mne_events(meta), decim=20, tmin=-.2, tmax=1.5, preload=True)\n",
    "epochs = epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data, epoch_runs\n",
    "from utils import (\n",
    "    decod,\n",
    "    correlate,\n",
    "    match_list,\n",
    "    create_target,\n",
    "    analysis,\n",
    "    save_decoding_results,\n",
    ")\n",
    "from plot import plot_subject\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 9\n",
    "task = \"read\"\n",
    "subject = subjects[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856d515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs.metadata).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.load_data()\n",
    "epochs = epochs['kind==\"word\"']\n",
    "epochs[\"content_word == False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9cc25f465bce2bd58662313d1fe29f78ce66d40d6f2798a767eb1052c037478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
