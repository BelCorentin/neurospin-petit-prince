{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe12bcb",
   "metadata": {},
   "source": [
    "# Reformat the txt file for LASER handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e453f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Good code, to do for all chapers\\n# Test: for chapter 1, there are 132 lines\\nfrom dataset import get_code_path\\nimport numpy as np \\nimport re\\nfor chapter in np.arange(1,10):\\n\\n    with open(f\"{get_code_path()}/experiments/formatting/text_lpp/new_test_run{chapter}.txt\", \\'r\\') as file:\\n        data = file.read()\\n    text = \" \".join(data.split())\\n    # Split text into sentences with regex\\n    sentences = re.findall(r\\'[\\\\w\\\\s\\\\S]+?[.?!][\"\\']?(?=\\\\s|$)\\', text)\\n    with open(f\"{get_code_path()}/data/txt_laser/run{chapter}.txt\", \"w\") as file:\\n        for sentence in sentences:\\n            file.write(sentence + \\'\\n\\')\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Good code, to do for all chapers\n",
    "# Test: for chapter 1, there are 132 lines\n",
    "from dataset import get_code_path\n",
    "import numpy as np \n",
    "import re\n",
    "for chapter in np.arange(1,10):\n",
    "\n",
    "    with open(f\"{get_code_path()}/experiments/formatting/text_lpp/new_test_run{chapter}.txt\", 'r') as file:\n",
    "        data = file.read()\n",
    "    text = \" \".join(data.split())\n",
    "    # Split text into sentences with regex\n",
    "    sentences = re.findall(r'[\\w\\s\\S]+?[.?!][\"\\']?(?=\\s|$)', text)\n",
    "    with open(f\"{get_code_path()}/data/txt_laser/run{chapter}.txt\", \"w\") as file:\n",
    "        for sentence in sentences:\n",
    "            file.write(sentence + '\\n')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67a6a0",
   "metadata": {},
   "source": [
    "# GFP for sentence - epoching on sentence end and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_runs\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "task = \"read\"\n",
    "subject = subjects[1]\n",
    "baseline_min = -4.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327068d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      " Epoching for run 01, subject: 2\n",
      "\n",
      "Opening raw data file /home/co/data/BIDS_lecture/sub-2/ses-01/meg/sub-2_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 22000 ... 491999 =     22.000 ...   491.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/BIDS_lecture/sub-2/ses-01/meg/sub-2_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/BIDS_lecture/sub-2/ses-01/meg/sub-2_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 469999  =      0.000 ...   469.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Omitted 117 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger channel has a non-zero initial value of 2048 (consider using initial_event=True to detect this event)\n",
      "1467 events found\n",
      "Event IDs: [2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062\n",
      " 2063]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  Unnamed: 0     word  onset  duration  \\\n",
      "0         0           0  Lorsque    0.7      0.25   \n",
      "1         1           1  j'avais    1.0      0.25   \n",
      "2         2           2      six    1.3      0.25   \n",
      "3         3           3     ans,    1.6      0.25   \n",
      "4         4           4     j'ai    1.9      0.25   \n",
      "...     ...         ...      ...    ...       ...   \n",
      "1406   1459        1459       ne  508.9      0.25   \n",
      "1407   1460        1460     peut  509.2      0.25   \n",
      "1408   1461        1461      pas  509.5      0.25   \n",
      "1409   1462        1462    aller  509.8      0.25   \n",
      "1410   1463        1463     bien  510.1      0.25   \n",
      "\n",
      "                               trial_type    start condition  n_closing  \\\n",
      "0     {'kind': 'word', 'word': 'Lorsque'}   23.752  sentence          1   \n",
      "1      {'kind': 'word', 'word': 'javais'}   24.052  sentence          1   \n",
      "2         {'kind': 'word', 'word': 'six'}   24.302  sentence          1   \n",
      "3         {'kind': 'word', 'word': 'ans'}   24.585  sentence          4   \n",
      "4         {'kind': 'word', 'word': 'jai'}   24.852  sentence          1   \n",
      "...                                   ...      ...       ...        ...   \n",
      "1406       {'kind': 'word', 'word': 'ne'}  481.125  sentence          1   \n",
      "1407     {'kind': 'word', 'word': 'peut'}  481.409  sentence          2   \n",
      "1408      {'kind': 'word', 'word': 'pas'}  481.675  sentence          1   \n",
      "1409    {'kind': 'word', 'word': 'aller'}  481.941  sentence          2   \n",
      "1410     {'kind': 'word', 'word': 'bien'}  482.208  sentence          1   \n",
      "\n",
      "      is_last_word   pos  content_word  sentence_end  \n",
      "0            False    CS         False         False  \n",
      "1            False   XXX         False         False  \n",
      "2            False   DET         False         False  \n",
      "3            False    NC          True         False  \n",
      "4            False   XXX         False         False  \n",
      "...            ...   ...           ...           ...  \n",
      "1406         False   ADV          True         False  \n",
      "1407         False     V          True         False  \n",
      "1408         False   ADV          True         False  \n",
      "1409         False  VINF          True         False  \n",
      "1410         False   ADV          True          True  \n",
      "\n",
      "[1411 rows x 13 columns]\n",
      "134 134\n",
      "Added embeddings\n",
      "Adding metadata with 15 columns\n",
      "134 matching events found\n",
      "Setting baseline interval to [-4.0, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 134 events and 4501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:226: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=20 parameter will result in a sampling frequency of 50.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 16 columns\n",
      "134 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:314: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(epochs)\n"
     ]
    }
   ],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max, epoch_on=epoch_on ,reference=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685a43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d58005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import decod\n",
    "R_vec = decod(epochs, decoding_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905586b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.fill_between(epochs.times, R_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40765d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f47780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diff(epochs.metadata.onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8eb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e9edd",
   "metadata": {},
   "source": [
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482306bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.round(np.diff(epochs2.metadata.onset),3)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"{val} occurs {count} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.diff(epochs2.metadata.onset)>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cbf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcf368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d44ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f35cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9a8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dae2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_(epochs, column, value):\n",
    "    meta  = epochs.metadata\n",
    "    subset = meta[meta[column]==value].level_0\n",
    "    return epochs[subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs.metadata['n_closing'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69967734",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_(epochs,'is_last_word',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = {'sentence': {'column':'is_last_word','target':True},\n",
    "        'word': {'column':'kind','target':'word'},\n",
    "        'constituent': {'column':'n_closing','target':2}}\n",
    "\n",
    "cases = {'start', 'end'}\n",
    "\n",
    "i = 1\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        ep = epochs_(epochs, cond[condi]['column'], cond[condi]['target'])\n",
    "        ax = fig.add_subplot(3, 2, i)\n",
    "        #ep.average().plot(gfp='only')\n",
    "        evo = ep.average(method=\"median\")\n",
    "        evo.plot(spatial_colors=True)\n",
    "        i = i + 1\n",
    "        ax.set_title(f'Plot {cond}')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217312",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4 = epochs_(epochs, 'n_closing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4.average().plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs\n",
    "\n",
    "class CustomEpochs(Epochs):\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Parse the key into metadata field name and value\n",
    "        field, value = key.split('==')\n",
    "        field = field.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Get the indices of the epochs that match the metadata query\n",
    "        indices = [i for i, metadata in enumerate(self.metadata[field]) if metadata == value]\n",
    "\n",
    "        # Return a new Epochs object containing only the matching epochs\n",
    "        return self.__class__(self._data[indices], self.events[indices], self.event_id,\n",
    "                              tmin=self.tmin, tmax=self.tmax, baseline=self.baseline,\n",
    "                              metadata=self.metadata.iloc[indices], info=self.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs = CustomEpochs(epochs, epochs.events, \"1\", -0.2, 0.8, epochs.baseline, epochs.metadata)\n",
    "\n",
    "# Get all epochs where the 'kind' metadata field is 'word':\n",
    "word_epochs = custom_epochs['kind==word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07344132",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "def mne_events(meta):\n",
    "    events = np.ones((len(meta), 3), dtype=int)\n",
    "    events[:, 0] = meta.start*raw.info['sfreq']\n",
    "    return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "epochs = mne.Epochs(raw, **mne_events(meta), decim=20, tmin=-.2, tmax=1.5, preload=True)\n",
    "epochs = epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data, epoch_runs\n",
    "from utils import (\n",
    "    decod,\n",
    "    correlate,\n",
    "    match_list,\n",
    "    create_target,\n",
    "    analysis,\n",
    "    save_decoding_results,\n",
    ")\n",
    "from plot import plot_subject\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 9\n",
    "task = \"read\"\n",
    "subject = subjects[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856d515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs.metadata).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.load_data()\n",
    "epochs = epochs['kind==\"word\"']\n",
    "epochs[\"content_word == False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
