{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe12bcb",
   "metadata": {},
   "source": [
    "# Reformat the txt file for LASER handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e453f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Split text into sentences with regex\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m sentences \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS]+?[.?!][\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]?(?=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms|$)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_code_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/txt_laser/run\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Good code, to do for all chapers\n",
    "# Test: for chapter 1, there are 132 lines\n",
    "from dataset import get_code_path\n",
    "import numpy as np \n",
    "import re\n",
    "for chapter in np.arange(1,10):\n",
    "\n",
    "    with open(f\"{get_code_path()}/experiments/formatting/text_lpp/new_test_run{chapter}.txt\", 'r') as file:\n",
    "        data = file.read()\n",
    "    text = \" \".join(data.split())\n",
    "    # Split text into sentences with regex\n",
    "    sentences = re.findall(r'[\\w\\s\\S]+?[.?!][\"\\']?(?=\\s|$)', text)\n",
    "    with open(f\"{get_code_path()}/data/txt_laser/run{chapter}.txt\", \"w\") as file:\n",
    "        for sentence in sentences:\n",
    "            file.write(sentence + '\\n')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67a6a0",
   "metadata": {},
   "source": [
    "# GFP for sentence - epoching on sentence end and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_runs\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "task = \"read\"\n",
    "subject = subjects[4]\n",
    "baseline_min = -4.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327068d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      " Epoching for run 01, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 89000 ... 554999 =     89.000 ...   554.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 465999  =      0.000 ...   465.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "Added embeddings\n",
      "Adding metadata with 15 columns\n",
      "134 matching events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting baseline interval to [-4.0, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 134 events and 4501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:224: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=20 parameter will result in a sampling frequency of 50.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 16 columns\n",
      "134 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:312: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(epochs)\n"
     ]
    }
   ],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max, epoch_on=epoch_on ,reference=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f685a43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>start</th>\n",
       "      <th>condition</th>\n",
       "      <th>n_closing</th>\n",
       "      <th>is_last_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>content_word</th>\n",
       "      <th>sentence_end</th>\n",
       "      <th>laser</th>\n",
       "      <th>label</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>vécues</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'vécues'}</td>\n",
       "      <td>97.153</td>\n",
       "      <td>sentence</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>VPP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.023229877, 0.024350138, -0.00015318407, 0.0...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>fauve</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'fauve'}</td>\n",
       "      <td>100.020</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.022218416, -0.00034505766, 0.0015076251, 0....</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>dessin</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'dessin'}</td>\n",
       "      <td>101.820</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.00026135266, 0.0016505849, -2.3930232e-05,...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>mâcher</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'mâcher'}</td>\n",
       "      <td>106.586</td>\n",
       "      <td>sentence</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>VINF</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.017938925, -0.00026753946, -5.8330224e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>leur</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'leur'}</td>\n",
       "      <td>111.103</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.013751491, -0.00038898917, -4.4464363e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1376</td>\n",
       "      <td>1425</td>\n",
       "      <td>1425</td>\n",
       "      <td>aille</td>\n",
       "      <td>496.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'aille'}</td>\n",
       "      <td>537.843</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>VS</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.011370567, -6.920686e-05, 0.00038883876, 0....</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1378</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>où</td>\n",
       "      <td>497.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'où'}</td>\n",
       "      <td>538.843</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.000113535774, -0.00022956666, -0.000114733...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1380</td>\n",
       "      <td>1429</td>\n",
       "      <td>1429</td>\n",
       "      <td>devant</td>\n",
       "      <td>498.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'devant'}</td>\n",
       "      <td>539.826</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0019510961, -0.0020051037, -0.00089106197, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1393</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>chez</td>\n",
       "      <td>503.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'chez'}</td>\n",
       "      <td>544.326</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0077716443, 0.00020009138, -5.0174247e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1410</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>bien</td>\n",
       "      <td>510.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'bien'}</td>\n",
       "      <td>549.909</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.031558756, 0.00062578707, 0.003126733, 0.03...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index  Unnamed: 0    word  onset  duration  \\\n",
       "0         21     21          21  vécues    7.0      0.25   \n",
       "1         30     30          30   fauve   10.2      0.25   \n",
       "2         35     35          35  dessin   12.2      0.25   \n",
       "3         50     51          51  mâcher   17.5      0.25   \n",
       "4         65     66          66    leur   22.5      0.25   \n",
       "..       ...    ...         ...     ...    ...       ...   \n",
       "129     1376   1425        1425   aille  496.7      0.25   \n",
       "130     1378   1427        1427      où  497.8      0.25   \n",
       "131     1380   1429        1429  devant  498.9      0.25   \n",
       "132     1393   1444        1444    chez  503.9      0.25   \n",
       "133     1410   1463        1463    bien  510.1      0.25   \n",
       "\n",
       "                             trial_type    start condition  n_closing  \\\n",
       "0    {'kind': 'word', 'word': 'vécues'}   97.153  sentence          6   \n",
       "1     {'kind': 'word', 'word': 'fauve'}  100.020  sentence          5   \n",
       "2    {'kind': 'word', 'word': 'dessin'}  101.820  sentence          5   \n",
       "3    {'kind': 'word', 'word': 'mâcher'}  106.586  sentence          4   \n",
       "4      {'kind': 'word', 'word': 'leur'}  111.103  sentence          1   \n",
       "..                                  ...      ...       ...        ...   \n",
       "129   {'kind': 'word', 'word': 'aille'}  537.843  sentence          5   \n",
       "130      {'kind': 'word', 'word': 'où'}  538.843  sentence          2   \n",
       "131  {'kind': 'word', 'word': 'devant'}  539.826  sentence          1   \n",
       "132    {'kind': 'word', 'word': 'chez'}  544.326  sentence          1   \n",
       "133    {'kind': 'word', 'word': 'bien'}  549.909  sentence          1   \n",
       "\n",
       "     is_last_word   pos  content_word  sentence_end  \\\n",
       "0           False   VPP          True          True   \n",
       "1           False    NC          True          True   \n",
       "2            True    NC          True          True   \n",
       "3           False  VINF          True          True   \n",
       "4           False   DET         False          True   \n",
       "..            ...   ...           ...           ...   \n",
       "129          True    VS          True          True   \n",
       "130         False   ADV          True          True   \n",
       "131         False     P         False          True   \n",
       "132         False     P         False          True   \n",
       "133         False   ADV          True          True   \n",
       "\n",
       "                                                 laser  label  kind  \n",
       "0    [0.023229877, 0.024350138, -0.00015318407, 0.0...  run_1  word  \n",
       "1    [0.022218416, -0.00034505766, 0.0015076251, 0....  run_1  word  \n",
       "2    [-0.00026135266, 0.0016505849, -2.3930232e-05,...  run_1  word  \n",
       "3    [0.017938925, -0.00026753946, -5.8330224e-05, ...  run_1  word  \n",
       "4    [0.013751491, -0.00038898917, -4.4464363e-05, ...  run_1  word  \n",
       "..                                                 ...    ...   ...  \n",
       "129  [0.011370567, -6.920686e-05, 0.00038883876, 0....  run_1  word  \n",
       "130  [-0.000113535774, -0.00022956666, -0.000114733...  run_1  word  \n",
       "131  [0.0019510961, -0.0020051037, -0.00089106197, ...  run_1  word  \n",
       "132  [0.0077716443, 0.00020009138, -5.0174247e-05, ...  run_1  word  \n",
       "133  [0.031558756, 0.00062578707, 0.003126733, 0.03...  run_1  word  \n",
       "\n",
       "[134 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd8e2a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mmetadata[target]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     18\u001b[0m r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(epochs\u001b[38;5;241m.\u001b[39mtimes))\n\u001b[0;32m---> 19\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnew_array\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mlen\u001b[39m(epochs\u001b[38;5;241m.\u001b[39mtimes)):\n\u001b[1;32m     21\u001b[0m     X \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mget_data()[:, :, t]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_array' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "from tqdm.notebook import trange\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Decod function\n",
    "decoding_criterion=\"laser\"\n",
    "target = decoding_criterion\n",
    "model = make_pipeline(StandardScaler(), RidgeCV())\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "y = epochs.metadata[target].values\n",
    "r = np.zeros(len(epochs.times))\n",
    "y = new_array\n",
    "for t in trange(len(epochs.times)):\n",
    "    X = epochs.get_data()[:, :, t]\n",
    "    for train, test in cv.split(X, y):\n",
    "        model.fit(X[train], y[train])\n",
    "        y_pred = model.predict(X[test])\n",
    "        break;\n",
    "        r[t] += correlate(y_pred, y[test])[0]\n",
    "r /= cv.n_splitsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1999f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate(X, Y):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array(X)[:, None]\n",
    "    if Y.ndim == 1:\n",
    "        Y = np.array(Y)[:, None]\n",
    "    X = X - X.mean(0)\n",
    "    Y = Y - Y.mean(0)\n",
    "\n",
    "    SX2 = (X**2).sum(0) ** 0.5\n",
    "    SY2 = (Y**2).sum(0) ** 0.5\n",
    "    SXY = (X * Y).sum(0)\n",
    "    return SXY / (SX2 * SY2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f42e1566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlate(y_pred, y[test]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9871c16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40765d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f47780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diff(epochs.metadata.onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8eb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e9edd",
   "metadata": {},
   "source": [
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482306bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.round(np.diff(epochs2.metadata.onset),3)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"{val} occurs {count} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55740958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.diff(epochs2.metadata.onset)>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153cbf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcf368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d44ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f35cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9a8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dae2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_(epochs, column, value):\n",
    "    meta  = epochs.metadata\n",
    "    subset = meta[meta[column]==value].level_0\n",
    "    return epochs[subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs.metadata['n_closing'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69967734",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_(epochs,'is_last_word',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = {'sentence': {'column':'is_last_word','target':True},\n",
    "        'word': {'column':'kind','target':'word'},\n",
    "        'constituent': {'column':'n_closing','target':2}}\n",
    "\n",
    "cases = {'start', 'end'}\n",
    "\n",
    "i = 1\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        ep = epochs_(epochs, cond[condi]['column'], cond[condi]['target'])\n",
    "        ax = fig.add_subplot(3, 2, i)\n",
    "        #ep.average().plot(gfp='only')\n",
    "        evo = ep.average(method=\"median\")\n",
    "        evo.plot(spatial_colors=True)\n",
    "        i = i + 1\n",
    "        ax.set_title(f'Plot {cond}')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217312",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4 = epochs_(epochs, 'n_closing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4.average().plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs\n",
    "\n",
    "class CustomEpochs(Epochs):\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Parse the key into metadata field name and value\n",
    "        field, value = key.split('==')\n",
    "        field = field.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Get the indices of the epochs that match the metadata query\n",
    "        indices = [i for i, metadata in enumerate(self.metadata[field]) if metadata == value]\n",
    "\n",
    "        # Return a new Epochs object containing only the matching epochs\n",
    "        return self.__class__(self._data[indices], self.events[indices], self.event_id,\n",
    "                              tmin=self.tmin, tmax=self.tmax, baseline=self.baseline,\n",
    "                              metadata=self.metadata.iloc[indices], info=self.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs = CustomEpochs(epochs, epochs.events, \"1\", -0.2, 0.8, epochs.baseline, epochs.metadata)\n",
    "\n",
    "# Get all epochs where the 'kind' metadata field is 'word':\n",
    "word_epochs = custom_epochs['kind==word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07344132",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "def mne_events(meta):\n",
    "    events = np.ones((len(meta), 3), dtype=int)\n",
    "    events[:, 0] = meta.start*raw.info['sfreq']\n",
    "    return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "epochs = mne.Epochs(raw, **mne_events(meta), decim=20, tmin=-.2, tmax=1.5, preload=True)\n",
    "epochs = epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data, epoch_runs\n",
    "from utils import (\n",
    "    decod,\n",
    "    correlate,\n",
    "    match_list,\n",
    "    create_target,\n",
    "    analysis,\n",
    "    save_decoding_results,\n",
    ")\n",
    "from plot import plot_subject\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 9\n",
    "task = \"read\"\n",
    "subject = subjects[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856d515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs.metadata).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.load_data()\n",
    "epochs = epochs['kind==\"word\"']\n",
    "epochs[\"content_word == False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
