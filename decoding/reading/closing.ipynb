{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b10881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data\n",
    "from utils import decod, correlate, match_list\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "mne.set_log_level(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bd23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/co/data/BIDS_lecture\n"
     ]
    }
   ],
   "source": [
    "print(get_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : integrate this inside epoch_data in dataset.py directly\n",
    "\n",
    "# what's currently missing: metadata information adding, basically adding closing column.\n",
    "# For that, the parse function is needed\n",
    "def load_events(self):\n",
    "\n",
    "    raw = self.raw()\n",
    "    path = StudyPaths().download\n",
    "    bids_path = BIDSPath(\n",
    "        subject=self.subject_uid[4:],\n",
    "        session=\"01\",\n",
    "        run=self.run,\n",
    "        task=\"listen\",\n",
    "        root=path,\n",
    "        datatype=\"meg\",\n",
    "    )\n",
    "\n",
    "    # extract annotations\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "    meta['word'] = [eval(w)['word'] for w in meta.trial_type]\n",
    "    meta['kind'] = [eval(w)['kind'] for w in meta.trial_type]\n",
    "    \n",
    "    events = self.raw_events\n",
    "\n",
    "    # word events\n",
    "    # match events and metadata\n",
    "    word_events = events[events[:, 2] > 1]\n",
    "    meg_delta = np.diff(word_events[:, 0].astype(float) / raw.info[\"sfreq\"])\n",
    "    meta_delta = np.diff(meta.onset.values)\n",
    "\n",
    "    pres = 1e2\n",
    "    i, j = utils.match_list(np.round(meg_delta*pres), np.round(meta_delta*pres))\n",
    "    assert len(i) / len(meg_delta) > .95\n",
    "    assert len(i) > 500\n",
    "    meta = meta.iloc[j].reset_index(drop=True)\n",
    "    meta[\"start\"] = word_events[i, 0] / self.raw().info[\"sfreq\"]\n",
    "\n",
    "    # Sound events\n",
    "    CHAPTERS = {\n",
    "        1: \"1-3\",\n",
    "        2: \"4-6\",\n",
    "        3: \"7-9\",\n",
    "        4: \"10-12\",\n",
    "        5: \"13-14\",\n",
    "        6: \"15-19\",\n",
    "        7: \"20-22\",\n",
    "        8: \"23-25\",\n",
    "        9: \"26-27\",\n",
    "    }\n",
    "\n",
    "    # Event start and end:\n",
    "    idx = [np.where(events[:, 2] == 1)[0][0]]\n",
    "    sound_start = events[idx, 0] / self.raw().info[\"sfreq\"]\n",
    "    assert len(sound_start) == 1\n",
    "    sound_start = sound_start[0]\n",
    "    chapter = CHAPTERS[self.run_uid]\n",
    "\n",
    "    sound_event = []\n",
    "    sound_path = path / \"stimuli\" / f\"ch{chapter}.wav\"\n",
    "    assert sound_path.exists()\n",
    "    sound_event.append(\n",
    "        dict(kind=\"sound\", filepath=sound_path, start=sound_start)\n",
    "    )\n",
    "\n",
    "    meta = pd.concat([meta, pd.DataFrame(sound_event)], ignore_index=True)\n",
    "    meta[\"condition\"] = \"sentence\"\n",
    "    meta = meta.sort_values('start').reset_index(drop=True)\n",
    "    \n",
    "    # add parsing data\n",
    "    meta = enrich(meta, path/'stimuli'/f'ch{chapter}.txt')\n",
    "    \n",
    "    return meta[['start', 'duration', 'kind', 'word', 'filepath', 'condition', 'sequence_id', 'sequence_uid', 'word_index', 'closing_', 'match_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f78c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 1\n",
    "\n",
    "def parse(sent):\n",
    "    'identifies the number of closing nodes'\n",
    "\n",
    "    def is_closed(node, position):\n",
    "        \"\"\"JR quick code to know whether is a word is closed given a word position\"\"\"\n",
    "        if node.i > position:\n",
    "            return False\n",
    "        for child in node.children:\n",
    "            if child.i > position:\n",
    "                return False\n",
    "            if not is_closed(child, position):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    closeds = []\n",
    "    for current in range(1, len(sent)+1):\n",
    "        closed = 0\n",
    "        for position, word in enumerate(sent): # [:current]\n",
    "            closed += is_closed(word, current)\n",
    "        closeds.append(closed)\n",
    "\n",
    "    closing = np.r_[np.diff(closeds), closeds[-1]]\n",
    "    return closing\n",
    "\n",
    "def format_meta(meta,run_id):\n",
    "    model = 'fr_core_news_sm'\n",
    "    if not spacy.util.is_package(model):\n",
    "        spacy.cli.download(model)\n",
    "\n",
    "    nlp = spacy.load(model)\n",
    "\n",
    "    CHAPTERS = {\n",
    "    1: \"1-3\",\n",
    "    2: \"4-6\",\n",
    "    3: \"7-9\",\n",
    "    4: \"10-12\",\n",
    "    5: \"13-14\",\n",
    "    6: \"15-19\",\n",
    "    7: \"20-22\",\n",
    "    8: \"23-25\",\n",
    "    9: \"26-27\",\n",
    "    }\n",
    "    txt_file = f'./../../data/syntax/ch{CHAPTERS[run]}.syntax.txt'\n",
    "    with open(txt_file, 'r') as f:\n",
    "        txt = f.read().replace('\\n', '')\n",
    "\n",
    "    # parse text file\n",
    "    doc = nlp(txt)\n",
    "\n",
    "    # add parse information to metadata\n",
    "    parse_annots = []\n",
    "    for sent_id, sent in enumerate(doc.sents):\n",
    "        # HERE ADD ERIC DE LA CLERGERIE parser instead\n",
    "        closings = parse(sent)\n",
    "        assert len(closings) == len(sent)\n",
    "        for word, closing in zip(sent, closings):\n",
    "            parse_annots.append(dict(\n",
    "                word_index=word.i - sent[0].i,\n",
    "                sequence_id=sent_id,\n",
    "                sequence_uid=str(sent),\n",
    "                closing=closing,\n",
    "                match_token=word.text,\n",
    "            ))\n",
    "\n",
    "    # align text file and meg metadata\n",
    "    def format_text(text):\n",
    "        for char in ('jlsmtncd'):\n",
    "            text = text.replace(f\"{char}'\", char)\n",
    "        text = text.replace('Å“', 'oe')\n",
    "        return text.lower()\n",
    "\n",
    "    meg_words = meta.word.fillna('######').values\n",
    "    text_words = [format_text(w.text) for w in doc]\n",
    "\n",
    "    i, j = match_list(meg_words, text_words)\n",
    "\n",
    "    # deal with missed tokens (e.g. wrong spelling, punctuation)\n",
    "    assert len(parse_annots) == len(text_words)\n",
    "    parse_annots = pd.DataFrame(parse_annots)\n",
    "    parse_annots.closing = parse_annots.closing.fillna(0)\n",
    "    parse_annots['closing_'] = 0\n",
    "    parse_annots['missed_closing'] = 0\n",
    "    missing = np.setdiff1d(range(len(parse_annots)), j)\n",
    "    for missed in missing:\n",
    "        current_closing = parse_annots.iloc[missed].closing\n",
    "        prev_word = parse_annots.iloc[[missed-1]].index\n",
    "        if prev_word[0] >=0:\n",
    "            parse_annots.loc[prev_word, 'missed_closing'] = current_closing\n",
    "    parse_annots.closing_ = parse_annots.closing + parse_annots.missed_closing\n",
    "\n",
    "    # Add new columns to original mne.Epochs.metadata\n",
    "    # fill columns\n",
    "    columns = ('word_index', 'sequence_id', 'sequence_uid', 'closing_', 'match_token')\n",
    "    for column in columns:\n",
    "        meta[column] = None\n",
    "        meta.loc[meta.iloc[i].index, column] = parse_annots[column].iloc[j].values\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5450c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subjects for which the decoding will be tested: \n",
      "\n",
      "['1', '2', '3', '4', '5', '6']\n",
      "Subject 1's decoding started\n",
      ".Running the script on RAW data:\n",
      "run 01, subject: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/cb271805/272a9f9d-f140-48d6-b390-094ccc29aae0/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/media/cb271805/272a9f9d-f140-48d6-b390-094ccc29aae0/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:55: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/media/cb271805/272a9f9d-f140-48d6-b390-094ccc29aae0/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/media/cb271805/272a9f9d-f140-48d6-b390-094ccc29aae0/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:84: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=20 parameter will result in a sampling frequency of 50.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(\n",
      "/tmp/ipykernel_2056128/2126757813.py:25: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  Unnamed: 0     word   onset  duration  \\\n",
      "0         0           0  Lorsque    0.70       0.3   \n",
      "1         1           1   javais    1.05       0.3   \n",
      "2         2           2      six    1.40       0.3   \n",
      "3         3           3      ans    1.75       0.3   \n",
      "4         4           4      jai    2.10       0.3   \n",
      "...     ...         ...      ...     ...       ...   \n",
      "1406   1459        1459       ne  511.35       0.3   \n",
      "1407   1460        1460     peut  511.70       0.3   \n",
      "1408   1461        1461      pas  512.05       0.3   \n",
      "1409   1462        1462    aller  512.40       0.3   \n",
      "1410   1463        1463     bien  512.75       0.3   \n",
      "\n",
      "                               trial_type    start  label  kind word_index  \\\n",
      "0     {'kind': 'word', 'word': 'Lorsque'}   44.534  run_1  word       None   \n",
      "1      {'kind': 'word', 'word': 'javais'}   44.889  run_1  word       None   \n",
      "2         {'kind': 'word', 'word': 'six'}   45.189  run_1  word         16   \n",
      "3         {'kind': 'word', 'word': 'ans'}   45.489  run_1  word         22   \n",
      "4         {'kind': 'word', 'word': 'jai'}   45.806  run_1  word       None   \n",
      "...                                   ...      ...    ...   ...        ...   \n",
      "1406       {'kind': 'word', 'word': 'ne'}  528.061  run_1  word        111   \n",
      "1407     {'kind': 'word', 'word': 'peut'}  528.378  run_1  word        117   \n",
      "1408      {'kind': 'word', 'word': 'pas'}  528.694  run_1  word        124   \n",
      "1409    {'kind': 'word', 'word': 'aller'}  529.011  run_1  word        136   \n",
      "1410     {'kind': 'word', 'word': 'bien'}  529.328  run_1  word        147   \n",
      "\n",
      "     sequence_id                                       sequence_uid closing_  \\\n",
      "0           None                                               None     None   \n",
      "1           None                                               None     None   \n",
      "2              2  Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...        3   \n",
      "3              2  Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...        2   \n",
      "4           None                                               None     None   \n",
      "...          ...                                                ...      ...   \n",
      "1406         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
      "1407         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
      "1408         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
      "1409         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
      "1410         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
      "\n",
      "     match_token  \n",
      "0           None  \n",
      "1           None  \n",
      "2            six  \n",
      "3            ans  \n",
      "4           None  \n",
      "...          ...  \n",
      "1406          ne  \n",
      "1407        peut  \n",
      "1408         pas  \n",
      "1409       aller  \n",
      "1410        bien  \n",
      "\n",
      "[1411 rows x 14 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseEpochs' object has no attribute 'metadat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# TODO : re-epoch\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(format_meta(epochs\u001b[38;5;241m.\u001b[39mmetadata, run_id))\n\u001b[0;32m---> 40\u001b[0m epochs\u001b[38;5;241m.\u001b[39mmetadat\n\u001b[1;32m     41\u001b[0m epochs\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosing\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mclosing_\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Run a linear regression between MEG signals\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# and word frequency classification\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseEpochs' object has no attribute 'metadat'"
     ]
    }
   ],
   "source": [
    "report = mne.Report()\n",
    "path = get_path('LPP_read')\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "\n",
    "print(\"\\nSubjects for which the decoding will be tested: \\n\")\n",
    "print(subjects)\n",
    "\n",
    "for subject in subjects:  # Ignore the first one\n",
    "\n",
    "    print(f\"Subject {subject}'s decoding started\")\n",
    "    epochs = []\n",
    "    for run_id in range(1, RUN + 1):\n",
    "        print(\".\", end=\"\")\n",
    "        epo = epoch_data(subject, \"%.2i\" % run_id, task='listen', path=path)\n",
    "        epo.metadata[\"label\"] = f\"run_{run_id}\"\n",
    "        epochs.append(epo)\n",
    "\n",
    "    # Quick fix for the dev_head: has to be\n",
    "    # fixed before doing source reconstruction\n",
    "    for epo in epochs:\n",
    "        epo.info[\"dev_head_t\"] = epochs[0].info[\"dev_head_t\"]\n",
    "        # epo.info['nchan'] = epochs[0].info['nchan']\n",
    "\n",
    "    epochs = mne.concatenate_epochs(epochs)\n",
    "\n",
    "    # Get the evoked potential averaged on all epochs for each channel\n",
    "    evo = epochs.average(method=\"median\")\n",
    "    evo.plot(spatial_colors=True)\n",
    "\n",
    "    # Handling the data structure\n",
    "    epochs.metadata[\"kind\"] = epochs.metadata.trial_type.apply(\n",
    "        lambda s: eval(s)[\"kind\"]\n",
    "    )\n",
    "    epochs.metadata[\"word\"] = epochs.metadata.trial_type.apply(\n",
    "        lambda s: eval(s)[\"word\"]\n",
    "    )\n",
    "    # TODO : re-epoch\n",
    "    print(format_meta(epochs.metadata, run_id))\n",
    "    epochs.metadata\n",
    "    epochs.metadata['closing'] = epochs.metadata.closing_.fillna(0)\n",
    "    # Run a linear regression between MEG signals\n",
    "    # and word frequency classification\n",
    "    X = epochs.get_data()\n",
    "\n",
    "    embeddings = epochs.metadata.word.apply(lambda word: nlp(word).vector).values\n",
    "    embeddings = np.array([emb for emb in embeddings])\n",
    "\n",
    "    y = embeddings\n",
    "\n",
    "    R_vec = decod(X, y)\n",
    "    R_vec_avg = np.mean(R_vec,axis = 1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=[6, 6])\n",
    "    dec = plt.fill_between(epochs.times, R_vec_avg)\n",
    "    # plt.show()\n",
    "    report.add_evokeds(evo, titles=f\"Evoked for sub {subject} \")\n",
    "    report.add_figure(fig, title=f\"decoding for subject {subject}\")\n",
    "    # report.add_figure(dec, subject, tags=\"word\")\n",
    "    report.save(\"./figures/reading_decoding_embeddings.html\", open_browser=False, overwrite=True)\n",
    "\n",
    "    print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc497a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>start</th>\n",
       "      <th>label</th>\n",
       "      <th>kind</th>\n",
       "      <th>word_index</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_uid</th>\n",
       "      <th>closing_</th>\n",
       "      <th>match_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lorsque</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'Lorsque'}</td>\n",
       "      <td>44.534</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>javais</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'javais'}</td>\n",
       "      <td>44.889</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>six</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'six'}</td>\n",
       "      <td>45.189</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...</td>\n",
       "      <td>3</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ans</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'ans'}</td>\n",
       "      <td>45.489</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...</td>\n",
       "      <td>2</td>\n",
       "      <td>ans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>jai</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'jai'}</td>\n",
       "      <td>45.806</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1459</td>\n",
       "      <td>1459</td>\n",
       "      <td>ne</td>\n",
       "      <td>511.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'ne'}</td>\n",
       "      <td>528.061</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>111</td>\n",
       "      <td>164</td>\n",
       "      <td>Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...</td>\n",
       "      <td>0</td>\n",
       "      <td>ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>peut</td>\n",
       "      <td>511.70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'peut'}</td>\n",
       "      <td>528.378</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...</td>\n",
       "      <td>0</td>\n",
       "      <td>peut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1461</td>\n",
       "      <td>1461</td>\n",
       "      <td>pas</td>\n",
       "      <td>512.05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'pas'}</td>\n",
       "      <td>528.694</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>124</td>\n",
       "      <td>164</td>\n",
       "      <td>Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...</td>\n",
       "      <td>0</td>\n",
       "      <td>pas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1462</td>\n",
       "      <td>1462</td>\n",
       "      <td>aller</td>\n",
       "      <td>512.40</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'aller'}</td>\n",
       "      <td>529.011</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>136</td>\n",
       "      <td>164</td>\n",
       "      <td>Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...</td>\n",
       "      <td>0</td>\n",
       "      <td>aller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>bien</td>\n",
       "      <td>512.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'kind': 'word', 'word': 'bien'}</td>\n",
       "      <td>529.328</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "      <td>147</td>\n",
       "      <td>164</td>\n",
       "      <td>Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...</td>\n",
       "      <td>0</td>\n",
       "      <td>bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0     word   onset  duration  \\\n",
       "0         0           0  Lorsque    0.70       0.3   \n",
       "1         1           1   javais    1.05       0.3   \n",
       "2         2           2      six    1.40       0.3   \n",
       "3         3           3      ans    1.75       0.3   \n",
       "4         4           4      jai    2.10       0.3   \n",
       "...     ...         ...      ...     ...       ...   \n",
       "1406   1459        1459       ne  511.35       0.3   \n",
       "1407   1460        1460     peut  511.70       0.3   \n",
       "1408   1461        1461      pas  512.05       0.3   \n",
       "1409   1462        1462    aller  512.40       0.3   \n",
       "1410   1463        1463     bien  512.75       0.3   \n",
       "\n",
       "                               trial_type    start  label  kind word_index  \\\n",
       "0     {'kind': 'word', 'word': 'Lorsque'}   44.534  run_1  word       None   \n",
       "1      {'kind': 'word', 'word': 'javais'}   44.889  run_1  word       None   \n",
       "2         {'kind': 'word', 'word': 'six'}   45.189  run_1  word         16   \n",
       "3         {'kind': 'word', 'word': 'ans'}   45.489  run_1  word         22   \n",
       "4         {'kind': 'word', 'word': 'jai'}   45.806  run_1  word       None   \n",
       "...                                   ...      ...    ...   ...        ...   \n",
       "1406       {'kind': 'word', 'word': 'ne'}  528.061  run_1  word        111   \n",
       "1407     {'kind': 'word', 'word': 'peut'}  528.378  run_1  word        117   \n",
       "1408      {'kind': 'word', 'word': 'pas'}  528.694  run_1  word        124   \n",
       "1409    {'kind': 'word', 'word': 'aller'}  529.011  run_1  word        136   \n",
       "1410     {'kind': 'word', 'word': 'bien'}  529.328  run_1  word        147   \n",
       "\n",
       "     sequence_id                                       sequence_uid closing_  \\\n",
       "0           None                                               None     None   \n",
       "1           None                                               None     None   \n",
       "2              2  Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...        3   \n",
       "3              2  Sint (VN (CLS-SUJ 1=j'avais) (DET 2=six) (NC 3...        2   \n",
       "4           None                                               None     None   \n",
       "...          ...                                                ...      ...   \n",
       "1406         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
       "1407         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
       "1408         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
       "1409         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
       "1410         164  Sint (PP-MOD (PP-MOD (P 1=avec) (NP (ADV+ (DET...        0   \n",
       "\n",
       "     match_token  \n",
       "0           None  \n",
       "1           None  \n",
       "2            six  \n",
       "3            ans  \n",
       "4           None  \n",
       "...          ...  \n",
       "1406          ne  \n",
       "1407        peut  \n",
       "1408         pas  \n",
       "1409       aller  \n",
       "1410        bien  \n",
       "\n",
       "[1411 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2570a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
