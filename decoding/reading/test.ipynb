{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bad1960",
   "metadata": {},
   "source": [
    "# Reformat the txt file for LASER handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926d3b46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Split text into sentences with regex\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m sentences \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS]+?[.?!][\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]?(?=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms|$)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_code_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/txt_laser/run\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Good code, to do for all chapers\n",
    "# Test: for chapter 1, there are 132 lines\n",
    "from dataset import get_code_path\n",
    "import numpy as np \n",
    "import re\n",
    "for chapter in np.arange(1,10):\n",
    "\n",
    "    with open(f\"{get_code_path()}/experiments/formatting/text_lpp/new_test_run{chapter}.txt\", 'r') as file:\n",
    "        data = file.read()\n",
    "    text = \" \".join(data.split())\n",
    "    # Split text into sentences with regex\n",
    "    sentences = re.findall(r'[\\w\\s\\S]+?[.?!][\"\\']?(?=\\s|$)', text)\n",
    "    with open(f\"{get_code_path()}/data/txt_laser/run{chapter}.txt\", \"w\") as file:\n",
    "        for sentence in sentences:\n",
    "            file.write(sentence + '\\n')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67a6a0",
   "metadata": {},
   "source": [
    "# GFP for sentence - epoching on sentence end and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9c5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homemade imports\n",
    "from dataset import get_path, get_subjects, epoch_runs\n",
    "from plot import plot_subject\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import mne\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa49be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 1\n",
    "task = \"read\"\n",
    "subject = subjects[4]\n",
    "baseline_min = -4.0\n",
    "baseline_max = 0.5\n",
    "epoch_on = 'sentence'\n",
    "reference = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327068d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      " Epoching for run 01, subject: 5\n",
      "\n",
      "Opening raw data file /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 89000 ... 554999 =     89.000 ...   554.999 secs\n",
      "Ready.\n",
      "Reading events from /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/co/data/BIDS_lecture/sub-5/ses-01/meg/sub-5_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 465999  =      0.000 ...   465.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Omitted 128 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:99: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 20 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 20.00 Hz\n",
      "- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n",
      "- Filter length: 6601 samples (6.601 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added embeddings\n",
      "Adding metadata with 15 columns\n",
      "134 matching events found\n",
      "Setting baseline interval to [-4.0, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 134 events and 4501 original time points (prior to decimation) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:224: RuntimeWarning: The measurement information indicates a low-pass frequency of 20.0 Hz. The decim=20 parameter will result in a sampling frequency of 50.0 Hz, which can cause aliasing artifacts.\n",
      "  epochs = mne.Epochs(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Adding metadata with 16 columns\n",
      "134 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co/workspace_LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:312: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(epochs)\n"
     ]
    }
   ],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max, epoch_on=epoch_on ,reference=reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26977fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>start</th>\n",
       "      <th>condition</th>\n",
       "      <th>n_closing</th>\n",
       "      <th>is_last_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>content_word</th>\n",
       "      <th>sentence_end</th>\n",
       "      <th>laser</th>\n",
       "      <th>label</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>vécues</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'vécues'}</td>\n",
       "      <td>97.153</td>\n",
       "      <td>sentence</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>VPP</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.023229877, 0.024350138, -0.00015318407, 0.0...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>fauve</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'fauve'}</td>\n",
       "      <td>100.020</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.022218416, -0.00034505766, 0.0015076251, 0....</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>dessin</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'dessin'}</td>\n",
       "      <td>101.820</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.00026135266, 0.0016505849, -2.3930232e-05,...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>mâcher</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'mâcher'}</td>\n",
       "      <td>106.586</td>\n",
       "      <td>sentence</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>VINF</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.017938925, -0.00026753946, -5.8330224e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>leur</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'leur'}</td>\n",
       "      <td>111.103</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.013751491, -0.00038898917, -4.4464363e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1376</td>\n",
       "      <td>1425</td>\n",
       "      <td>1425</td>\n",
       "      <td>aille</td>\n",
       "      <td>496.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'aille'}</td>\n",
       "      <td>537.843</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>VS</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.011370567, -6.920686e-05, 0.00038883876, 0....</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1378</td>\n",
       "      <td>1427</td>\n",
       "      <td>1427</td>\n",
       "      <td>où</td>\n",
       "      <td>497.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'où'}</td>\n",
       "      <td>538.843</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.000113535774, -0.00022956666, -0.000114733...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1380</td>\n",
       "      <td>1429</td>\n",
       "      <td>1429</td>\n",
       "      <td>devant</td>\n",
       "      <td>498.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'devant'}</td>\n",
       "      <td>539.826</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0019510961, -0.0020051037, -0.00089106197, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1393</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>chez</td>\n",
       "      <td>503.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'chez'}</td>\n",
       "      <td>544.326</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.0077716443, 0.00020009138, -5.0174247e-05, ...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1410</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>bien</td>\n",
       "      <td>510.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'bien'}</td>\n",
       "      <td>549.909</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.031558756, 0.00062578707, 0.003126733, 0.03...</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index  Unnamed: 0    word  onset  duration  \\\n",
       "0         21     21          21  vécues    7.0      0.25   \n",
       "1         30     30          30   fauve   10.2      0.25   \n",
       "2         35     35          35  dessin   12.2      0.25   \n",
       "3         50     51          51  mâcher   17.5      0.25   \n",
       "4         65     66          66    leur   22.5      0.25   \n",
       "..       ...    ...         ...     ...    ...       ...   \n",
       "129     1376   1425        1425   aille  496.7      0.25   \n",
       "130     1378   1427        1427      où  497.8      0.25   \n",
       "131     1380   1429        1429  devant  498.9      0.25   \n",
       "132     1393   1444        1444    chez  503.9      0.25   \n",
       "133     1410   1463        1463    bien  510.1      0.25   \n",
       "\n",
       "                             trial_type    start condition  n_closing  \\\n",
       "0    {'kind': 'word', 'word': 'vécues'}   97.153  sentence          6   \n",
       "1     {'kind': 'word', 'word': 'fauve'}  100.020  sentence          5   \n",
       "2    {'kind': 'word', 'word': 'dessin'}  101.820  sentence          5   \n",
       "3    {'kind': 'word', 'word': 'mâcher'}  106.586  sentence          4   \n",
       "4      {'kind': 'word', 'word': 'leur'}  111.103  sentence          1   \n",
       "..                                  ...      ...       ...        ...   \n",
       "129   {'kind': 'word', 'word': 'aille'}  537.843  sentence          5   \n",
       "130      {'kind': 'word', 'word': 'où'}  538.843  sentence          2   \n",
       "131  {'kind': 'word', 'word': 'devant'}  539.826  sentence          1   \n",
       "132    {'kind': 'word', 'word': 'chez'}  544.326  sentence          1   \n",
       "133    {'kind': 'word', 'word': 'bien'}  549.909  sentence          1   \n",
       "\n",
       "     is_last_word   pos  content_word  sentence_end  \\\n",
       "0           False   VPP          True          True   \n",
       "1           False    NC          True          True   \n",
       "2            True    NC          True          True   \n",
       "3           False  VINF          True          True   \n",
       "4           False   DET         False          True   \n",
       "..            ...   ...           ...           ...   \n",
       "129          True    VS          True          True   \n",
       "130         False   ADV          True          True   \n",
       "131         False     P         False          True   \n",
       "132         False     P         False          True   \n",
       "133         False   ADV          True          True   \n",
       "\n",
       "                                                 laser  label  kind  \n",
       "0    [0.023229877, 0.024350138, -0.00015318407, 0.0...  run_1  word  \n",
       "1    [0.022218416, -0.00034505766, 0.0015076251, 0....  run_1  word  \n",
       "2    [-0.00026135266, 0.0016505849, -2.3930232e-05,...  run_1  word  \n",
       "3    [0.017938925, -0.00026753946, -5.8330224e-05, ...  run_1  word  \n",
       "4    [0.013751491, -0.00038898917, -4.4464363e-05, ...  run_1  word  \n",
       "..                                                 ...    ...   ...  \n",
       "129  [0.011370567, -6.920686e-05, 0.00038883876, 0....  run_1  word  \n",
       "130  [-0.000113535774, -0.00022956666, -0.000114733...  run_1  word  \n",
       "131  [0.0019510961, -0.0020051037, -0.00089106197, ...  run_1  word  \n",
       "132  [0.0077716443, 0.00020009138, -5.0174247e-05, ...  run_1  word  \n",
       "133  [0.031558756, 0.00062578707, 0.003126733, 0.03...  run_1  word  \n",
       "\n",
       "[134 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45689b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90741bf7a27d4ae8b2a2e7a550bc1bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decod\n\u001b[1;32m      2\u001b[0m decoding_criterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaser\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m R_vec \u001b[38;5;241m=\u001b[39m \u001b[43mdecod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoding_criterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace_LPP/code/neurospin-petit-prince/decoding/reading/utils.py:278\u001b[0m, in \u001b[0;36mdecod\u001b[0;34m(epochs, target)\u001b[0m\n\u001b[1;32m    276\u001b[0m X \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mget_data()[:, :, t]\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[0;32m--> 278\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X[test])\n\u001b[1;32m    280\u001b[0m     r[t] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pearsonr(y_pred, y[test])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:2169\u001b[0m, in \u001b[0;36m_BaseRidgeCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2159\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m _RidgeGCV(\n\u001b[1;32m   2160\u001b[0m         alphas,\n\u001b[1;32m   2161\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m         alpha_per_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_per_target,\n\u001b[1;32m   2168\u001b[0m     )\n\u001b[0;32m-> 2169\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39malpha_\n\u001b[1;32m   2171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1948\u001b[0m, in \u001b[0;36m_RidgeGCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;124;03m\"\"\"Fit Ridge regression model with gcv.\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m \n\u001b[1;32m   1928\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;124;03mself : object\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m _normalize \u001b[38;5;241m=\u001b[39m _deprecate_normalize(\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   1946\u001b[0m )\n\u001b[0;32m-> 1948\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;66;03m# alpha_per_target cannot be used in classifier mode. All subclasses\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;66;03m# of _RidgeGCV that are classifiers keep alpha_per_target at its\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;66;03m# default value: False, so the condition below should never happen.\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_clf \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_per_target)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[1;32m   1074\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1100\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1100\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:150\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_object_dtype_isnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m():\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "from utils import decod\n",
    "decoding_criterion = 'laser'\n",
    "R_vec = decod(epochs, decoding_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3e239e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d34d57b49143dab093762d1687cf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (27,1024) and (27,1024) not aligned: 1024 (dim 1) != 27 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         y_pred_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39masarray(y_pred))\n\u001b[1;32m     25\u001b[0m         y_test_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39masarray(y[test]))\n\u001b[0;32m---> 27\u001b[0m         r[t] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_s\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m r \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mn_splitsb\n",
      "File \u001b[0;32m~/miniconda3/envs/meg-masc/lib/python3.10/site-packages/scipy/stats/_stats_py.py:4466\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative)\u001b[0m\n\u001b[1;32m   4462\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn input array is nearly constant; the computed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4463\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrelation coefficient may be inaccurate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4464\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(stats\u001b[38;5;241m.\u001b[39mNearConstantInputWarning(msg))\n\u001b[0;32m-> 4466\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxm\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnormxm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mym\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnormym\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4468\u001b[0m \u001b[38;5;66;03m# Presumably, if abs(r) > 1, then it is only some small artifact of\u001b[39;00m\n\u001b[1;32m   4469\u001b[0m \u001b[38;5;66;03m# floating point arithmetic.\u001b[39;00m\n\u001b[1;32m   4470\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmin\u001b[39m(r, \u001b[38;5;241m1.0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (27,1024) and (27,1024) not aligned: 1024 (dim 1) != 27 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "from tqdm.notebook import trange\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "target = decoding_criterion\n",
    "model = make_pipeline(StandardScaler(), RidgeCV())\n",
    "cv = KFold(n_splits=5)\n",
    "\n",
    "y = epochs.metadata[target].values\n",
    "r = np.zeros(len(epochs.times))\n",
    "y = new_array\n",
    "for t in trange(len(epochs.times)):\n",
    "    X = epochs.get_data()[:, :, t]\n",
    "    for train, test in cv.split(X, y):\n",
    "        model.fit(X[train], y[train])\n",
    "        y_pred = model.predict(X[test])\n",
    "        r[t] += pearsonr(y_pred, y[test])[0]\n",
    "r /= cv.n_splitsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bae54039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate(X, Y):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array(X)[:, None]\n",
    "    if Y.ndim == 1:\n",
    "        Y = np.array(Y)[:, None]\n",
    "    X = X - X.mean(0)\n",
    "    Y = Y - Y.mean(0)\n",
    "\n",
    "    SX2 = (X**2).sum(0) ** 0.5\n",
    "    SY2 = (Y**2).sum(0) ** 0.5\n",
    "    SXY = (X * Y).sum(0)\n",
    "    return SXY / (SX2 * SY2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3744e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlate(y_pred, y[test]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca494e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty 2D array of size (134, 1024)\n",
    "new_array = np.empty((134, 1024))\n",
    "\n",
    "# Fill in the new array with data from the original arrays\n",
    "for i in range(len(y)):\n",
    "    new_array[i] = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03b8dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.diff(epochs.metadata.onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs2 = epoch_runs(subject, RUN, task, path, baseline_min,baseline_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def6e40",
   "metadata": {},
   "source": [
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x \n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a091aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.round(np.diff(epochs2.metadata.onset),3)\n",
    "unique, counts = np.unique(arr, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for val, count in zip(unique, counts):\n",
    "    print(f\"{val} occurs {count} times.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.diff(epochs2.metadata.onset)>0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e443ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39670b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fb9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9559db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08bb48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9a8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dae2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_(epochs, column, value):\n",
    "    meta  = epochs.metadata\n",
    "    subset = meta[meta[column]==value].level_0\n",
    "    return epochs[subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba0ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs.metadata['n_closing'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69967734",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_(epochs,'is_last_word',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Build a 3x2 plot, with for each condition (sentence, word, constituent), and for (start, end),\n",
    "# the ERP associated\n",
    "cond = {'sentence': {'column':'is_last_word','target':True},\n",
    "        'word': {'column':'kind','target':'word'},\n",
    "        'constituent': {'column':'n_closing','target':2}}\n",
    "\n",
    "cases = {'start', 'end'}\n",
    "\n",
    "i = 1\n",
    "for condi in cond:\n",
    "    for case in cases:\n",
    "        ep = epochs_(epochs, cond[condi]['column'], cond[condi]['target'])\n",
    "        ax = fig.add_subplot(3, 2, i)\n",
    "        #ep.average().plot(gfp='only')\n",
    "        evo = ep.average(method=\"median\")\n",
    "        evo.plot(spatial_colors=True)\n",
    "        i = i + 1\n",
    "        ax.set_title(f'Plot {cond}')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3217312",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4 = epochs_(epochs, 'n_closing', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_4.average().plot(gfp='only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5e02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a87839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs\n",
    "\n",
    "class CustomEpochs(Epochs):\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        # Parse the key into metadata field name and value\n",
    "        field, value = key.split('==')\n",
    "        field = field.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Get the indices of the epochs that match the metadata query\n",
    "        indices = [i for i, metadata in enumerate(self.metadata[field]) if metadata == value]\n",
    "\n",
    "        # Return a new Epochs object containing only the matching epochs\n",
    "        return self.__class__(self._data[indices], self.events[indices], self.event_id,\n",
    "                              tmin=self.tmin, tmax=self.tmax, baseline=self.baseline,\n",
    "                              metadata=self.metadata.iloc[indices], info=self.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs = CustomEpochs(epochs, epochs.events, \"1\", -0.2, 0.8, epochs.baseline, epochs.metadata)\n",
    "\n",
    "# Get all epochs where the 'kind' metadata field is 'word':\n",
    "word_epochs = custom_epochs['kind==word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07344132",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch\n",
    "def mne_events(meta):\n",
    "    events = np.ones((len(meta), 3), dtype=int)\n",
    "    events[:, 0] = meta.start*raw.info['sfreq']\n",
    "    return dict(events=events, metadata=meta.reset_index())\n",
    "\n",
    "epochs = mne.Epochs(raw, **mne_events(meta), decim=20, tmin=-.2, tmax=1.5, preload=True)\n",
    "epochs = epochs['kind==\"word\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_path, get_subjects, epoch_data, epoch_runs\n",
    "from utils import (\n",
    "    decod,\n",
    "    correlate,\n",
    "    match_list,\n",
    "    create_target,\n",
    "    analysis,\n",
    "    save_decoding_results,\n",
    ")\n",
    "from plot import plot_subject\n",
    "import mne_bids\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import spacy\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "RUN = 9\n",
    "task = \"read\"\n",
    "subject = subjects[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856d515",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = epoch_runs(subject, RUN, task, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0915f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs.metadata).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.load_data()\n",
    "epochs = epochs['kind==\"word\"']\n",
    "epochs[\"content_word == False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
