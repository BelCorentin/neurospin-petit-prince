{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de81e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoching for run 1, subject: 3\n",
      "\n",
      "Opening raw data file /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 36000 ... 517999 =     36.000 ...   517.999 secs\n",
      "Ready.\n",
      "Reading events from /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /home/is153802/data/LPP_MEG_visual/sub-3/ses-01/meg/sub-3_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:51: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:51: RuntimeWarning: Omitted 81 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:51: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger channel has a non-zero initial value of 8 (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1466 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "1711          lueur\n",
      "1713           dans\n",
      "1714             le\n",
      "1715        mystère\n",
      "1716             de\n",
      "1717             sa\n",
      "1718       présence\n",
      "1720             et\n",
      "1721              j\n",
      "1723    interrogeai\n",
      "1724    brusquement\n",
      "1726              —\n",
      "1727             tu\n",
      "1728          viens\n",
      "1729           donc\n",
      "1730              d\n",
      "1732            une\n",
      "1733          autre\n",
      "1734        planète\n",
      "1736           mais\n",
      "1737             il\n",
      "1738             ne\n",
      "1739             me\n",
      "1740       répondit\n",
      "1741            pas\n",
      "1743             il\n",
      "1744        hochait\n",
      "1745             la\n",
      "1746           tête\n",
      "1747      doucement\n",
      "1748           tout\n",
      "1749             en\n",
      "1750      regardant\n",
      "1751            mon\n",
      "1752          avion\n",
      "1754              —\n",
      "1755              c\n",
      "1757            est\n",
      "1758           vrai\n",
      "1759            que\n",
      "1761             là\n",
      "1763         dessus\n",
      "1765             tu\n",
      "1766             ne\n",
      "1767           peux\n",
      "1768            pas\n",
      "1769          venir\n",
      "1770             de\n",
      "1771           bien\n",
      "1772           loin\n",
      "Name: word, dtype: object 1540         éclat\n",
      "1541            de\n",
      "1542          rire\n",
      "1543          mais\n",
      "1544            où\n",
      "1545        veuxtu\n",
      "1546            qu\n",
      "1547            il\n",
      "1548         aille\n",
      "1549             n\n",
      "1550       importe\n",
      "1551            où\n",
      "1552         droit\n",
      "1553        devant\n",
      "1554           lui\n",
      "1555         alors\n",
      "1556            le\n",
      "1557         petit\n",
      "1558        prince\n",
      "1559      remarqua\n",
      "1560     gravement\n",
      "1561            ça\n",
      "1562            ne\n",
      "1563          fait\n",
      "1564          rien\n",
      "1565             c\n",
      "1566           est\n",
      "1567     tellement\n",
      "1568         petit\n",
      "1569          chez\n",
      "1570           moi\n",
      "1571            et\n",
      "1572          avec\n",
      "1573            un\n",
      "1574           peu\n",
      "1575            de\n",
      "1576    mélancolie\n",
      "1577      peutêtre\n",
      "1578            il\n",
      "1579        ajouta\n",
      "1580         droit\n",
      "1581        devant\n",
      "1582           soi\n",
      "1583            on\n",
      "1584            ne\n",
      "1585          peut\n",
      "1586           pas\n",
      "1587         aller\n",
      "1588          bien\n",
      "1589          loin\n",
      "Name: clean_word, dtype: object\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[1588, 1589] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m             dict_epochs[epoch_key] \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,runs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     raw, meta_, events \u001b[38;5;241m=\u001b[39m read_raw(subject, run, events_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m     meta \u001b[38;5;241m=\u001b[39m meta_\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Metadata update\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Word start\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/reading/dataset.py:71\u001b[0m, in \u001b[0;36mread_raw\u001b[0;34m(subject, run_id, events_return)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Enriching the metadata with outside files:\u001b[39;00m\n\u001b[1;32m     70\u001b[0m path_syntax \u001b[38;5;241m=\u001b[39m get_code_path() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/syntax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 71\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43madd_syntax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# add sentence and word positions\u001b[39;00m\n\u001b[1;32m     74\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(meta\u001b[38;5;241m.\u001b[39mis_last_word\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/decoding/reading/utils.py:247\u001b[0m, in \u001b[0;36madd_syntax\u001b[0;34m(meta, syntax_path, run)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, default_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(n_closing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, is_last_word\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXXX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    246\u001b[0m     meta[key] \u001b[38;5;241m=\u001b[39m default_value\n\u001b[0;32m--> 247\u001b[0m     \u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m synt\u001b[38;5;241m.\u001b[39miloc[j][key]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    249\u001b[0m content_pos \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVINF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVPP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_word\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m pos: pos \u001b[38;5;129;01min\u001b[39;00m content_pos \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pos, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    252\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:712\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    711\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 712\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:661\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m--> 661\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:799\u001b[0m, in \u001b[0;36m_LocationIndexer._convert_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m--> 799\u001b[0m         idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m         keyidx\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(keyidx)\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:1294\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inds\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1327\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1328\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1330\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/meg-masc/lib/python3.10/site-packages/pandas/core/indexes/base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[1588, 1589] not in index'"
     ]
    }
   ],
   "source": [
    "from dataset import read_raw, get_subjects, get_path, mne_events\n",
    "from utils import decod_xy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import match_list\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "all_evos = []\n",
    "all_scores = []\n",
    "\n",
    "path = get_path(\"LPP_read\")\n",
    "subjects = get_subjects(path)\n",
    "task = \"read\"\n",
    "# Debug\n",
    "runs = 1\n",
    "\n",
    "epoch_windows = {\"word\": {\"onset_min\": -0.3, \"onset_max\": 1.0, \"offset_min\": -1.0, \"offset_max\": 0.3},\n",
    "                  \"constituent\": {\"offset_min\": -2.0, \"offset_max\": 0.5, \"onset_min\": -0.5, \"onset_max\": 2.0},\n",
    "                  \"sentence\": {\"offset_min\": -4.0, \"offset_max\": 1.0, \"onset_min\": -1.0, \"onset_max\": 4.0}}\n",
    "\n",
    "\n",
    "            \n",
    "for subject in subjects[2:3]:\n",
    "    dict_epochs = dict() # DICT containing epochs grouped by conditions (start x level)\n",
    "    # Dict init\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):\n",
    "                epoch_key = f'{level}_{start}'\n",
    "                dict_epochs[epoch_key] = [] \n",
    "    for run in range(1,runs+1):\n",
    "        raw, meta_, events = read_raw(subject, run, events_return = True)\n",
    "        meta = meta_.copy()\n",
    "        # Metadata update\n",
    "        # Word start\n",
    "        meta['word_onset'] = True\n",
    "\n",
    "        # Word end\n",
    "        meta['word_offset'] = True\n",
    "\n",
    "        # Sent start\n",
    "        meta['sentence_onset'] = meta.word_id == 0\n",
    "\n",
    "        # Sent stop\n",
    "        meta['next_word_id'] = meta['word_id'].shift(-1)\n",
    "        meta['sentence_offset'] = meta.apply(lambda x: True if x['word_id'] > x['next_word_id'] else False, axis=1)\n",
    "        meta['sentence_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_word_id', axis=1, inplace=True)\n",
    "\n",
    "        # Const start\n",
    "        meta['prev_closing'] = meta['n_closing'].shift(1)\n",
    "        meta['constituent_onset'] = meta.apply(lambda x: True if x['prev_closing'] > x['n_closing'] and x['n_closing'] == 1 else False, axis=1)\n",
    "        meta['constituent_onset'].fillna(False, inplace=True)\n",
    "        meta.drop('prev_closing', axis=1, inplace=True)\n",
    "\n",
    "        # Const stop\n",
    "        meta['next_closing'] = meta['n_closing'].shift(-1)\n",
    "        meta['constituent_offset'] = meta.apply(lambda x: True if x['n_closing'] > x['next_closing'] else False, axis=1)\n",
    "        meta['constituent_offset'].fillna(False, inplace=True)\n",
    "        meta.drop('next_closing', axis=1, inplace=True)\n",
    "\n",
    "        for start in ('onset', 'offset'): \n",
    "            # for level in ('word', 'constituent', 'sentence'):\n",
    "            for level in ('sentence', 'constituent', 'word'):\n",
    "                # Select only the rows containing the True for the conditions (sentence_end, etc..)\n",
    "                sel = meta.query(f'{level}_{start}==True')\n",
    "                assert sel.shape[0] > 10  #\n",
    "                # TODO check variance as well for sentences\n",
    "                # Matchlist events and meta\n",
    "                # So that we can epoch now that's we've sliced our metadata\n",
    "                i, j = match_list(events[:, 2], sel.word.apply(len))\n",
    "                sel = sel.reset_index().loc[j]\n",
    "                epochs = mne.Epochs(raw, **mne_events(sel, raw), decim = 10,\n",
    "                                     tmin = epoch_windows[f'{level}'][f'{start}_min'],\n",
    "                                       tmax = epoch_windows[f'{level}'][f'{start}_max'],\n",
    "                                         event_repeated = 'drop', # check event repeated\n",
    "                                            preload=True)  # n_words OR n_constitutent OR n_sentences\n",
    "                epoch_key = f'{level}_{start}'\n",
    "            \n",
    "                dict_epochs[epoch_key].append(epochs)\n",
    "        \n",
    "            \n",
    "    # Once we have the dict of epochs per condition full (epoching for each run for a subject)\n",
    "    # we can concatenate them, and fix the dev_head             \n",
    "    for start_ in ('onset', 'offset'): \n",
    "        for level_ in ('word', 'constituent', 'sentence'):\n",
    "            epoch_key = f'{level_}_{start_}'\n",
    "            all_epochs_chosen = dict_epochs[epoch_key]\n",
    "            # Concatenate epochs\n",
    "            for epo in all_epochs_chosen:\n",
    "                epo.info[\"dev_head_t\"] = all_epochs_chosen[1].info[\"dev_head_t\"]\n",
    "\n",
    "            dict_epochs[epoch_key] = mne.concatenate_epochs(all_epochs_chosen)\n",
    "\n",
    "    # Now that we have all the epochs, rerun the plotting / decoding on averaged\n",
    "    for start in ('onset', 'offset'): \n",
    "            for level in ('word', 'constituent', 'sentence'):  \n",
    "                epoch_key = f'{level}_{start}'\n",
    "                epochs = dict_epochs[epoch_key]\n",
    "                # mean\n",
    "                evo = epochs.copy().pick_types(meg=True).average(method='median')\n",
    "                all_evos.append(dict(subject=subject, evo=evo, start=start, level=level))\n",
    "\n",
    "all_scores = pd.DataFrame(all_scores,index=False)\n",
    "all_evos = pd.DataFrame(all_evos,index=False)\n",
    "\n",
    "all_scores.to_csv('./score.csv')\n",
    "all_evos.to_csv('./evos.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
