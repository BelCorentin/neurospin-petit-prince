{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c94f2ac-eafd-4ef3-b240-048cf7e432ae",
   "metadata": {},
   "source": [
    "# Clean version of the auditory debug ntbk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a4220",
   "metadata": {},
   "source": [
    "# Testing updated JRA match list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765c85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import logging\n",
    "import mne_bids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from jra_utils import approx_match_samples\n",
    "\n",
    "from pathlib import Path\n",
    "# Set the logger level to WARNING to reduce verbosity\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "#path = Path(\"/home/co/data/neuralset/LPP_copy/pallierlisten2023/download\")\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "def testing(subject, run_id, n_missing):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    triggers = mne.find_stim_steps(raw, stim_channel=\"STI008\")\n",
    "    # Offsets\n",
    "    triggers = triggers[triggers[:, 2] == 0]\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Remove the empty words:\n",
    "\n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    words = meta\n",
    "\n",
    "    events_df = meta\n",
    "    # Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "    # word_triggers = triggers[triggers[:, 2] > 1]\n",
    "    word_triggers = triggers\n",
    "    try:\n",
    "        i, j = approx_match_samples((words.start * 1000).tolist()[:], word_triggers[:, 0], abs_tol=10, max_missing=n_missing)\n",
    "        return f\"Worked for {subject} {run_id}, {len(i) / words.start.shape[0]}\"\n",
    "    except Exception as e:\n",
    "        # When it doesn't work, print the index where it broke, and create a new file from it\n",
    "        # To add to the tests\n",
    "        print(f\"Failed for {subject} {run_id}\")\n",
    "        print(f\"Error message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80049e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_subjects = 24\n",
    "worked = 0\n",
    "n_missing = 5\n",
    "for subject in range(1,total_subjects+1):\n",
    "    for run in range(1,10):\n",
    "        run_id = '0' + str(run)\n",
    "        subject = str(subject)\n",
    "        result = testing(subject, run_id, n_missing)\n",
    "        try:\n",
    "            if \"Worked\" in result:\n",
    "                print(f\"{result}\")\n",
    "                worked += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {subject} {run_id}\")\n",
    "            continue\n",
    "\n",
    "print(f\"Worked for {worked} out of {total_subjects} subjects: {worked / total_subjects * 100} for {n_missing} missing samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f4f5f",
   "metadata": {},
   "source": [
    "# Updating JRA match list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff34c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download/sub-44/ses-01/meg/sub-44_ses-01_task-listen_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 33000 ... 652999 =     33.000 ...   652.999 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-1a412fcadf64>:22: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading events from /media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download/sub-44/ses-01/meg/sub-44_ses-01_task-listen_run-01_events.tsv.\n",
      "Reading channel info from /media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download/sub-44/ses-01/meg/sub-44_ses-01_task-listen_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-1a412fcadf64>:22: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "import mne_bids\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "run_id = '01'\n",
    "subject = '44'\n",
    "\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "task = 'listen'\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "# triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "# triggers = mne.find_events(raw, stim_channel=\"STI008\", shortest_event=1)\n",
    "\n",
    "# Filtering \n",
    "\n",
    "triggers = mne.find_stim_steps(raw, stim_channel=\"STI008\")\n",
    "# Offsets\n",
    "triggers = triggers[triggers[:, 2] == 0]\n",
    "\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "        lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "# Remove the empty words:\n",
    "\n",
    "meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "# Drop the rows containing NaN values in the text column\n",
    "meta = meta.dropna(subset=['word'])\n",
    "\n",
    "meta['start'] = meta.onset\n",
    "\n",
    "words = meta\n",
    "\n",
    "events_df = meta\n",
    "# Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "# word_triggers = triggers[triggers[:, 2] > 1]\n",
    "word_triggers = triggers\n",
    "\n",
    "# Building a complete array to understand whats going on before / after match list\n",
    "\n",
    "# i, j = approx_match_samples(word_triggers[:, 0], (words.start * 1000).tolist()[:], tol=10)\n",
    "\n",
    "# current_i = -1\n",
    "# current_j = -1\n",
    "\n",
    "# list_events = []\n",
    "# for i_, j_ in zip(i, j):  # Make sure that 'i' and 'j' iterables are defined before this line\n",
    "#     for m_i in range(current_i + 1, i_):\n",
    "#         list_events.append({\"data\": \"trigger\", \"trigger_ind\": m_i, \"trigger_time\": word_triggers[m_i][0]/ raw.info['sfreq']})\n",
    "        \n",
    "#     for m_j in range(current_j + 1, j_):\n",
    "#         list_events.append({\"data\": \"word\", \"word\": words.word.iloc[m_j], \"word_time\": words.onset.iloc[m_j], \"word_duration\": words.duration.iloc[m_j]})\n",
    "#     list_events.append({\"data\": \"match\", \"trigger_ind\": i_, \"word_ind\":words.index[j_], \"word\": words.word.iloc[j_], \"trigger_time\": word_triggers[i_][0] / raw.info['sfreq'], \"word_time\": words.onset.iloc[j_], \"word_duration\": words.duration.iloc[j_]})\n",
    "#     current_i = i_\n",
    "#     current_j = j_\n",
    "    \n",
    "\n",
    "# df_events = pd.DataFrame(list_events)\n",
    "# df_events = df_events.loc[:, sorted(df_events.columns)]\n",
    "# df_events.to_csv('./df_events.csv', sep = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9badcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import jra_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "seq0 = word_triggers[:, 0]\n",
    "seq1 = (words.start * 1000).tolist()\n",
    "\n",
    "\n",
    "\n",
    "def plot_matches(seq0, seq1):\n",
    "    try:\n",
    "        matches = utils.approx_match_samples(seq0, seq1, abs_tol=10, max_missing=5)\n",
    "    except utils.NoApproximateMatch as e:\n",
    "        matches = e.matches\n",
    "        print(e)\n",
    "    position0 = seq0[matches[0][-1]]\n",
    "    position1 = seq1[matches[1][-1]]\n",
    "    offset = position0 - position1\n",
    "    print(f\"Matching until {position0} ({position1} on second seq, {offset=}\")\n",
    "    L = max(0, int(max(seq0) + 10))\n",
    "    for d, seq, m, off in [(1, seq0, matches[0], 0), (-1, seq1, matches[1], offset)]:\n",
    "        print(off)\n",
    "        data = np.zeros(L)\n",
    "        select = (np.array(seq) + off).astype(int)\n",
    "        select2 = select[m]\n",
    "        select = select[0 <= select]\n",
    "        select = select[select < len(data)]\n",
    "        data[select] = d\n",
    "        data[select2] += d\n",
    "        # Label this plotted data as the ground truth\n",
    "        plt.plot(data)\n",
    "\n",
    "    return matches\n",
    "\n",
    "# plot_matches(seq0, seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67761360",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stim = raw.pick_channels(['STI008']).get_data()\n",
    "data_stim = data_stim / 10\n",
    "to_add = np.zeros(raw.first_samp)\n",
    "data_stim = np.concatenate([to_add, data_stim[0]])\n",
    "\n",
    "matches = plot_matches(seq0, seq1)\n",
    "\n",
    "plt.plot(data_stim)\n",
    "# Label this last plot as the MEG data\n",
    "plt.legend(['Mne Processed STI008', 'Ground truth', 'Raw STI008 MEG data'])\n",
    "\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc81f83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7e13157a51f0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the difference between matched metadata times and MEG triggers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(np.array(seq0) - np.array(seq1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "plot_matches(seq0, seq1)\n",
    "plt.plot(data_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into a csv file both arrays that were used for matching\n",
    "np.save(f'saves/word_triggers_{subject}_{run_id}.npy', word_triggers[:, 0])\n",
    "np.save(f'saves/words_start_{subject}_{run_id}.npy', (words.start * 1000).tolist())\n",
    "# save datastim\n",
    "np.save(f'saves/data_stim_{subject}_{run_id}.npy', data_stim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "raw.pick_types(stim=True, misc=True).plot(block=True, start=0, duration=10., precompute='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bf700",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.first_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot((words.start * 1000).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(word_triggers[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881ea6f-1cdc-4978-8b15-a721d220f78f",
   "metadata": {},
   "source": [
    "# Testing JR alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1facb-d4ae-49fe-9c81-aea4210c07c3",
   "metadata": {},
   "source": [
    "Trying to use the alignment method done by JR to show that the decoding works better! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c3e8a-a870-45bb-a816-571b1ef7ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the wrong indices:\n",
    "\n",
    "wrongs = {}\n",
    "\n",
    "wrongs['5'] = {}\n",
    "\n",
    "wrongs['5']['3'] = {'events' :759, 'triggers': 804}\n",
    "\n",
    "wrongs['5']['4'] = {'events' :974, 'triggers': 1061}\n",
    "\n",
    "wrongs['5']['9'] = {'events' :630, 'triggers': 670}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b13dc-90e4-41fa-b75d-49b2f8059a8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_events = []\n",
    "error_triggers = []\n",
    "for subject in wrongs.keys():\n",
    "    for run in wrongs[subject].keys():\n",
    "        run_id = '0' + str(run)\n",
    "        subject = str(subject)\n",
    "        word_triggers, meta = get_triggers(subject, run_id)\n",
    "        id_trigger = wrongs[subject][run]['triggers']\n",
    "        id_events = wrongs[subject][run]['events']\n",
    "        \n",
    "        # Get an array around the problematic indexes\n",
    "        window = 10\n",
    "        trigger_array = word_triggers[id_trigger - window:id_trigger + window][:,0]\n",
    "        events_array = np.array(meta.iloc[id_events - window:id_events + window].start * 1000)\n",
    "        \n",
    "        error_events.append(events_array)\n",
    "        error_triggers.append(trigger_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c38dc9-b188-4812-8376-c7d8a36176eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77943b-b952-49ce-bb05-46999123b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83506340-7204-42b5-814b-f4152f3aba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triggers(subject, run_id):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Remove the empty words:\n",
    "\n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    words = meta\n",
    "\n",
    "    events_df = meta\n",
    "    return triggers[triggers[:, 2] > 1], meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58602e-31fa-4ced-afc9-08965438a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import logging\n",
    "import mne_bids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from jr_utils import Align, resample_safe\n",
    "from utils import match_list\n",
    "\n",
    "from pathlib import Path\n",
    "# Set the logger level to WARNING to reduce verbosity\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# General epoching function\n",
    "alignment = True\n",
    "\n",
    "run_id = '01'\n",
    "subject = '4'\n",
    "\n",
    "#path = Path(\"/home/co/data/neuralset/LPP_copy/pallierlisten2023/download\")\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "def testing(subject, run_id):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Remove the empty words:\n",
    "\n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    words = meta\n",
    "\n",
    "    events_df = meta\n",
    "    # Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "    word_triggers = triggers[triggers[:, 2] > 1]\n",
    "    try:\n",
    "        i, j = approx_match_samples((words.start * 1000).tolist()[:], word_triggers[:, 0], tol=50, max_missing=3)\n",
    "        return f\"Worked for {subject} {run_id}, {len(i) / words.start.shape[0]}\"\n",
    "    except Exception as e:\n",
    "        # When it doesn't work, print the index where it broke, and create a new file from it\n",
    "        # To add to the tests\n",
    "        print(f\"Failed for {subject} {run_id}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "\n",
    "for subject in range(5,6):\n",
    "    for run in range(1,10):\n",
    "        run_id = '0' + str(run)\n",
    "        subject = str(subject)\n",
    "        print(testing(subject, run_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671febf-419a-407f-abea-6522675baa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "for subject in range(5,6):\n",
    "    for run in range(1,10):\n",
    "        run_id = '0' + str(run)\n",
    "        subject = str(subject)\n",
    "        print(testing(subject, run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10970062-2161-4898-90bb-6a0c369f3f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7ef91-89b1-45bd-b6d2-2e99f8e15156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "for subject in range(21,25):\n",
    "    for run in range(6,9):\n",
    "        run_id = '0' + str(run)\n",
    "        subject = str(subject)\n",
    "        print(testing(subject, run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54dc4f-29fc-4a2a-8369-8393dc32a071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i, j = approx_match_samples((words.start * 1000).tolist()[:], word_triggers[:, 0], tol=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe8d73-c900-4681-bfb9-0923e22b2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff((words.start * 1000))[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a3d7e-9526-451a-b9b9-45dd07225bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.to_csv(, \"test.csv\")\n",
    "words_times = words.start * 1000\n",
    "np.savetxt('words_times.csv', words_times, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05694637-2185-4ee9-9f1e-ec34b43fec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import mne\n",
    "    import logging\n",
    "    import mne_bids\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.io import wavfile\n",
    "\n",
    "    from jr_utils import Align, resample_safe\n",
    "    from utils import match_list\n",
    "\n",
    "    from pathlib import Path\n",
    "    # Set the logger level to WARNING to reduce verbosity\n",
    "    logger = logging.getLogger('mne')\n",
    "    logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "    # General epoching function\n",
    "    alignment = True\n",
    "\n",
    "    run_id = '01'\n",
    "    subject = '3'\n",
    "\n",
    "    path = Path(\"/home/co/data/neuralset/LPP_copy/pallierlisten2023/download\")\n",
    "\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Remove the empty words:\n",
    "\n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    words = meta\n",
    "\n",
    "    events_df = meta\n",
    "    # Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "    word_triggers = triggers[triggers[:, 2] > 1]\n",
    "\n",
    "    # Testing the JR alignment\n",
    "\n",
    "    if alignment:\n",
    "        starts = mne.find_events(raw, output='step', shortest_event=1)[:, 0]\n",
    "        meg_times = np.copy(raw.times)\n",
    "        meg_triggers = np.zeros_like(meg_times)\n",
    "        meg_triggers[starts - raw.first_samp] = 1\n",
    "\n",
    "        # read wav\n",
    "        path_wav = path / 'sourcedata/stimuli/audio/ch1-3.wav'\n",
    "        wav_freq, wav = wavfile.read(path_wav)\n",
    "        wav = wav[:, 1] / wav.max()\n",
    "        # -- decim to get down to meg frequency\n",
    "        wav_triggers = resample_safe(wav, int(len(wav)/wav_freq*raw.info['sfreq']))\n",
    "\n",
    "        # -- get events\n",
    "        wav_times = np.cumsum(np.ones(len(wav_triggers)))/wav_freq\n",
    "        # fit alignment\n",
    "        align = Align(freq=raw.info['sfreq'], decim=100)\n",
    "        inds = np.where(np.diff(wav_triggers) > 0)[0] + 1\n",
    "        wav_spikes = 0 * wav_triggers\n",
    "        wav_spikes[inds] = 1\n",
    "        n = min(len(wav_spikes), len(meg_triggers))\n",
    "        align.fit(wav_spikes[:n], meg_triggers[:n])\n",
    "        out = align.predict(wav_spikes)\n",
    "\n",
    "    # Now that we have the out object, which represents the shifted triggers in the corrected frequency space\n",
    "    # We can finally realign it with the metdata starts, after diving by sfreq.\n",
    "\n",
    "    # Transform the current out object to make it like the triggers one, in order to be able \n",
    "    # To match on the timing diffs\n",
    "\n",
    "    # Handle the fact that the triggers are multiple values eg. [0 0 0 1 1 1 0 0 0 0 0 0 1 1 1  0 0 0]\n",
    "    #unique_vals, counts = np.unique(wav_triggers, return_counts=True)\n",
    "    #(array([0.        , 0.91555528]), array([602472,  11045]))\n",
    "\n",
    "    trigger_value = np.unique(out)[1]\n",
    "    aligned_trigger_indices = np.where(np.diff(out) == trigger_value)[0] + 1\n",
    "\n",
    "\n",
    "    # Matching triggers and metadata\n",
    "    decimals = 2\n",
    "    triggers_delta = np.round(np.diff(word_triggers[:, 0] / raw.info[\"sfreq\"]), decimals=decimals)  # type: ignore\n",
    "    events_delta = np.round(np.diff(words.start.values), decimals=decimals)  # type: ignore\n",
    "    i, j = match_list(triggers_delta, events_delta)\n",
    "\n",
    "    print(f\"Found {len(i)/len(words)} of the words in the triggers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a49a1-f12f-4671-91ed-ca5c4c3c6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(align._corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6a712-5a68-4565-b98e-0d4cbd8eee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(meg_triggers)\n",
    "plt.plot(-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bb18c-6eb4-449a-b98c-5049c06eeafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34f72b-6e2c-4975-9471-0c1307b897ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(np.where(wav_spikes)[0][:8]) , np.diff(np.where(meg_triggers)[0][:10]), np.diff(np.where(out)[0][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ddb54-fb2d-4de4-833c-9bbf736c04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(wav_triggers)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd5a2d-b166-4fda-a771-2a3726eb4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.last_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fbbbd-5928-4d2e-9372-8c34ba67eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_trigger_indices.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef8a64-df45-4937-adb2-de3106adf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching triggers and metadata\n",
    "decimals = 2\n",
    "triggers_delta = np.round(np.diff(aligned_trigger_indices / raw.info[\"sfreq\"]), decimals=decimals)  # type: ignore\n",
    "events_delta = np.round(np.diff(meg_triggers), decimals=decimals)  # type: ignore\n",
    "i, j = match_list(triggers_delta, events_delta)\n",
    "\n",
    "print(f\"Found {len(i)/len(words)} of the words in the triggers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564a4baa-d179-4d07-bcb3-93e56fd1edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5692e-19b6-49df-b713-157c04287903",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24119710-8f83-4335-a5da-3af20638465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faca0ff-91f7-4230-b84a-81263c87f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_triggers[-1][0] - word_triggers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50109f4-0026-4257-8964-56b6a8e7c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_trigger_indices[-1] - aligned_trigger_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47ad10-625d-45e1-95dd-1e3377fdea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "align._stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b6ee7-e495-45c3-9cb5-a4aaaa1f279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "align._offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24777f-109b-444d-9590-799c052e48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(aligned_trigger_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d948d5-a636-4783-9427-f99d7f272ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_value = np.unique(out)[1]\n",
    "aligned_trigger_indices = np.where(np.diff(out) == trigger_value)[0] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3609f-9e9a-4264-bfbe-72b1821fcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.first_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b8eff-9391-44c8-a195-142722b67133",
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e13ed-113f-4864-8d41-3c9efb9ef18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "17890 + 28000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a236c3d-d665-4a0f-80a6-317aca58992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_trigger_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557c216-6ce7-4af8-9f86-7b58923d2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a numpy array of the downsampled audio signal\n",
    "    \n",
    "# Create a numpy array of the time axis for the downsampled signal\n",
    "downsampled_time = np.arange(len(signal)) / 1000\n",
    "\n",
    "# Create a numpy array of the time axis for the original signal\n",
    "original_time = np.arange(len(signal) * 44) / 44100\n",
    "\n",
    "# Use interpolation to upsample the downsampled signal to the original sampling rate\n",
    "upsampled_signal = np.interp(original_time, downsampled_time, signal)\n",
    "\n",
    "# Plot the downsampled and upsampled signals\n",
    "plt.plot(original_time, upsampled_signal, label='Upsampled signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74324ae0-d269-4551-b1b0-a3a1814c5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_indices = words.iloc[j].index\n",
    "\n",
    "mask = events_df.index.isin(true_indices)\n",
    "\n",
    "# Set the start column for the selected rows\n",
    "events_df.loc[mask, \"start\"] = (\n",
    "    aligned_trigger_indices[i] / raw.info[\"sfreq\"]\n",
    ")\n",
    "\n",
    "# Drop the rows that don't match the indices in true_indices\n",
    "events_df = events_df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675ad08-2401-44b9-862f-a13570b4e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = events_df.sort_values(by=\"start\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada75bb-0246-4e70-826c-69a3a268a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbc2f3-5b97-4497-b2d2-038585319af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Grid testing\n",
    "\n",
    "Testing the timings & nb of triggers in the original TextGrid file that was used to generate metadata / triggers in the wav file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16d48c-dcd8-4e47-ae98-9b8123f0a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrids as tg\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "files = [f'/home/co/tmp/testing_code/{i}.TextGrid' for i in range(1,4)]\n",
    "\n",
    "all_starts = []\n",
    "grid_starts = []\n",
    "grid_word_count = []\n",
    "\n",
    "for file in files:\n",
    "    textgrid = tg.TextGrid(file)\n",
    "    words = [interval.text for interval in (textgrid['text words']) if interval.text != \"\"]\n",
    "    starts = [interval.xmin for interval in (textgrid['text words']) if interval.text != \"\"]\n",
    "    all_starts.append(starts)\n",
    "    grid_word_count.append(len(words))\n",
    "    \n",
    "    first_pause = textgrid['text words'][0].xmax\n",
    "    grid_starts.append(first_pause)\n",
    "    \n",
    "grid_length = [starts[-1] - starts[0] for starts in all_starts]\n",
    "\n",
    "for i in range(len(grid_length)):\n",
    "    print(f'For run {i+1}')\n",
    "    print(f'Word count: {grid_word_count[i]}')\n",
    "    print(f'Grids word length from Praat textgrids: {grid_length[i]} ') \n",
    "    print(f'Grid start from audio start to first word: {grid_starts[i]} ') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ffe7d3-856a-4f31-a9b9-eb281ad4001b",
   "metadata": {},
   "source": [
    "# Wav File testing\n",
    "\n",
    "Now testing the amount of triggers in the wav file, as well as its real length (as used in the MEG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba3d83-c873-43dd-b7d6-2de3b7187e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CHAPTER_PATHS = [\n",
    "    \"ch1-3.wav\",\n",
    "    \"ch4-6.wav\",\n",
    "    \"ch7-9.wav\",\n",
    "    \"ch10-12.wav\",\n",
    "    \"ch13-14.wav\",\n",
    "    \"ch15-19.wav\",\n",
    "    \"ch20-22.wav\",\n",
    "    \"ch23-25.wav\",\n",
    "    \"ch26-27.wav\",\n",
    "]\n",
    "\n",
    "audio_word_trigger_length = []\n",
    "audio_trigger_length = []\n",
    "\n",
    "for i, chapter in enumerate(CHAPTER_PATHS):\n",
    "    wav_file = f'/home/co/data/neuralset/LPP_copy/PallierListen2023/download/sourcedata/stimuli/audio/{chapter}'\n",
    "    duration = get_wav_duration(wav_file)\n",
    "    fs, data = wavfile.read(wav_file)\n",
    "\n",
    "    # Getting the channel for the triggers encoded in the 2nd part of the wav\n",
    "    data = data[:,1]\n",
    "    data = np.round(data / 30000)\n",
    "    diff = np.diff(data)\n",
    "    audio_triggers = np.where(diff == 1)[0]\n",
    "    word_total_length =  (audio_triggers[-1] - audio_triggers[0] )/ fs\n",
    "    \n",
    "    audio_word_trigger_length.append(word_total_length)\n",
    "    audio_trigger_length.append(duration)\n",
    "    print(f'For run: {i+1}')\n",
    "    print(f'Word count:' , len(audio_triggers))\n",
    "    print(\"Length of word triggers in the audio file : \", word_total_length)\n",
    "    print(\"TOTAL Length of the audio file : \", duration)\n",
    "    print(f'Wav start from audio start to first word: {audio_triggers[0] / fs} ') \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72997aad-14cf-4a12-9ace-837bce58de48",
   "metadata": {},
   "source": [
    "# Metadata testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df564b5d-e83e-4e0f-b3d5-82569fb3e437",
   "metadata": {},
   "source": [
    "There is an inherent problem that I could fix with the metadata. In the textgrid, there is a weird jump with du (it is always followed by an empty event \"\").\n",
    "\n",
    "I added it to the metadata, but it is not present in the triggers. It means a difference of ~40 words that are missed when matching on metadata with triggers. \n",
    "\n",
    "I fixed it by removing empty words when reading the event file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638bbd6-cd8f-4e46-b3a9-dc99cd8f597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/co/data/LPP_MEG_auditory/sub-1/ses-01/meg/sub-1_ses-01_task-listen_run-\"\n",
    "\n",
    "for run in range(1,10):\n",
    "    file = path + f'0{run}_events.tsv'\n",
    "    meta = pd.read_csv(file, sep='\\t')\n",
    "    meta['start'] = meta.onset\n",
    "    \n",
    "    # Trying to remove the additional empty word\n",
    "    \n",
    "    meta_triggers = meta.start\n",
    "    print(f'For run {run}')\n",
    "    print(f'Word count: {meta.shape[0]}')\n",
    "    print(f'Meta length from metadata file: {(meta_triggers.iloc[-1] - meta_triggers.iloc[0])} ') \n",
    "    print(f'Metadata start from audio start to first word: {meta_triggers[0]} ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72912ad-4fe1-4f9e-8c49-4405bcce1836",
   "metadata": {},
   "source": [
    "# Triggers testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two events in STI001\n",
    "# Start of sound, first trigger STI008613.5172789115646\n",
    "# Verify buffer over/under run\n",
    "# Instller JACK driver audio PC MEG?\n",
    "\n",
    "# Timing photodiode theorique PallierRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a4a43-36a3-4652-a1ae-a34c6cd77998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import logging\n",
    "import mne_bids\n",
    "# Set the logger level to WARNING to reduce verbosity\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "subject = '2'\n",
    "\n",
    "all_triggers = []  # All the trigger timings\n",
    "all_word_triggers = []  # All the word triggers\n",
    "trigger_starts = []  # The time of between first trigger (beginning of audio) and first word\n",
    "triggers_word_count = []  # The total number of word triggers for each run\n",
    "all_word_trigger_length = []  # The total length from the first word trigger to the last one\n",
    "all_trigger_length = []  # The total length from the first trigger to the last one (the whole audio file)\n",
    "\n",
    "for run in range(1,10):\n",
    "    run_id = '0'+ str(run)\n",
    "    # Audio data\n",
    "    \n",
    "    audio_data = get_audio_timestamps(subject, run_id)\n",
    "    \n",
    "    # Triggers words\n",
    "    f, triggers = get_triggers(subject, run_id)\n",
    "    all_triggers.append(triggers)\n",
    "    \n",
    "    word_triggers = triggers[triggers[:, 2] > 1][:,0]\n",
    "    all_word_triggers.append(word_triggers)\n",
    "    \n",
    "    first_diff = (triggers[1][0] - triggers[0][0]) / f\n",
    "    trigger_starts.append(first_diff)\n",
    "    \n",
    "    triggers_word_count.append(word_triggers.shape[0])\n",
    "    \n",
    "    word_trigger_length = (word_triggers[-1] - word_triggers[0]) / f\n",
    "    all_word_trigger_length.append(word_trigger_length)\n",
    "    \n",
    "    total_length = triggers[-1][0] - triggers[0][0]\n",
    "    all_trigger_length.append(total_length)\n",
    "        \n",
    "for i in range(len(all_word_trigger_length)):\n",
    "    print(f'For run {i}')\n",
    "    print(f'Number of word triggers: {triggers_word_count[i]} ') \n",
    "    print(f'Trigger start from audio start to first word: {trigger_starts[i]} ') \n",
    "    print(f'Total length of words triggers: {all_word_trigger_length[i]}')\n",
    "    print(f'Total length from first triger to the last: {all_trigger_length[i] / f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb3e5d-8ab6-4974-a2f9-25f07443e0b8",
   "metadata": {},
   "source": [
    "# Comparaisons\n",
    "\n",
    "Let's compare the difference between the trigger length recorded vs theoritical, between runs / subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab511d3-6cd6-46ad-9a99-cfced73ad5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_diff = [all_word_trigger_length[run] - audio_word_trigger_length[run] for run in range(9)]\n",
    "\n",
    "plt.plot(timing_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c424c7-4120-463b-b101-d2adf9e3de92",
   "metadata": {},
   "source": [
    "Trying to generate an explicit array, that contains matched words, unmatched, with the indidces from words and triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aab9ce-27c3-4a8f-be14-c9334bae90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '01'\n",
    "subject = '3'\n",
    "\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "task = 'listen'\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run_id,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "# triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "        lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "# Remove the empty words:\n",
    "\n",
    "meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "# Drop the rows containing NaN values in the text column\n",
    "meta = meta.dropna(subset=['word'])\n",
    "\n",
    "meta['start'] = meta.onset\n",
    "\n",
    "words = meta\n",
    "\n",
    "events_df = meta\n",
    "# Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "word_triggers = triggers[triggers[:, 2] > 1]\n",
    "\n",
    "\n",
    "# Matching triggers and metadata\n",
    "\n",
    "\n",
    "decimals = 2\n",
    "triggers_delta = np.round(np.diff(word_triggers[:, 0] / raw.info[\"sfreq\"]), decimals=decimals)  # type: ignore\n",
    "events_delta = np.round(np.diff(words.start.values), decimals=decimals)  # type: ignore\n",
    "i, j = match_list(triggers_delta, events_delta)\n",
    "\n",
    "print(f\"Found {len(i)/len(words)} of the words in the triggers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4249d0-b62f-4dc9-befd-18006eeaa4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a complete array to understand whats going on before / after match list\n",
    "\n",
    "current_i = -1\n",
    "current_j = -1\n",
    "\n",
    "list_events = []\n",
    "for i_, j_ in zip(i, j):  # Make sure that 'i' and 'j' iterables are defined before this line\n",
    "    for m_i in range(current_i + 1, i_):\n",
    "        list_events.append({\"data\": \"trigger\", \"trigger_ind\": m_i, \"trigger_time\": word_triggers[m_i][0]/ raw.info['sfreq']})\n",
    "        \n",
    "    for m_j in range(current_j + 1, j_):\n",
    "        list_events.append({\"data\": \"word\", \"word\": words.word.iloc[m_j], \"word_time\": words.onset.iloc[m_j], \"word_duration\": words.duration.iloc[m_j]})\n",
    "    list_events.append({\"data\": \"match\", \"trigger_ind\": i_, \"word_ind\":words.index[j_], \"word\": words.word.iloc[j_], \"trigger_time\": word_triggers[i_][0] / raw.info['sfreq'], \"word_time\": words.onset.iloc[j_], \"word_duration\": words.duration.iloc[j_]})\n",
    "    current_i = i_\n",
    "    current_j = j_\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a8d33-e1f3-4bb1-b0a0-46ce25e71122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.DataFrame(list_events)\n",
    "df_events = df_events.loc[:, sorted(df_events.columns)]\n",
    "df_events.to_csv('./df_events.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456fde1-44d5-4e95-97da-644406caed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 5 words for which we know it is the end of a sentence,and confirm their timings !\n",
    "\n",
    "targets = []\n",
    "\n",
    "audio_start = 4724  # Find the audio start in the wav file extracted, from the wave form\n",
    "\n",
    "timings = [1601, 1611, 1621, 1622, 1628, 1629, 1630]  # Gravement, (chez) moi: 605328,  ajouta, droit: 610390: pas aller bien \n",
    "# Le petit prince remarqua gravement: word_ind 1601\n",
    "\n",
    "for timing in timings:\n",
    "    target = df_events.loc[df_events.word_ind == timing].trigger_time.values[0]\n",
    "    targets.append(target*raw.info['sfreq'])\n",
    "\n",
    "diff_moi = (df_events.loc[df_events.word_ind == 1611].trigger_time.values[0] * 1000 )- 605328\n",
    "diff_droit =( df_events.loc[df_events.word_ind == 1622].trigger_time.values[0] * 1000) - 610390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb08e8-c524-43db-8b4a-371a2c378fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_moi, diff_droit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c123f-b799-464d-a7b2-4854008b127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = 612660\n",
    "audio_length - audio_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11382b98-4189-4676-b3da-48e67d79ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.trigger_time.iloc[-1] - df_events.trigger_time.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e86062-35fb-4f4d-9921-8c01670291db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cc793-014a-43a6-8195-cbb76fb9e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_events[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcccbb5-db3a-4ebb-954d-7899244e41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.to_csv('./df_events.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c79618-de6c-4631-8588-bb89a95ac31f",
   "metadata": {},
   "source": [
    "## Analyzing the MEG recorded wav file, to see if it aligns with the matched data timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e00e17-d509-4041-84c2-5392f6d9d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/co/Downloads/petitprince-sub6.npy'\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374efc2c-dbd8-4002-b9ca-d51cf417c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e419c0-4a47-44c6-a251-8935438e5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = df_events.trigger_time[:1].values[0] * 1000\n",
    "\n",
    "for target in targets:\n",
    "    epsilon = 200  # Go slightly before the event to make sure the audio starts after epsilon time\n",
    "    inf_ = target - first_word + audio_start\n",
    "    sup_ = 0\n",
    "    plt.figure()\n",
    "    plt.plot(data[int(inf_):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010583dd-5789-43d4-b264-d86339632a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76941aa-41f5-44d8-b161-fd89bf70b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a69756-3340-4528-8347-49f3ca102527",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data[inf_:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e58f0-ab6f-4e8b-bc45-f780bd06baef",
   "metadata": {},
   "source": [
    "# Subject analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edec1b-2922-4462-bea9-9713effd9a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the pre-computed array of results, no need to reload every raw file\n",
    "\n",
    "# Load the NumPy array from a file in binary format\n",
    "arr = np.load('results.npy', allow_pickle=True)\n",
    "\n",
    "# Convert the NumPy array to a list of dictionaries\n",
    "rst = arr.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e8293-5c4a-42e9-b67d-93be36f786be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing_diff(rst[:10], 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68b95a-a708-4eba-8484-99e4170d4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timing_diff(all_results[:10], 'audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78d29b6-de54-44f3-a694-990357fdb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub 1 seems to have no shift.. let's investigate\n",
    "\n",
    "sub1_data = all_results[0]\n",
    "\n",
    "sub1_run1_audio_length = sub1_data['all_triggers'][0][-1][0] - sub1_data['all_triggers'][0][0][0]\n",
    "\n",
    "sub1_run1_words_length = sub1_data['all_word_triggers'][0][-1] - sub1_data['all_word_triggers'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac93b788-426c-4225-bea4-e2b26ab4fc34",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "We could try to, for each subject, each run, find the linear shift and apply it to the metadata: we align the first trigger (start in STI001), and then apply the metadata starts * modified sfreq.\n",
    "\n",
    "To do so, we need to study first if for each subject, the shift throughout the run is always linear.\n",
    "\n",
    "Then, for one subject, through runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822fbfd-92bb-411c-9c06-9bba6f9c5a60",
   "metadata": {},
   "source": [
    "## Studying the shift through subject for run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88d3d4-04c3-49c1-9f18-6b73af1b05b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for subject in range(1, 58):\n",
    "    subject = str(subject)\n",
    "\n",
    "    # Create a new figure object and set it as the current figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the data for the current subject\n",
    "    diff, prec = get_trigger_diff_array(subject=subject)\n",
    "    plt.plot(diff)\n",
    "    plt.title(f\"{subject}_prec_{prec}\")\n",
    "    # Save the figure to a file\n",
    "    plt.savefig(f'./figures/{subject}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803475c-f183-4ba2-8221-b85a05c566b8",
   "metadata": {},
   "source": [
    "# Decoding attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef88abf-a62d-4abc-8fbc-7ae435069b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import populate_metadata_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f11aa-f3e9-49a7-943f-89961ef2f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '19'\n",
    "decoding_criterion = 'wlength'\n",
    "level = 'word'\n",
    "start = 'onset'\n",
    "modality = \"auditory\"\n",
    "\n",
    "epochs = populate_metadata_epochs(modality,\n",
    "    subject,\n",
    "    level,\n",
    "    start,\n",
    "    runs=1,\n",
    "    decoding_criterion=decoding_criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccdd77-e04a-4349-9608-323033894340",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "# decoding word emb\n",
    "print(\"loading data\")\n",
    "epochs = epochs.pick_types(meg=True, stim=False, misc=False).load_data()\n",
    "X = epochs.get_data()\n",
    "print(\"data loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8d052-c496-4d1b-adad-fa1a4364bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8c7a7-58bf-4e64-8030-e3837c17cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = epochs.metadata.wlength\n",
    "R_vec = decod_xy(X, y)\n",
    "scores = R_vec\n",
    "\n",
    "for t, score in enumerate(scores):\n",
    "    all_scores.append(\n",
    "        dict(\n",
    "            subject=subject,\n",
    "            score=score,\n",
    "            t=epochs.times[t],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d85fb2-abab-42c3-ae80-3db522ccd355",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951f20c-3af9-4c0c-84d4-b7ce91a339bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from Levenshtein import editops\n",
    "import string\n",
    "\n",
    "def decod_xy(X, y):\n",
    "    \"\"\"\n",
    "    Simple decoding function to evaluate how much\n",
    "    information can be infered from X to predict y.\n",
    "    Training a RidgeCV and then calculating the\n",
    "    Pearson R between predicted and test y\n",
    "    Args:\n",
    "        - X: np.Array\n",
    "        - y: np.Array\n",
    "    Returns:\n",
    "        - np.Array\n",
    "    \"\"\"\n",
    "    assert len(X) == len(y)\n",
    "    # define data\n",
    "    model = make_pipeline(StandardScaler(), RidgeCV(alphas=np.logspace(-3, 8, 10)))\n",
    "    cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "    # fit predict\n",
    "    n, n_chans, n_times = X.shape\n",
    "    if y.ndim == 1:\n",
    "        y = np.asarray(y).reshape(y.shape[0], 1)\n",
    "    R = np.zeros((n_times, y.shape[1]))\n",
    "\n",
    "    for t in range(n_times):\n",
    "        print(\".\", end=\"\")\n",
    "        rs = []\n",
    "        # y_pred = cross_val_predict(model, X[:, :, t], y, cv=cv)\n",
    "        for train, test in cv.split(X):\n",
    "            model.fit(X[train, :, t], y[train])\n",
    "            y_pred = model.predict(X[test, :, t])\n",
    "            r = correlate(y[test], y_pred)\n",
    "            rs.append(r)\n",
    "        R[t] = np.mean(rs)\n",
    "        # R[t] = correlate(y, y_pred)\n",
    "\n",
    "    return R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a379ca-3f6c-43d6-96a6-f10142aac954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import mne_bids\n",
    "import mne\n",
    "\n",
    "import pandas as pd\n",
    "from utils import match_list\n",
    "\n",
    "\n",
    "#path = '/home/co/data/LPP_MEG_auditory'\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "\n",
    "def get_trigger_diff_array(subject):\n",
    "    run_id = '01'\n",
    "    path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierListen2023/download\")\n",
    "\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Trying to remove the empty words:\n",
    "    \n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    words = meta\n",
    "\n",
    "    events_df = meta\n",
    "    # Triggers from the MEG: :, 2 is the trigger value: 1 is a word, 128 is the start / end\n",
    "    word_triggers = triggers[triggers[:, 2] > 1]\n",
    "\n",
    "\n",
    "    # Matching triggers and metadata\n",
    "\n",
    "\n",
    "    decimals = 2\n",
    "    triggers_delta = np.round(np.diff(word_triggers[:, 0] / raw.info[\"sfreq\"]), decimals=decimals)  # type: ignore\n",
    "    events_delta = np.round(np.diff(words.start.values), decimals=decimals)  # type: ignore\n",
    "    i, j = match_list(triggers_delta, events_delta)\n",
    "\n",
    "    print(f\"Found {len(i)/len(words)} of the words in the triggers\")\n",
    "\n",
    "    true_indices = words.iloc[j].index\n",
    "\n",
    "    # Find the missing words df\n",
    "    opposite_indices = events_df.index.difference(true_indices)\n",
    "    opposite_events_df = events_df.loc[opposite_indices]\n",
    "\n",
    "\n",
    "    events_df = events_df.loc[true_indices].copy()\n",
    "\n",
    "    events_df.loc[true_indices, \"start\"] = (\n",
    "        word_triggers[i, 0] / raw.info[\"sfreq\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Match on text the events_df df with the initial metadata, to have info how it shifts\n",
    "\n",
    "    metadata_words = meta\n",
    "    matched_words = events_df\n",
    "\n",
    "    # Match list between the two events arrays\n",
    "    idx2, idx = match_list((metadata_words.word.values), (matched_words.word.values))\n",
    "\n",
    "    # Return the diff arrays\n",
    "    diff_array = metadata_words.start.values[idx2] - matched_words.start.values[idx]\n",
    "    return diff_array, len(i)/len(words)\n",
    "\n",
    "def get_triggers(subject, run_id):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    return sfreq, triggers\n",
    "\n",
    "def get_audio_timestamps(subject, run_id):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    audio_data = raw.get_data(picks=[\"MISC004\"])[0,:]\n",
    "\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    return sfreq, audio_data\n",
    "\n",
    "def get_raw(subject, run_id):\n",
    "    task = 'listen'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    return raw\n",
    "\n",
    "\n",
    "import wave\n",
    "\n",
    "def get_wav_duration(filename):\n",
    "    with wave.open(filename, 'rb') as wav_file:\n",
    "        # Get the total number of frames in the WAV file\n",
    "        frames = wav_file.getnframes()\n",
    "        \n",
    "        # Get the frame rate (number of frames per second)\n",
    "        frame_rate = wav_file.getframerate()\n",
    "        \n",
    "        # Calculate the duration in seconds\n",
    "        duration = frames / float(frame_rate)\n",
    "        \n",
    "        return duration\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_timing_diff(all_results, target):\n",
    "    num_subjects = len(all_results)\n",
    "    num_runs = 9\n",
    "\n",
    "    # Create an empty list to store the timing differences for all subjects and runs\n",
    "    timing_diffs = [[] for _ in range(num_subjects)]\n",
    "\n",
    "    # Loop over all subjects and runs\n",
    "    for subject_idx, subject_results in enumerate(all_results):\n",
    "        for run in range(1, num_runs + 1):\n",
    "            \n",
    "            if target == 'word':\n",
    "                # Extract the word trigger length and audio word trigger length for the current run\n",
    "                word_trigger_length = subject_results['all_word_trigger_length'][run - 1]\n",
    "                audio_word_trigger_length_ = audio_word_trigger_length[run - 1]\n",
    "\n",
    "                # Calculate the timing difference\n",
    "                timing_diff_ = word_trigger_length - audio_word_trigger_length_\n",
    "\n",
    "            if target == 'audio':\n",
    "                audio_trigger_length_meg = subject_results['all_trigger_length'][run - 1]\n",
    "                audio_trigger_length_ = audio_trigger_length[run - 1]\n",
    "\n",
    "                # Calculate the timing difference\n",
    "                timing_diff_ = (audio_trigger_length_meg / 1000) - audio_trigger_length_\n",
    "                \n",
    "                \n",
    "            timing_diffs[subject_idx].append(timing_diff_)\n",
    "            \n",
    "            \n",
    "    # Loop over all subjects and plot the timing differences for each run\n",
    "    for subject_idx, timing_diff in enumerate(timing_diffs):\n",
    "        plt.plot(range(1, num_runs + 1), timing_diff, label=f'Subject {subject_idx + 1}')\n",
    "\n",
    "    # Add a legend and labels to the plot\n",
    "    plt.legend()\n",
    "    plt.xlabel('Run')\n",
    "    plt.ylabel(f'Timing difference for {target}(s)')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406256c9-a684-4d50-8881-c6a1a62b042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import logging\n",
    "import mne_bids\n",
    "# Set the logger level to WARNING to reduce verbosity\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for subject in range(1,20):\n",
    "    subject = str(subject)\n",
    "    all_triggers = []  # All the trigger timings\n",
    "    all_word_triggers = []  # All the word triggers\n",
    "    trigger_starts = []  # The time of between first trigger (beginning of audio) and first word\n",
    "    triggers_word_count = []  # The total number of word triggers for each run\n",
    "    all_word_trigger_length = []  # The total length from the first word trigger to the last one\n",
    "    all_trigger_length = []  # The total length from the first trigger to the last one (the whole audio file)\n",
    "\n",
    "    subject_results = {}  # Create an empty dictionary for the subject results\n",
    "    \n",
    "    for run in range(1,10):\n",
    "        run_id = '0'+ str(run)\n",
    "\n",
    "        # Triggers words\n",
    "        f, triggers = get_triggers(subject, run_id)\n",
    "        all_triggers.append(triggers)\n",
    "\n",
    "        word_triggers = triggers[triggers[:, 2] > 1][:,0]\n",
    "        all_word_triggers.append(word_triggers)\n",
    "\n",
    "        first_diff = (triggers[1][0] - triggers[0][0]) / f\n",
    "        trigger_starts.append(first_diff)\n",
    "\n",
    "        triggers_word_count.append(word_triggers.shape[0])\n",
    "\n",
    "        word_trigger_length = (word_triggers[-1] - word_triggers[0]) / f\n",
    "        all_word_trigger_length.append(word_trigger_length)\n",
    "\n",
    "        total_length = triggers[-1][0] - triggers[0][0]\n",
    "        all_trigger_length.append(total_length)\n",
    "\n",
    "    # Add the results to the subject dictionary\n",
    "    subject_results['all_triggers'] = all_triggers\n",
    "    subject_results['all_word_triggers'] = all_word_triggers\n",
    "    subject_results['trigger_starts'] = trigger_starts\n",
    "    subject_results['triggers_word_count'] = triggers_word_count\n",
    "    subject_results['all_word_trigger_length'] = all_word_trigger_length\n",
    "    subject_results['all_trigger_length'] = all_trigger_length\n",
    "\n",
    "    all_results.append(subject_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68e28b-d473-4099-aad6-07774a5eea76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
