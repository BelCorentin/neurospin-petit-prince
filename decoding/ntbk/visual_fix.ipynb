{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import logging\n",
    "import mne_bids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the logger level to WARNING to reduce verbosity\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "#path = Path(\"/home/co/data/neuralset/LPP_copy/pallierlisten2023/download\")\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download\")\n",
    "\n",
    "def testing(subject, run_id):\n",
    "    task = 'read'\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=task,\n",
    "        datatype=\"meg\",\n",
    "        root=path,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    # triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "    triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "    # Generate event_file path\n",
    "    event_file = path / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "    meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "            lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "    # Remove the empty words:\n",
    "\n",
    "    meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "    # Drop the rows containing NaN values in the text column\n",
    "    meta = meta.dropna(subset=['word'])\n",
    "\n",
    "    meta['start'] = meta.onset\n",
    "\n",
    "    # return meta\n",
    "    # Get the length of the meta file\n",
    "    total_time_meta = np.array(meta.onset)[-1] - np.array(meta.onset)[0]\n",
    "\n",
    "    # Length of triggers\n",
    "    total_time_triggers = triggers[-1][0] - triggers[0][0]\n",
    "\n",
    "    return total_time_meta, total_time_triggers, (len(triggers) / len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.35699999999997, 1.0013651877133105)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \"2\"\n",
    "run = '01'\n",
    "\n",
    "# meta = testing(subject, run)\n",
    "total_time_meta, total_time_triggers, perc = testing(subject, run)\n",
    "shift = total_time_meta - (total_time_triggers / 1000)\n",
    "shift, perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509.7, 459343)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time_meta, total_time_triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"40\"\n",
    "run = '01'\n",
    "\n",
    "task = 'read'\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "# triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "# Generate event_file path\n",
    "event_file = path / f\"sub-{bids_path.subject}\"\n",
    "event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "event_file = event_file / \"meg\"\n",
    "event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "event_file += f\"_ses-{bids_path.session}\"\n",
    "event_file += f\"_task-{bids_path.task}\"\n",
    "event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "assert Path(event_file).exists()\n",
    "\n",
    "meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "\n",
    "meta[\"word\"] = meta[\"trial_type\"].apply(\n",
    "        lambda x: eval(x)[\"word\"] if type(eval(x)) == dict else np.nan)\n",
    "\n",
    "# Remove the empty words:\n",
    "\n",
    "meta.loc[meta['word'] == ' ', 'word'] = None\n",
    "\n",
    "# Drop the rows containing NaN values in the text column\n",
    "meta = meta.dropna(subset=['word'])\n",
    "\n",
    "meta['start'] = meta.onset\n",
    "\n",
    "# return meta\n",
    "# Get the length of the meta file\n",
    "total_time_meta = np.array(meta.onset)[-1] - np.array(meta.onset)[0]\n",
    "\n",
    "# Length of triggers\n",
    "total_time_triggers = triggers[-1][0] - triggers[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diff(triggers[:,0]))\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw data\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(raw.copy().pick_channels(['STI101']).get_data()[0] )\n",
    "# Plot meta wlenght\n",
    "meta['wlength'] = meta['word'].apply(len)\n",
    "# plt.plot(meta.wlength, 'r')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-30/ses-01/meg/sub-30_ses-01_task-read_run-01_meg.fif...\n",
      "    Read a total of 13 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v6 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v7 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v8 (1 x 306)  idle\n",
      "    Range : 23000 ... 494999 =     23.000 ...   494.999 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-acce587e3e7c>:23: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading events from /media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-30/ses-01/meg/sub-30_ses-01_task-read_run-01_events.tsv.\n",
      "Reading channel info from /media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-30/ses-01/meg/sub-30_ses-01_task-read_run-01_channels.tsv.\n",
      "Using 4 HPI coils: 293 307 314 321 Hz\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-acce587e3e7c>:23: RuntimeWarning: Omitted 110 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "<ipython-input-3-acce587e3e7c>:23: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "<ipython-input-3-acce587e3e7c>:23: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1466 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "from utils import match_list\n",
    "\n",
    "import mne_bids\n",
    "import mne\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "path = Path(\"/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download\")\n",
    "\n",
    "\n",
    "subject = \"30\"\n",
    "run = '01'\n",
    "\n",
    "task = 'read'\n",
    "bids_path = mne_bids.BIDSPath(\n",
    "    subject=subject,\n",
    "    session=\"01\",\n",
    "    task=task,\n",
    "    datatype=\"meg\",\n",
    "    root=path,\n",
    "    run=run,\n",
    ")\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "\n",
    "all_triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "# Triggers are simpler for this modality: no need to get the step function / offsets\n",
    "word_triggers = all_triggers\n",
    "if word_triggers[:, 2].max() > 2048:\n",
    "    word_triggers[:, 2] = (\n",
    "        word_triggers[:, 2] - 2048\n",
    "    ) \n",
    "\n",
    "\n",
    "eventsile = '/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-1/ses-01/meg/sub-1_ses-01_task-read_run-01_events.tsv'\n",
    "words = pd.read_csv(eventsile, sep=\"\\t\")\n",
    "# file = \"/home/co/code/LPP_experiment/formatting/v2/run1_v2_0.25_0.5.tsv\"\n",
    "# words = pd.read_csv(file, sep=\"\\t\")\n",
    "# words['wlength'] = words['word'].apply(len)\n",
    "# i, j = match_list(word_triggers[:, 2], words.wlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1466 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 30167,      0,      1],\n",
       "       [ 30787,      1,      7],\n",
       "       [ 31113,      0,      7],\n",
       "       ...,\n",
       "       [489006,      0,      5],\n",
       "       [489273,      0,      4],\n",
       "       [489548,      0,     11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.find_events(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Annotations | 1355 segments: {'kind': 'word', 'word': '1'} (3), {'kind': ...>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7147124719940254"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7, 14, 12,  9,  9, 12,  8, 13, 11,  7,  8, 13,  6, 11,  8, 11,\n",
       "        8, 10,  6, 13, 12, 14,  6, 11,  9, 11,  7, 14, 13, 10, 12, 13, 10,\n",
       "       10,  6, 12,  9, 11,  7, 13,  8,  8,  8, 11,  6, 11, 15, 11,  8, 10,\n",
       "        6,  8,  9, 11])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_triggers[~np.isin(np.arange(word_triggers.shape[0]), i)][:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Neuralset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 0.8837047353760445\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "for annot in raw.annotations:\n",
    "    description = annot.pop(\"description\")\n",
    "    if \"BAD_ACQ_SKIP\" in description:\n",
    "        continue\n",
    "    event = eval(description)\n",
    "    event[\"condition\"] = \"sentence\"\n",
    "    event[\"type\"] = event.pop(\"kind\").capitalize()\n",
    "    event[\"start\"] = annot[\"onset\"]\n",
    "    event[\"duration\"] = annot[\"duration\"]\n",
    "    event[\"stop\"] = annot[\"onset\"] + annot[\"duration\"]\n",
    "    event[\"language\"] = \"french\"\n",
    "    events.append(event)\n",
    "\n",
    "events_df = pd.DataFrame(events).rename(columns=dict(word=\"text\"))\n",
    "\n",
    "# Remove empty words that were included in the metadata files...\n",
    "events_df.loc[events_df[\"text\"] == \" \", \"text\"] = None\n",
    "# Drop the rows containing NaN values in the text column\n",
    "events_df = events_df.dropna(subset=[\"text\"])\n",
    "events_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Match the events with the metadata\n",
    "metadata = pd.read_csv('/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sourcedata/task-read_run-01_extra_info.tsv')\n",
    "\n",
    "# TODO: this hack doesnt work as in read, the j and avais have been merged\n",
    "# It is thus needed to think about how to find again this information\n",
    "# Small data augmentation because some columns dont exist in the read metadata\n",
    "# metadata_listen = pd.read_csv(self.path / \"sourcedata/task-listen_run-{self.run}_extra_info.tsv\")\n",
    "# # Add to metadata the missing columns from the listen metadata: n_closing, is_last_word, pos, content_word\n",
    "# metadata = metadata.merge(metadata_listen[[\"word\", \"n_closing\", \"is_last_word\", \"pos\", \"content_word\"]], on=\"word\")\n",
    "\n",
    "rows_events, rows_metadata = match_list(\n",
    "    [str(word) for word in events_df[\"text\"].values],\n",
    "    [str(word) for word in metadata[\"word\"].values],\n",
    ")\n",
    "\n",
    "\n",
    "events_idx, metadata_idx = (\n",
    "    events_df.index[rows_events],\n",
    "    metadata.index[rows_metadata],events_df\n",
    ")\n",
    "\n",
    "# Adding the information about sequence_id and n_closing\n",
    "events_df[\"word\"] = events_df[\"text\"]\n",
    "# for col in [\"sequence_id\", \"n_closing\", \"is_last_word\", \"pos\"]:\n",
    "for col in [\"sequence_id\"]:\n",
    "    events_df.loc[events_idx, col] = metadata.loc[metadata_idx, col]\n",
    "\n",
    "# get the correct words (pb with apostrophes)\n",
    "eventsile = '/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-1/ses-01/meg/sub-1_ses-01_task-read_run-01_events.tsv'\n",
    "\n",
    "correct_words_df = pd.read_csv(eventsile, delimiter=\"\\t\")\n",
    "correct_words_df.trial_type = correct_words_df.trial_type.apply(\n",
    "    lambda x: eval(x)[\"word\"]\n",
    ")\n",
    "rows_events, rows_metadata = match_list(\n",
    "    events_df[\"text\"].values.astype(str),\n",
    "    correct_words_df[\"trial_type\"].values.astype(str),\n",
    ")\n",
    "\n",
    "events_idx, metadata_idx = (\n",
    "    events_df.index[rows_events],\n",
    "    correct_words_df.index[rows_metadata],\n",
    ")\n",
    "events_df.loc[events_idx, \"text\"] = correct_words_df.loc[metadata_idx, \"word\"]\n",
    "\n",
    "\n",
    "all_triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "# Triggers are simpler for this modality: no need to get the step function / offsets\n",
    "word_triggers = all_triggers[all_triggers[:, 2] > 1]\n",
    "\n",
    "words = events_df.loc[events_df.type == \"Word\"]\n",
    "words[\"wlength\"] = words.text.apply(len)\n",
    "if word_triggers[:, 2].max() > 2048:\n",
    "    word_triggers[:, 2] = (\n",
    "        word_triggers[:, 2] - 2048\n",
    "    )  # HACK because of a bug in the word_triggers for 2 subjects that have particularly high word_triggers\n",
    "i, j = match_list(word_triggers[:, 2], words.wlength)\n",
    "print(f\"Matched: {len(i) / len(word_triggers)}\")\n",
    "\n",
    "true_indices = words.iloc[j].index\n",
    "\n",
    "events_df.loc[true_indices, \"start\"] = word_triggers[i, 0] / raw.info[\"sfreq\"]\n",
    "\n",
    "\n",
    "# sort by start\n",
    "events_df = events_df.sort_values(by=\"start\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "for annot in raw.annotations:\n",
    "    description = annot.pop(\"description\")\n",
    "    if \"BAD_ACQ_SKIP\" in description:\n",
    "        continue\n",
    "    event = eval(description)\n",
    "    event[\"condition\"] = \"sentence\"\n",
    "    event[\"type\"] = event.pop(\"kind\").capitalize()\n",
    "    event[\"start\"] = annot[\"onset\"]\n",
    "    event[\"duration\"] = annot[\"duration\"]\n",
    "    event[\"stop\"] = annot[\"onset\"] + annot[\"duration\"]\n",
    "    event[\"language\"] = \"french\"\n",
    "    events.append(event)\n",
    "\n",
    "events_df = pd.DataFrame(events).rename(columns=dict(word=\"text\"))\n",
    "\n",
    "# Remove empty words that were included in the metadata files...\n",
    "events_df.loc[events_df[\"text\"] == \" \", \"text\"] = None\n",
    "# Drop the rows containing NaN values in the text column\n",
    "events_df = events_df.dropna(subset=[\"text\"])\n",
    "events_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Match the events with the metadata\n",
    "metadata = pd.read_csv('/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sourcedata/task-read_run-01_extra_info.tsv')\n",
    "\n",
    "# TODO: this hack doesnt work as in read, the j and avais have been merged\n",
    "# It is thus needed to think about how to find again this information\n",
    "# Small data augmentation because some columns dont exist in the read metadata\n",
    "# metadata_listen = pd.read_csv(self.path / \"sourcedata/task-listen_run-{self.run}_extra_info.tsv\")\n",
    "# # Add to metadata the missing columns from the listen metadata: n_closing, is_last_word, pos, content_word\n",
    "# metadata = metadata.merge(metadata_listen[[\"word\", \"n_closing\", \"is_last_word\", \"pos\", \"content_word\"]], on=\"word\")\n",
    "\n",
    "rows_events, rows_metadata = match_list(\n",
    "    [str(word) for word in events_df[\"text\"].values],\n",
    "    [str(word) for word in metadata[\"word\"].values],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "events_idx, metadata_idx = (\n",
    "    events_df.index[rows_events],\n",
    "    metadata.index[rows_metadata],\n",
    ")\n",
    "\n",
    "# Adding the information about sequence_id and n_closing\n",
    "events_df[\"word\"] = events_df[\"text\"]\n",
    "# for col in [\"sequence_id\", \"n_closing\", \"is_last_word\", \"pos\"]:\n",
    "for col in [\"sequence_id\"]:\n",
    "    events_df.loc[events_idx, col] = metadata.loc[metadata_idx, col]\n",
    "\n",
    "# get the correct words (pb with apostrophes)\n",
    "eventsile = '/media/co/T7/workspace-LPP/data/MEG/LPP/PallierRead2023/download/sub-1/ses-01/meg/sub-1_ses-01_task-read_run-01_events.tsv'\n",
    "\n",
    "correct_words_df = pd.read_csv(eventsile, delimiter=\"\\t\")\n",
    "correct_words_df.trial_type = correct_words_df.trial_type.apply(\n",
    "    lambda x: eval(x)[\"word\"]\n",
    ")\n",
    "rows_events, rows_metadata = match_list(\n",
    "    events_df[\"text\"].values.astype(str),\n",
    "    correct_words_df[\"trial_type\"].values.astype(str),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.loc[events_idx, \"clean_text\"] = correct_words_df.loc[metadata_idx, \"trial_type\"].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>condition</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>stop</th>\n",
       "      <th>language</th>\n",
       "      <th>word</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lorsque</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>23.95</td>\n",
       "      <td>french</td>\n",
       "      <td>Lorsque</td>\n",
       "      <td>0</td>\n",
       "      <td>Lorsque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j'avais</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.25</td>\n",
       "      <td>french</td>\n",
       "      <td>javais</td>\n",
       "      <td>0</td>\n",
       "      <td>javais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>six</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.55</td>\n",
       "      <td>french</td>\n",
       "      <td>six</td>\n",
       "      <td>0</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ans,</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.85</td>\n",
       "      <td>french</td>\n",
       "      <td>ans</td>\n",
       "      <td>0</td>\n",
       "      <td>ans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j'ai</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.15</td>\n",
       "      <td>french</td>\n",
       "      <td>jai</td>\n",
       "      <td>0</td>\n",
       "      <td>jai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>avec</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>493.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>493.95</td>\n",
       "      <td>french</td>\n",
       "      <td>avec</td>\n",
       "      <td>114</td>\n",
       "      <td>avec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>la</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.25</td>\n",
       "      <td>french</td>\n",
       "      <td>la</td>\n",
       "      <td>114</td>\n",
       "      <td>la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>caisse</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.55</td>\n",
       "      <td>french</td>\n",
       "      <td>caisse</td>\n",
       "      <td>114</td>\n",
       "      <td>caisse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>que</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.85</td>\n",
       "      <td>french</td>\n",
       "      <td>que</td>\n",
       "      <td>114</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>tu</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>495.00</td>\n",
       "      <td>french</td>\n",
       "      <td>tu</td>\n",
       "      <td>114</td>\n",
       "      <td>tu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text condition  type  start  duration    stop language     word  \\\n",
       "0     Lorsque  sentence  Word   23.7      0.25   23.95   french  Lorsque   \n",
       "1     j'avais  sentence  Word   24.0      0.25   24.25   french   javais   \n",
       "2         six  sentence  Word   24.3      0.25   24.55   french      six   \n",
       "3        ans,  sentence  Word   24.6      0.25   24.85   french      ans   \n",
       "4        j'ai  sentence  Word   24.9      0.25   25.15   french      jai   \n",
       "...       ...       ...   ...    ...       ...     ...      ...      ...   \n",
       "1350     avec  sentence  Word  493.7      0.25  493.95   french     avec   \n",
       "1351       la  sentence  Word  494.0      0.25  494.25   french       la   \n",
       "1352   caisse  sentence  Word  494.3      0.25  494.55   french   caisse   \n",
       "1353      que  sentence  Word  494.6      0.25  494.85   french      que   \n",
       "1354       tu  sentence  Word  494.9      0.10  495.00   french       tu   \n",
       "\n",
       "      sequence_id clean_text  \n",
       "0               0    Lorsque  \n",
       "1               0     javais  \n",
       "2               0        six  \n",
       "3               0        ans  \n",
       "4               0        jai  \n",
       "...           ...        ...  \n",
       "1350          114       avec  \n",
       "1351          114         la  \n",
       "1352          114     caisse  \n",
       "1353          114        que  \n",
       "1354          114         tu  \n",
       "\n",
       "[1355 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('onset', 24.0),\n",
       "             ('duration', 0.25),\n",
       "             ('description', \"{'kind': 'word', 'word': 'javais'}\"),\n",
       "             ('orig_time',\n",
       "              datetime.datetime(2023, 5, 2, 14, 52, 47, 347192, tzinfo=datetime.timezone.utc))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_words_match = correct_words_df[\"trial_type\"].values.astype(str)\n",
    "rows_events, rows_metadata = match_list(\n",
    "    events_df[\"text\"].values.astype(str),\n",
    "    correct_words_match,\n",
    ")\n",
    "\n",
    "events_idx, metadata_idx = (\n",
    "    events_df.index[rows_events],\n",
    "    correct_words_df.index[rows_metadata],\n",
    ")\n",
    "events_df.loc[events_idx, \"text\"] = correct_words_df.loc[metadata_idx, \"word\"]\n",
    "events_df.loc[events_idx, \"clean_text\"] = correct_words_df.loc[metadata_idx, \"trial_type\"].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for annot in raw.annotations:\n",
    "    word = annot[\"description\"]\n",
    "    words.append(eval(word)['word'])\n",
    "    # Match it with the metadata\n",
    "\n",
    "word_meta = correct_words_df.trial_type\n",
    "i,j = match_list(words, word_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355       mas\n",
       "1356    donnée\n",
       "1357      cest\n",
       "1358       que\n",
       "1359        la\n",
       "         ...  \n",
       "1460      peut\n",
       "1461       pas\n",
       "1462     aller\n",
       "1463      bien\n",
       "1464      loin\n",
       "Name: trial_type, Length: 110, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the words in word_meta not matched\n",
    "import numpy as np\n",
    "word_meta[~np.isin(np.arange(len(word_meta)), j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>condition</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>stop</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lorsque</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>23.95</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>javais</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.25</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>six</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.55</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ans</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>24.85</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jai</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.15</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>avec</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>493.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>493.95</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>la</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.25</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>caisse</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.55</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>que</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>494.85</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>tu</td>\n",
       "      <td>sentence</td>\n",
       "      <td>Word</td>\n",
       "      <td>494.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>495.00</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1355 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         text condition  type  start  duration    stop language\n",
       "0     Lorsque  sentence  Word   23.7      0.25   23.95   french\n",
       "1      javais  sentence  Word   24.0      0.25   24.25   french\n",
       "2         six  sentence  Word   24.3      0.25   24.55   french\n",
       "3         ans  sentence  Word   24.6      0.25   24.85   french\n",
       "4         jai  sentence  Word   24.9      0.25   25.15   french\n",
       "...       ...       ...   ...    ...       ...     ...      ...\n",
       "1350     avec  sentence  Word  493.7      0.25  493.95   french\n",
       "1351       la  sentence  Word  494.0      0.25  494.25   french\n",
       "1352   caisse  sentence  Word  494.3      0.25  494.55   french\n",
       "1353      que  sentence  Word  494.6      0.25  494.85   french\n",
       "1354       tu  sentence  Word  494.9      0.10  495.00   french\n",
       "\n",
       "[1355 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_events.shape[0] / events_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>wlength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"les</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>digestion.\"</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>\"pourquoi</td>\n",
       "      <td>41.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>peur?\"</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>\"c'est</td>\n",
       "      <td>129.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>chapeau.\"</td>\n",
       "      <td>129.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>\"s'il</td>\n",
       "      <td>188.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>mouton...\"</td>\n",
       "      <td>193.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>\"mais...</td>\n",
       "      <td>252.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>là?\"</td>\n",
       "      <td>254.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>\"s'il</td>\n",
       "      <td>258.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>mouton...\"</td>\n",
       "      <td>260.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>\"ça</td>\n",
       "      <td>286.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>mouton.\"</td>\n",
       "      <td>288.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>\"non!</td>\n",
       "      <td>300.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>mouton.\"</td>\n",
       "      <td>313.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>\"non!</td>\n",
       "      <td>316.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>autre.\"</td>\n",
       "      <td>319.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>\"tu</td>\n",
       "      <td>323.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>cornes...\"</td>\n",
       "      <td>328.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>\"celui-là</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>longtemps.\"</td>\n",
       "      <td>336.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>\"ça</td>\n",
       "      <td>343.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>dedans.\"</td>\n",
       "      <td>347.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>\"c'est</td>\n",
       "      <td>352.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>mouton.\"</td>\n",
       "      <td>365.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>\"pas</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>endormi...\"</td>\n",
       "      <td>371.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>\"qu'est-ce</td>\n",
       "      <td>399.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>avion.\"</td>\n",
       "      <td>406.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>\"comment!</td>\n",
       "      <td>411.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>drôle!...\"</td>\n",
       "      <td>416.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>\"alors,</td>\n",
       "      <td>426.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>es-tu?\"</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>\"tu</td>\n",
       "      <td>434.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>planète?\"</td>\n",
       "      <td>436.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>\"c'est</td>\n",
       "      <td>442.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>loin...\"</td>\n",
       "      <td>445.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>\"les</td>\n",
       "      <td>458.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>planètes\".</td>\n",
       "      <td>458.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>\"d'où</td>\n",
       "      <td>461.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>\"chez</td>\n",
       "      <td>464.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>toi\"?</td>\n",
       "      <td>464.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>mouton?\"</td>\n",
       "      <td>466.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>\"ce</td>\n",
       "      <td>469.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>piquet.\"</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>\"l'attacher?</td>\n",
       "      <td>485.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>perdra.\"</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>\"mais</td>\n",
       "      <td>495.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>lui...\"</td>\n",
       "      <td>499.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  onset  duration  wlength\n",
       "41            \"les   14.5      0.25        4\n",
       "67     digestion.\"   22.8      0.25       11\n",
       "123      \"pourquoi   41.6      0.25        9\n",
       "127         peur?\"   42.8      0.25        6\n",
       "383         \"c'est  129.1      0.25        6\n",
       "385      chapeau.\"  129.7      0.25        9\n",
       "554          \"s'il  188.9      0.25        5\n",
       "563     mouton...\"  193.1      0.25       10\n",
       "738       \"mais...  252.1      0.25        8\n",
       "743           là?\"  254.1      0.25        4\n",
       "756          \"s'il  258.5      0.25        5\n",
       "761     mouton...\"  260.5      0.25       10\n",
       "841            \"ça  286.5      0.25        3\n",
       "847       mouton.\"  288.8      0.25        8\n",
       "881          \"non!  300.5      0.25        5\n",
       "914       mouton.\"  313.4      0.25        8\n",
       "922          \"non!  316.8      0.25        5\n",
       "929        autre.\"  319.9      0.25        7\n",
       "938            \"tu  323.1      0.25        3\n",
       "952     cornes...\"  328.3      0.25       10\n",
       "966      \"celui-là  333.0      0.25        9\n",
       "976    longtemps.\"  336.5      0.25       11\n",
       "998            \"ça  343.6      0.25        3\n",
       "1008      dedans.\"  347.1      0.25        8\n",
       "1023        \"c'est  352.1      0.25        6\n",
       "1058      mouton.\"  365.1      0.25        8\n",
       "1066          \"pas  368.0      0.25        4\n",
       "1074   endormi...\"  371.4      0.25       11\n",
       "1151    \"qu'est-ce  399.0      0.25       10\n",
       "1169       avion.\"  406.4      0.25        7\n",
       "1182     \"comment!  411.3      0.25        9\n",
       "1194    drôle!...\"  416.9      0.25       10\n",
       "1221       \"alors,  426.5      0.25        7\n",
       "1231       es-tu?\"  430.0      0.25        7\n",
       "1245           \"tu  434.7      0.25        3\n",
       "1250     planète?\"  436.2      0.25        9\n",
       "1267        \"c'est  442.3      0.25        6\n",
       "1278      loin...\"  445.6      0.25        8\n",
       "1315          \"les  458.2      0.25        4\n",
       "1317    planètes\".  458.8      0.25       10\n",
       "1325         \"d'où  461.7      0.25        5\n",
       "1332         \"chez  464.3      0.25        5\n",
       "1333         toi\"?  464.6      0.25        5\n",
       "1338      mouton?\"  466.6      0.25        8\n",
       "1346           \"ce  469.5      0.25        3\n",
       "1386      piquet.\"  483.0      0.25        8\n",
       "1394  \"l'attacher?  485.9      0.25       12\n",
       "1411      perdra.\"  492.0      0.25        8\n",
       "1421         \"mais  495.5      0.25        5\n",
       "1430       lui...\"  499.2      0.25        7"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the words of not matched words\n",
    "words.loc[~words.index.isin(j)][:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
