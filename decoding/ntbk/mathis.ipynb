{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sample for the Pallier2023Listen code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jra_utils import approx_match_samples\n",
    "from jr_utils import match_list\n",
    "\n",
    "\n",
    "CHAPTER_PATHS = [\n",
    "    \"ch1-3.wav\",\n",
    "    \"ch4-6.wav\",\n",
    "    \"ch7-9.wav\",\n",
    "    \"ch10-12.wav\",\n",
    "    \"ch13-14.wav\",\n",
    "    \"ch15-19.wav\",\n",
    "    \"ch20-22.wav\",\n",
    "    \"ch23-25.wav\",\n",
    "    \"ch26-27.wav\",\n",
    "]\n",
    "\n",
    "# Handle the particular runs for which we need a higher tolerance\n",
    "# To handle the default case, we'll use this in the later code\n",
    "# abs_tol, max_missing = TOL_MISSING_DICT.get((subject, run), (10, 5))\n",
    "TOL_MISSING_DICT = {\n",
    "    (9, 6): (30, 5),\n",
    "    (10, 6): (30, 5),\n",
    "    (12, 5): (30, 5),\n",
    "    (13, 3): (30, 5),\n",
    "    (13, 7): (30, 5),\n",
    "    (14, 9): (30, 5),\n",
    "    (21, 6): (30, 5),\n",
    "    (21, 8): (30, 5),\n",
    "    (22, 4): (30, 5),\n",
    "    (33, 2): (30, 5),\n",
    "    (39, 5): (30, 5),\n",
    "    (40, 2): (30, 5),\n",
    "    (41, 1): (30, 5),\n",
    "    (43, 4): (30, 5),\n",
    "    (43, 5): (30, 5),\n",
    "    (44, 9): (30, 5),\n",
    "    (24, 2): (10, 20),\n",
    "}\n",
    "\n",
    "\n",
    "def _get_seq_id_path(self):\n",
    "    return self.path / f\"sourcedata/task-{self.task}_run-{self.run}_extra_info.tsv\"\n",
    "\n",
    "def _get_syntax_path(self):\n",
    "    return (\n",
    "        self.path\n",
    "        / f\"sourcedata/stimuli/run{self.run}_v2_0.25_0.5-tokenized.syntax.txt\"\n",
    "    )\n",
    "\n",
    "def _get_word_info_path(self):\n",
    "    return str(self._get_bids_path()).replace(\"meg.fif\", \"events.tsv\")\n",
    "\n",
    "def _load_events(self) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Redefine this method in the subclasses\n",
    "    for both listen and read\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "# # # # # actual studies # # # # #\n",
    "\n",
    "\n",
    "class PallierListen2023(_Pallier2023Base):\n",
    "\n",
    "    task: tp.ClassVar[str] = \"listen\"\n",
    "\n",
    "    def _load_events(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        in this particular data, I'm transforming our original rich dataframe\n",
    "        into mne use a Annotation class in order to save the whole thing into\n",
    "        a *.fif file, At reading time, I'm converting it back to a DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        error_msg_prefix = (\n",
    "            f\"subject {self.subject}, session {self.session}, run {self.run}\\n\"\n",
    "        )\n",
    "\n",
    "        raw = self._load_raw(self.timeline)\n",
    "        # Get the start and stop triggers from STI101\n",
    "        sound_triggers = mne.find_events(raw, stim_channel=\"STI101\", shortest_event=1)\n",
    "\n",
    "        # extract annotations\n",
    "        events = []\n",
    "        for annot in raw.annotations:\n",
    "            description = annot.pop(\"description\")\n",
    "            if \"BAD_ACQ_SKIP\" in description:\n",
    "                continue\n",
    "            event = eval(description)\n",
    "            event[\"condition\"] = \"sentence\"\n",
    "            event[\"type\"] = event.pop(\"kind\").capitalize()\n",
    "            event[\"start\"] = annot[\"onset\"]\n",
    "            event[\"duration\"] = annot[\"duration\"]\n",
    "            event[\"stop\"] = annot[\"onset\"] + annot[\"duration\"]\n",
    "            event[\"language\"] = \"french\"\n",
    "            events.append(event)\n",
    "\n",
    "        # extract sound annotation\n",
    "        try:\n",
    "            sound_triggers = sound_triggers[sound_triggers[:, 2] == 1]  # get the triggers\n",
    "            start, stop = sound_triggers[:, 0] / raw.info[\"sfreq\"]\n",
    "            events.append(\n",
    "                dict(\n",
    "                    type=\"Sound\",\n",
    "                    start=start,\n",
    "                    duration=stop - start,\n",
    "                    filepath=Path(self.path)\n",
    "                    / \"sourcedata/stimuli/audio\"\n",
    "                    / CHAPTER_PATHS[int(self.run) - 1],\n",
    "                )\n",
    "            )\n",
    "        except Exception as e:\n",
    "            warnings.warn(\n",
    "                f\"No sound triggers found for subject {self.subject}, run {self.run}: {e}\"\n",
    "            )\n",
    "\n",
    "        events_df = pd.DataFrame(events).rename(columns=dict(word=\"text\"))\n",
    "\n",
    "        # Remove empty words that were included in the metadata files...\n",
    "        events_df.loc[events_df[\"text\"] == \" \", \"text\"] = None\n",
    "\n",
    "        # Drop the rows containing NaN values in the text column\n",
    "        events_df = events_df.dropna(subset=[\"text\"])\n",
    "        events_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        metadata = pd.read_csv(self._get_seq_id_path())\n",
    "        rows_events, rows_metadata = match_list(\n",
    "            [str(word) for word in events_df[\"text\"].values],\n",
    "            [str(word) for word in metadata[\"word\"].values],\n",
    "        )\n",
    "\n",
    "        assert len(rows_events) / len(events_df) > 0.95, (\n",
    "            error_msg_prefix\n",
    "            + f\"only {len(rows_events) / len(events_df)} of the words were found in the metadata\"\n",
    "        )\n",
    "        events_idx, metadata_idx = (\n",
    "            events_df.index[rows_events],\n",
    "            metadata.index[rows_metadata],\n",
    "        )\n",
    "\n",
    "        # Adding the information about sequence_id and n_closing\n",
    "        events_df[\"word\"] = events_df[\"text\"]\n",
    "        for col in [\"sequence_id\", \"n_closing\", \"is_last_word\", \"pos\"]:\n",
    "            events_df.loc[events_idx, col] = metadata.loc[metadata_idx, col]\n",
    "\n",
    "        # add train/test/val splits\n",
    "        events_df = set_sentence_split(events_df)  # TODO\n",
    "\n",
    "        # Handling the alignment issue with audio shift in the MEG recordings\n",
    "        starts = mne.find_events(raw, output=\"step\", shortest_event=1)[:, 0]\n",
    "        meg_times = np.copy(raw.times)\n",
    "        meg_triggers = np.zeros_like(meg_times)\n",
    "        meg_triggers[starts - raw.first_samp] = 1\n",
    "\n",
    "        words = events_df.loc[events_df.type == \"Word\"]\n",
    "\n",
    "        # Get the word triggers from STI008, as a step so we can get the offset\n",
    "        word_triggers = mne.find_stim_steps(raw, stim_channel=\"STI008\")\n",
    "        # Offsets of the step function: allows us to match\n",
    "        word_triggers = word_triggers[word_triggers[:, 2] == 0]\n",
    "\n",
    "        # New match\n",
    "        abs_tol, max_missing = TOL_MISSING_DICT.get(\n",
    "            (int(self.subject), int(self.run)), (10, 5)\n",
    "        )\n",
    "        i, j = approx_match_samples(\n",
    "            (words.start * 1000).tolist(),\n",
    "            word_triggers[:, 0],\n",
    "            abs_tol=abs_tol,\n",
    "            max_missing=max_missing,\n",
    "        )\n",
    "        print(f\"Found {len(i)/len(words)} of the words in the triggers\")\n",
    "\n",
    "        words = words.iloc[i, :]\n",
    "\n",
    "        events_df.loc[:, \"unaligned_start\"] = events_df.loc[:, \"start\"]\n",
    "        events_df.loc[words.index, \"start\"] = word_triggers[j, 0] / raw.info[\"sfreq\"]\n",
    "\n",
    "        # Add sentence / constituent info\n",
    "        events_df = enrich_metadata(events_df)\n",
    "\n",
    "        # add raw event\n",
    "        uri = f\"method:_load_raw?timeline={self.timeline}\"\n",
    "        meg = {\"filepath\": uri, \"type\": \"Meg\", \"start\": 0}\n",
    "        events_df = pd.concat([pd.DataFrame([meg]), events_df])\n",
    "\n",
    "        # sort by start\n",
    "        events_df = events_df.sort_values(by=\"start\").reset_index(drop=True)\n",
    "\n",
    "        return events_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
