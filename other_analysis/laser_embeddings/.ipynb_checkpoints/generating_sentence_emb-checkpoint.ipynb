{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aebc7b4",
   "metadata": {},
   "source": [
    "# New Approach:\n",
    "\n",
    "For both:\n",
    "- Sentence embeddings\n",
    "- Constituent embeddings\n",
    "\n",
    "Generate the embedding by iterating through them, instead of generating it from the whole txt file and chunking after.\n",
    "\n",
    "In order to get the right chunking:\n",
    "- get the metadata format from a normal analysis,\n",
    "- get the frontiers of constituents / sentences from it, and generate the embeddings from there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eec524",
   "metadata": {},
   "source": [
    "## Testing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e46dd7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'decod_xy' from 'utils' (/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/testing/laser_embeddings/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decod_xy, mne_events\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'decod_xy' from 'utils' (/mnt/localdrive/workspace-LPP/code/neurospin-petit-prince/testing/laser_embeddings/utils.py)"
     ]
    }
   ],
   "source": [
    "from utils import decod_xy, mne_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c50e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Open the events files to get the metadata, and then generate the txt file from there\n",
    "for run in np.arange(1,10):\n",
    "\n",
    "    file = f'/home/co/data/LPP_MEG_auditory/sub-{sub}/ses-01/meg/sub-{sub}_ses-01_task-read_run-0{run}_events.tsv'\n",
    "\n",
    "    # Load the TSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    # Keep track of the previous onset value\n",
    "    prev_onset = None\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(f'run{run}.txt', 'w') as output_file:\n",
    "\n",
    "        # Loop through each row in the DataFrame\n",
    "        for i, row in df.iterrows():\n",
    "\n",
    "            # Get the onset value for this row\n",
    "            onset = row['onset']\n",
    "\n",
    "            # If this is the first row, or the onset difference with the previous row is less than 0.7, append the current column to the output\n",
    "            if ((row.word).__contains__(\".\")\n",
    "                or (row.word).__contains__(\"?\")\n",
    "                or (row.word).__contains__(\"!\")):\n",
    "                output_file.write(row['word'] +'\\n')\n",
    "                \n",
    "\n",
    "            # Otherwise, start a new line in the output file\n",
    "            else:\n",
    "                \n",
    "                output_file.write(row['word'] + ' ')\n",
    "\n",
    "            # Remember the onset value for the next iteration\n",
    "            prev_onset = onset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d90e41",
   "metadata": {},
   "source": [
    "# Previous Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7019f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: generate the run{i}.txt file to input to LASER\n",
    "\n",
    "# What was done previously: chunk the txt file raw by actual sentence (based on ., ?, !, etc..)\n",
    "# Problem: the metadata in epochs (sentence_end calculated using the word onset difference) doesn't match, as there are\n",
    "# Offsets that happen sometimes not at the end of sentences\n",
    "\n",
    "# Solution: temporary: generate the line chunking for LASER by word onset difference from the metadata file\n",
    "# Final: it will only work for read modality: for audio, an option could be to replicate the metadata file\n",
    "# => supposing the shape of both metadata files are the same, we can add the sentence_end column to the audio one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a97b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Open the events files to get the metadata, and then generate the txt file from there\n",
    "for run in np.arange(1,10):\n",
    "\n",
    "    file = f'/home/co/data/BIDS_lecture/sub-{sub}/ses-01/meg/sub-{sub}_ses-01_task-read_run-0{run}_events.tsv'\n",
    "\n",
    "\n",
    "\n",
    "    # Load the TSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    # Keep track of the previous onset value\n",
    "    prev_onset = None\n",
    "\n",
    "    # Open the output file for writing\n",
    "    with open(f'run{run}.txt', 'w') as output_file:\n",
    "\n",
    "        # Loop through each row in the DataFrame\n",
    "        for i, row in df.iterrows():\n",
    "\n",
    "            # Get the onset value for this row\n",
    "            onset = row['onset']\n",
    "\n",
    "            # If this is the first row, or the onset difference with the previous row is less than 0.7, append the current column to the output\n",
    "            if ((row.word).__contains__(\".\")\n",
    "                or (row.word).__contains__(\"?\")\n",
    "                or (row.word).__contains__(\"!\")):\n",
    "                output_file.write(row['word'] +'\\n')\n",
    "                \n",
    "\n",
    "            # Otherwise, start a new line in the output file\n",
    "            else:\n",
    "                \n",
    "                output_file.write(row['word'] + ' ')\n",
    "\n",
    "            # Remember the onset value for the next iteration\n",
    "            prev_onset = onset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "158eb636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 3.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(np.round(np.diff(df.onset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f7081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 output.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ad0d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>start</th>\n",
       "      <th>condition</th>\n",
       "      <th>n_closing</th>\n",
       "      <th>is_last_word</th>\n",
       "      <th>pos</th>\n",
       "      <th>content_word</th>\n",
       "      <th>sentence_end</th>\n",
       "      <th>label</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>fois</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'fois'}</td>\n",
       "      <td>36.252</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>une</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'une'}</td>\n",
       "      <td>36.519</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>magnifique</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'magnifique'}</td>\n",
       "      <td>36.785</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>image</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'image'}</td>\n",
       "      <td>37.052</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>dans</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'dans'}</td>\n",
       "      <td>37.336</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1406</td>\n",
       "      <td>1459</td>\n",
       "      <td>1459</td>\n",
       "      <td>ne</td>\n",
       "      <td>508.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'ne'}</td>\n",
       "      <td>491.725</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1407</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td>peut</td>\n",
       "      <td>509.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'peut'}</td>\n",
       "      <td>491.991</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>V</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1408</td>\n",
       "      <td>1461</td>\n",
       "      <td>1461</td>\n",
       "      <td>pas</td>\n",
       "      <td>509.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'pas'}</td>\n",
       "      <td>492.258</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>1462</td>\n",
       "      <td>1462</td>\n",
       "      <td>aller</td>\n",
       "      <td>509.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'aller'}</td>\n",
       "      <td>492.541</td>\n",
       "      <td>sentence</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>VINF</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>1463</td>\n",
       "      <td>1463</td>\n",
       "      <td>bien</td>\n",
       "      <td>510.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'kind': 'word', 'word': 'bien'}</td>\n",
       "      <td>492.825</td>\n",
       "      <td>sentence</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>run_1</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1404 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  index  Unnamed: 0        word  onset  duration  \\\n",
       "7           7      7           7        fois    2.8      0.25   \n",
       "8           8      8           8         une    3.1      0.25   \n",
       "9           9      9           9  magnifique    3.4      0.25   \n",
       "10         10     10          10       image    3.7      0.25   \n",
       "11         11     11          11        dans    4.0      0.25   \n",
       "...       ...    ...         ...         ...    ...       ...   \n",
       "1406     1406   1459        1459          ne  508.9      0.25   \n",
       "1407     1407   1460        1460        peut  509.2      0.25   \n",
       "1408     1408   1461        1461         pas  509.5      0.25   \n",
       "1409     1409   1462        1462       aller  509.8      0.25   \n",
       "1410     1410   1463        1463        bien  510.1      0.25   \n",
       "\n",
       "                                  trial_type    start condition  n_closing  \\\n",
       "7           {'kind': 'word', 'word': 'fois'}   36.252  sentence          2   \n",
       "8            {'kind': 'word', 'word': 'une'}   36.519  sentence          1   \n",
       "9     {'kind': 'word', 'word': 'magnifique'}   36.785  sentence          1   \n",
       "10         {'kind': 'word', 'word': 'image'}   37.052  sentence          2   \n",
       "11          {'kind': 'word', 'word': 'dans'}   37.336  sentence          1   \n",
       "...                                      ...      ...       ...        ...   \n",
       "1406          {'kind': 'word', 'word': 'ne'}  491.725  sentence          1   \n",
       "1407        {'kind': 'word', 'word': 'peut'}  491.991  sentence          2   \n",
       "1408         {'kind': 'word', 'word': 'pas'}  492.258  sentence          1   \n",
       "1409       {'kind': 'word', 'word': 'aller'}  492.541  sentence          2   \n",
       "1410        {'kind': 'word', 'word': 'bien'}  492.825  sentence          1   \n",
       "\n",
       "      is_last_word   pos  content_word  sentence_end  label  kind  \n",
       "7            False    NC          True         False  run_1  word  \n",
       "8            False   DET         False         False  run_1  word  \n",
       "9            False   ADJ          True         False  run_1  word  \n",
       "10           False    NC          True         False  run_1  word  \n",
       "11           False     P         False         False  run_1  word  \n",
       "...            ...   ...           ...           ...    ...   ...  \n",
       "1406         False   ADV          True         False  run_1  word  \n",
       "1407         False     V          True         False  run_1  word  \n",
       "1408         False   ADV          True         False  run_1  word  \n",
       "1409         False  VINF          True         False  run_1  word  \n",
       "1410         False   ADV          True          True  run_1  word  \n",
       "\n",
       "[1404 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620a449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "path = Path('/home/is153802/github/LASER/tasks/embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c561d791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LASER=/home/is153802/github/LASER\n"
     ]
    }
   ],
   "source": [
    "%env LASER=/home/is153802/github/LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aedc33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-24 22:09:01,159 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:01,159 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:01,159 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:01,705 | INFO | preprocess | SPM processing run1.txt  \n",
      "2023-03-24 22:09:01,828 | INFO | embed | encoding /tmp/tmpild7c4y1/spm to /home/is153802/code/data/laser_embeddings/emb_1-3.bin\n",
      "2023-03-24 22:09:02,481 | INFO | embed | encoded 134 sentences in 0s\n",
      "2023-03-24 22:09:04,769 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:04,769 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:04,769 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:05,307 | INFO | preprocess | SPM processing run2.txt  \n",
      "2023-03-24 22:09:05,425 | INFO | embed | encoding /tmp/tmp_nei1fhw/spm to /home/is153802/code/data/laser_embeddings/emb_4-6.bin\n",
      "2023-03-24 22:09:06,141 | INFO | embed | encoded 136 sentences in 0s\n",
      "2023-03-24 22:09:08,366 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:08,366 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:08,366 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:08,913 | INFO | preprocess | SPM processing run3.txt  \n",
      "2023-03-24 22:09:09,033 | INFO | embed | encoding /tmp/tmpzj3s4nx4/spm to /home/is153802/code/data/laser_embeddings/emb_7-9.bin\n",
      "2023-03-24 22:09:10,062 | INFO | embed | encoded 183 sentences in 1s\n",
      "2023-03-24 22:09:12,334 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:12,334 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:12,334 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:12,880 | INFO | preprocess | SPM processing run4.txt  \n",
      "2023-03-24 22:09:12,975 | INFO | embed | encoding /tmp/tmpvarbms0y/spm to /home/is153802/code/data/laser_embeddings/emb_10-12.bin\n",
      "2023-03-24 22:09:13,719 | INFO | embed | encoded 174 sentences in 0s\n",
      "2023-03-24 22:09:15,988 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:15,988 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:15,988 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:16,527 | INFO | preprocess | SPM processing run5.txt  \n",
      "2023-03-24 22:09:16,644 | INFO | embed | encoding /tmp/tmpd8jhxakn/spm to /home/is153802/code/data/laser_embeddings/emb_13-14.bin\n",
      "2023-03-24 22:09:17,258 | INFO | embed | encoded 177 sentences in 0s\n",
      "2023-03-24 22:09:19,511 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:19,511 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:19,511 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:20,056 | INFO | preprocess | SPM processing run6.txt  \n",
      "2023-03-24 22:09:20,159 | INFO | embed | encoding /tmp/tmpfhxfnh46/spm to /home/is153802/code/data/laser_embeddings/emb_15-19.bin\n",
      "2023-03-24 22:09:20,875 | INFO | embed | encoded 210 sentences in 0s\n",
      "2023-03-24 22:09:23,158 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:23,159 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:23,159 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:23,702 | INFO | preprocess | SPM processing run7.txt  \n",
      "2023-03-24 22:09:23,821 | INFO | embed | encoding /tmp/tmptupnjqxt/spm to /home/is153802/code/data/laser_embeddings/emb_20-22.bin\n",
      "2023-03-24 22:09:24,453 | INFO | embed | encoded 192 sentences in 0s\n",
      "2023-03-24 22:09:26,745 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:26,745 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:26,745 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:27,310 | INFO | preprocess | SPM processing run8.txt  \n",
      "2023-03-24 22:09:27,428 | INFO | embed | encoding /tmp/tmp0id7fc1n/spm to /home/is153802/code/data/laser_embeddings/emb_23-25.bin\n",
      "2023-03-24 22:09:28,072 | INFO | embed | encoded 142 sentences in 0s\n",
      "2023-03-24 22:09:30,356 | INFO | embed | spm_model: /home/is153802/github/LASER/laser2.spm\n",
      "2023-03-24 22:09:30,356 | INFO | embed | spm_cvocab: /home/is153802/github/LASER/laser2.cvocab\n",
      "2023-03-24 22:09:30,356 | INFO | embed | loading encoder: /home/is153802/github/LASER/laser2.pt\n",
      "2023-03-24 22:09:30,897 | INFO | preprocess | SPM processing run9.txt  \n",
      "2023-03-24 22:09:31,013 | INFO | embed | encoding /tmp/tmpmv4efnm1/spm to /home/is153802/code/data/laser_embeddings/emb_26-27.bin\n",
      "2023-03-24 22:09:31,658 | INFO | embed | encoded 196 sentences in 0s\n"
     ]
    }
   ],
   "source": [
    "CHAPTERS = {\n",
    "        1: \"1-3\",\n",
    "        2: \"4-6\",\n",
    "        3: \"7-9\",\n",
    "        4: \"10-12\",\n",
    "        5: \"13-14\",\n",
    "        6: \"15-19\",\n",
    "        7: \"20-22\",\n",
    "        8: \"23-25\",\n",
    "        9: \"26-27\",\n",
    "    }\n",
    "\n",
    "for run in np.arange(1,10):\n",
    "    ch = CHAPTERS[run]\n",
    "    txt_file = f\"/home/is153802/code/data/txt_laser/run{run}.txt\"\n",
    "    emb_file = f\"/home/is153802/code/data/laser_embeddings/emb_{ch}.bin\"\n",
    "    !bash /home/is153802/github/LASER/tasks/embed/embed.sh {txt_file} {emb_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714227f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_10-12.bin  emb_1-3.bin    emb_20-22.bin  emb_26-27.bin  emb_7-9.bin\r\n",
      "emb_13-14.bin  emb_15-19.bin  emb_23-25.bin  emb_4-6.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/is153802/code/data/laser_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87933de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/co/workspace_LPP/code/neurospin-petit-prince/testing/laser_embeddings'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174514ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34macas_participation\u001b[0m/  \u001b[01;34mDesktop\u001b[0m/    \u001b[01;34mgithub\u001b[0m/     source_reconstruction.ipynb\r\n",
      "\u001b[01;34mafer\u001b[0m/                \u001b[01;34mDocuments\u001b[0m/  \u001b[01;34mmatlab\u001b[0m/     \u001b[01;34mtmp\u001b[0m/\r\n",
      "\u001b[01;36mcode\u001b[0m@                \u001b[01;34mDownloads\u001b[0m/  \u001b[01;34mneurospin\u001b[0m/  \u001b[01;34mvideos\u001b[0m/\r\n",
      "\u001b[01;36mdata\u001b[0m@                \u001b[01;34mexpe\u001b[0m/       \u001b[01;34mph\u001b[0m/         \u001b[01;36mworkspace_LPP\u001b[0m@\r\n",
      "\u001b[01;34mdecode\u001b[0m/              \u001b[01;34mfun\u001b[0m/        \u001b[01;34msnap\u001b[0m/       \u001b[01;34mZotero\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/is153802/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3719b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
