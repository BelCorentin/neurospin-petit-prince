{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting praat-textgrids\n",
      "  Using cached praat_textgrids-1.4.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: praat-textgrids\n",
      "Successfully installed praat-textgrids-1.4.0\n"
     ]
    }
   ],
   "source": [
    "# If needed \n",
    "# !pip install praat-textgrids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textgrids\n",
    "import mne\n",
    "import mne_bids\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0fbfe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset is : -0.012119999999999909\n",
      "Offset is : 0.027880000000000127\n",
      "Offset is : 0.0714399999999995\n",
      "Offset is : 0.00788000000000011\n",
      "Offset is : 0.017879999999999896\n",
      "Offset is : 0.0028800000000002157\n",
      "Offset is : 0.04287999999999981\n",
      "Offset is : 0.06288000000000027\n"
     ]
    }
   ],
   "source": [
    "# For each run:\n",
    "\n",
    "for run in np.arange(2,10):\n",
    "\n",
    "    # Open the text grid\n",
    "    grid = textgrids.TextGrid(f'./stimuli/grid/text_french_run{run}.TextGrid')\n",
    "\n",
    "    dict_ts_to_phoneme = {} # Dict linking timestamp to phoneme\n",
    "\n",
    "    # Get the list of phonemes, their timestamp, and create a dict based off it\n",
    "    for ph in grid['MAU']:\n",
    "        dict_ts_to_phoneme[ph.mid] = ph.text\n",
    "\n",
    "    # Explore the TextGrid file, and add the voiced information\n",
    "    # Now that all the text grids are generated, it is needed to add to each Text Grid the \n",
    "    # Following information: is it a voiced or a non-voiced phoneme?\n",
    "\n",
    "    # Voiced phonemes are the following:\n",
    "    voiced = ['Z','z','v','R','D','d','b']\n",
    "\n",
    "    # All the other phonemecs are then non-voiced\n",
    "\n",
    "    dict_ts_to_voiced = {}\n",
    "\n",
    "    for key in dict_ts_to_phoneme:\n",
    "        if dict_ts_to_phoneme[key] in voiced:\n",
    "            dict_ts_to_voiced[key] = 'voiced'\n",
    "        else:\n",
    "            dict_ts_to_voiced[key] = 'non-voiced'\n",
    "\n",
    "    # Deleting the first phoneme as it is an error:\n",
    "    dict_ts_to_voiced.pop(list(dict_ts_to_voiced.keys())[0])\n",
    "\n",
    "\n",
    "    # Now load the MEG recording, and add this information as annotations\n",
    "    TASK = 'rest'\n",
    "\n",
    "    subject = '220628'\n",
    "\n",
    "    path_bids = '/home/co/workspace_LPP/data/MEG/LPP/LPP_bids'\n",
    "\n",
    "\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "                subject=subject,\n",
    "                session='01',\n",
    "                task=TASK,\n",
    "                datatype=\"meg\",\n",
    "                root=path_bids,\n",
    "                run='0'+str(run),\n",
    "            )\n",
    "\n",
    "    # raw = mne_bids.read_raw_bids(bids_path)\n",
    "\n",
    "    events_path = str(bids_path.fpath)[:-7] + 'events.tsv'\n",
    "\n",
    "    events = pd.read_csv(events_path,delimiter = '\\t')[['onset','duration','trial_type']]\n",
    "\n",
    "    # Now we have to:\n",
    "\n",
    "    # Align the phonemes timestamps with the current onset of words as in the events.tsv file\n",
    "\n",
    "    # Add them as a kind: phoneme\n",
    "\n",
    "    # There is an offset between the first word and the first phoneme: let's reajust\n",
    "\n",
    "    offset = events.onset[0] - list(dict_ts_to_voiced.keys())[0]\n",
    "\n",
    "    print(f'Offset is : {offset}')\n",
    "\n",
    "    for timestamp in dict_ts_to_voiced.keys():\n",
    "        timestamp_final = timestamp + offset \n",
    "        to_add = pd.DataFrame([timestamp_final, 0.02, {'kind':'phoneme','voice':dict_ts_to_voiced[timestamp]}])\n",
    "        to_add_t = to_add.transpose()\n",
    "        to_add_t.columns = events.columns\n",
    "        events = pd.concat([events, to_add_t])\n",
    "    \n",
    "    events.to_csv(str(bids_path.fpath)[:-7] + 'events.tsv', sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
