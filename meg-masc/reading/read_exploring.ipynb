{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd8f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "# Imports\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "# Neuro\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "# ML/Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from wordfreq import zipf_frequency\n",
    "from Levenshtein import editops\n",
    "\n",
    "\n",
    "# Tools\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "mne.set_log_level(False)\n",
    "\n",
    "\n",
    "class PATHS:\n",
    "    data = Path(\"/home/is153802/workspace_LPP/data/MEG/LPP/BIDS_lecture\")\n",
    "\n",
    "TASK = \"listen\"\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "# Functions\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "\n",
    "# Epoching and decoding\n",
    "def epoch_data(subject, run_id):\n",
    "\n",
    "    bids_path = mne_bids.BIDSPath(\n",
    "        subject=subject,\n",
    "        session=\"01\",\n",
    "        task=TASK,\n",
    "        datatype=\"meg\",\n",
    "        root=PATHS.data,\n",
    "        run=run_id,\n",
    "    )\n",
    "\n",
    "    raw = mne_bids.read_raw_bids(bids_path)\n",
    "    raw.pick_types(meg=True, stim=True)\n",
    "    raw.load_data()\n",
    "    raw = raw.filter(0.5, 20)\n",
    "\n",
    "    event_file = PATHS.data / f\"sub-{bids_path.subject}\"\n",
    "    event_file = event_file / f\"ses-{bids_path.session}\"\n",
    "    event_file = event_file / \"meg\"\n",
    "    event_file = str(event_file / f\"sub-{bids_path.subject}\")\n",
    "    event_file += f\"_ses-{bids_path.session}\"\n",
    "    event_file += f\"_task-{bids_path.task}\"\n",
    "    event_file += f\"_run-{bids_path.run}_events.tsv\"\n",
    "    assert Path(event_file).exists()\n",
    "    # read events\n",
    "    meta = pd.read_csv(event_file, sep=\"\\t\")\n",
    "    events = mne.find_events(\n",
    "        raw, stim_channel=\"STI101\", shortest_event=1, min_duration=0.0010001\n",
    "    )\n",
    "\n",
    "    # match events and metadata\n",
    "    word_events = events[events[:, 2] > 1]\n",
    "    meg_delta = np.round(np.diff(word_events[:, 0] / raw.info[\"sfreq\"]))\n",
    "    meta_delta = np.round(np.diff(meta.onset.values))\n",
    "\n",
    "    print(events)\n",
    "    print(meta.onset.values)\n",
    "    i, j = match_list(meg_delta, meta_delta)\n",
    "    print(f\"Len i : {len(i)} for run {run_id}\")\n",
    "    assert len(i) > 500\n",
    "    events = word_events[i]\n",
    "    # events = events[i]  # events = words_events[i]\n",
    "    meta = meta.iloc[j].reset_index()\n",
    "\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, metadata=meta, tmin=-0.3, tmax=0.8, decim=10, baseline=(-0.2, 0.0)\n",
    "    )\n",
    "\n",
    "    data = epochs.get_data()\n",
    "    epochs.load_data()\n",
    "\n",
    "    # Scaling the data\n",
    "    n_words, n_chans, n_times = data.shape\n",
    "    vec = data.transpose(0, 2, 1).reshape(-1, n_chans)\n",
    "    scaler = RobustScaler()\n",
    "    idx = np.arange(len(vec))\n",
    "    np.random.shuffle(idx)\n",
    "    vec = scaler.fit(vec[idx[:20_000]]).transform(vec)\n",
    "    # To try: sigmas = 7 or 15\n",
    "    sigma = 7\n",
    "    vec = np.clip(vec, -sigma, sigma)\n",
    "    epochs._data[:, :, :] = (\n",
    "        scaler.inverse_transform(vec)\n",
    "        .reshape(n_words, n_times, n_chans)\n",
    "        .transpose(0, 2, 1)\n",
    "    )\n",
    "\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def decod(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    # define data\n",
    "    model = make_pipeline(StandardScaler(), RidgeCV(alphas=np.logspace(-3, 8, 10)))\n",
    "    cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "    # fit predict\n",
    "    n, n_chans, n_times = X.shape\n",
    "    R = np.zeros(n_times)\n",
    "    for t in range(n_times):\n",
    "        print(\".\", end=\"\")\n",
    "        y_pred = cross_val_predict(model, X[:, :, t], y, cv=cv)\n",
    "        R[t] = correlate(y, y_pred)\n",
    "    return R\n",
    "\n",
    "\n",
    "# Function to correlate\n",
    "def correlate(X, Y):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array(X)[:, None]\n",
    "    if Y.ndim == 1:\n",
    "        Y = np.array(Y)[:, None]\n",
    "    X = X - X.mean(0)\n",
    "    Y = Y - Y.mean(0)\n",
    "\n",
    "    SX2 = (X**2).sum(0) ** 0.5\n",
    "    SY2 = (Y**2).sum(0) ** 0.5\n",
    "    SXY = (X * Y).sum(0)\n",
    "    return SXY / (SX2 * SY2)\n",
    "\n",
    "\n",
    "# Utils\n",
    "def match_list(A, B, on_replace=\"delete\"):\n",
    "    \"\"\"Match two lists of different sizes and return corresponding indice\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: list | array, shape (n,)\n",
    "        The values of the first list\n",
    "    B: list | array: shape (m, )\n",
    "        The values of the second list\n",
    "    Returns\n",
    "    -------\n",
    "    A_idx : array\n",
    "        The indices of the A list that match those of the B\n",
    "    B_idx : array\n",
    "        The indices of the B list that match those of the A\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(A, str):\n",
    "        unique = np.unique(np.r_[A, B])\n",
    "        label_encoder = dict((k, v) for v, k in enumerate(unique))\n",
    "\n",
    "        def int_to_unicode(array: np.ndarray) -> str:\n",
    "            return \"\".join([str(chr(label_encoder[ii])) for ii in array])\n",
    "\n",
    "        A = int_to_unicode(A)\n",
    "        B = int_to_unicode(B)\n",
    "\n",
    "    changes = editops(A, B)\n",
    "    B_sel = np.arange(len(B)).astype(float)\n",
    "    A_sel = np.arange(len(A)).astype(float)\n",
    "    for type_, val_a, val_b in changes:\n",
    "        if type_ == \"insert\":\n",
    "            B_sel[val_b] = np.nan\n",
    "        elif type_ == \"delete\":\n",
    "            A_sel[val_a] = np.nan\n",
    "        elif on_replace == \"delete\":\n",
    "            # print('delete replace')\n",
    "            A_sel[val_a] = np.nan\n",
    "            B_sel[val_b] = np.nan\n",
    "        elif on_replace == \"keep\":\n",
    "            # print('keep replace')\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    B_sel = B_sel[np.where(~np.isnan(B_sel))]\n",
    "    A_sel = A_sel[np.where(~np.isnan(A_sel))]\n",
    "    assert len(B_sel) == len(A_sel)\n",
    "    return A_sel.astype(int), B_sel.astype(int)\n",
    "\n",
    "\n",
    "def get_subjects():\n",
    "    subjects = pd.read_csv(str(PATHS.data) + \"/participants.tsv\", sep=\"\\t\")\n",
    "    subjects = subjects.participant_id.apply(lambda x: x.split(\"-\")[1]).values\n",
    "    # subjects = np.delete(subjects, subjects.shape[0]-1)\n",
    "    # Let's sort this array before outputting it!\n",
    "    int_subjects = np.sort([int(subj) for subj in subjects])\n",
    "    subjects = [str(subj) for subj in int_subjects]\n",
    "\n",
    "    return subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d42e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subjects for which the decoding will be tested: \n",
      "\n",
      "['1']\n",
      "Subject 1's decoding started\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43914      0      1]\n",
      " [ 44534      1      7]\n",
      " [ 44889      0      7]\n",
      " ...\n",
      " [529011      0      5]\n",
      " [529328      0      4]\n",
      " [529628      0     11]]\n",
      "[  0.7    1.05   1.4  ... 512.4  512.75 513.1 ]\n",
      "Len i : 1407 for run 01\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49108      0      2]\n",
      " [ 49728      2      7]\n",
      " [ 50075      0      5]\n",
      " ...\n",
      " [578346      0      2]\n",
      " [578663      0      8]\n",
      " [578980      0      4]]\n",
      "[  0.7    1.05   1.4  ... 561.05 561.4  561.75]\n",
      "Len i : 1524 for run 02\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 54 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16564      0      3]\n",
      " [ 17543      0      9]\n",
      " [ 17826      0      5]\n",
      " ...\n",
      " [590163      0      5]\n",
      " [590479      0      9]\n",
      " [590796      0     15]]\n",
      "[  0.7    1.05   1.4  ... 600.95 601.3  601.65]\n",
      "Len i : 1653 for run 03\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 31 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23383      0      4]\n",
      " [ 24353      0      2]\n",
      " [ 24653      0      8]\n",
      " ...\n",
      " [523542      0      6]\n",
      " [523858      0      2]\n",
      " [524175      0      7]]\n",
      "[  0.7    1.05   1.4  ... 521.15 521.5  521.85]\n",
      "Len i : 1437 for run 04\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35803      0      5]\n",
      " [ 36771      0      9]\n",
      " [ 37071      0      7]\n",
      " ...\n",
      " [499027      0      3]\n",
      " [499343      0     12]\n",
      " [499660      0      7]]\n",
      "[  0.7    1.05   1.4  ... 479.5  479.85 480.2 ]\n",
      "Len i : 1299 for run 05\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 17 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19403      0      6]\n",
      " [ 20365      0      7]\n",
      " [ 20665      0      7]\n",
      " ...\n",
      " [590935      0      8]\n",
      " [591252      0      2]\n",
      " [591569      0     12]]\n",
      "[  0.7    1.05   1.4  ... 593.25 593.6  593.95]\n",
      "Len i : 1654 for run 06\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 34 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15746      0      7]\n",
      " [ 16721      0      2]\n",
      " [ 17021      0      6]\n",
      " ...\n",
      " [538993      0      8]\n",
      " [539309      0      3]\n",
      " [539626      0     13]]\n",
      "[  0.7    1.05   1.4  ... 543.2  543.55 543.9 ]\n",
      "Len i : 1506 for run 07\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38331      0      8]\n",
      " [ 38951      8     12]\n",
      " [ 39301      0      3]\n",
      " ...\n",
      " [500923      0      5]\n",
      " [501240      0      6]\n",
      " [501557      0     14]]\n",
      "[  0.7    1.05   1.4  ... 485.8  486.15 486.5 ]\n",
      "Len i : 1357 for run 08\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: This file contains raw Internal Active Shielding data. It may be distorted. Elekta recommends it be run through MaxFilter to produce reliable results. Consider closing the file and running MaxFilter on the data.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n",
      "/tmp/ipykernel_1527209/1655232870.py:55: RuntimeWarning: The unit for channel(s) STI001, STI002, STI003, STI004, STI005, STI006, STI007, STI008, STI009, STI010, STI011, STI012, STI013, STI014, STI015, STI016, STI101, STI201, STI301 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11573      0      9]\n",
      " [ 12550      0      1]\n",
      " [ 12850      0      6]\n",
      " ...\n",
      " [566420      0      1]\n",
      " [566720      0      9]\n",
      " [567037      0     13]]\n",
      "[  0.7    1.05   1.4  ... 577.5  577.85 578.2 ]\n",
      "Len i : 1604 for run 09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1527209/183602319.py:29: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs = mne.concatenate_epochs(epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................Finished!\n"
     ]
    }
   ],
   "source": [
    "report = mne.Report()\n",
    "\n",
    "subjects = get_subjects()\n",
    "\n",
    "RUN = 9\n",
    "\n",
    "print(\"\\nSubjects for which the decoding will be tested: \\n\")\n",
    "print(subjects)\n",
    "\n",
    "for subject in subjects:\n",
    "\n",
    "    if subject in to_exclude:\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject}'s decoding started\")\n",
    "    epochs = []\n",
    "    for run_id in range(1, RUN + 1):\n",
    "        print(\".\", end=\"\")\n",
    "        epo = epoch_data(subject, \"%.2i\" % run_id)\n",
    "        epo.metadata[\"label\"] = f\"run_{run_id}\"\n",
    "        epochs.append(epo)\n",
    "\n",
    "    # Quick fix for the dev_head: has to be\n",
    "    # fixed before doing source reconstruction\n",
    "    for epo in epochs:\n",
    "        epo.info[\"dev_head_t\"] = epochs[0].info[\"dev_head_t\"]\n",
    "        # epo.info['nchan'] = epochs[0].info['nchan']\n",
    "\n",
    "    epochs = mne.concatenate_epochs(epochs)\n",
    "\n",
    "    # Get the evoked potential averaged on all epochs for each channel\n",
    "    evo = epochs.average(method=\"median\")\n",
    "    evo.plot(spatial_colors=True)\n",
    "\n",
    "    # Handling the data structure\n",
    "    epochs.metadata[\"kind\"] = epochs.metadata.trial_type.apply(\n",
    "        lambda s: eval(s)[\"kind\"]\n",
    "    )\n",
    "    epochs.metadata[\"word\"] = epochs.metadata.trial_type.apply(\n",
    "        lambda s: eval(s)[\"word\"]\n",
    "    )\n",
    "\n",
    "    # Run a linear regression between MEG signals\n",
    "    # and word frequency classification\n",
    "    # X = epochs.get_data() # Regular data: mag & grad\n",
    "    # X = epochs.copy().pick_types(meg='mag').get_data()  # Only mag data\n",
    "    # X = epochs.copy().pick_types(meg='grad').get_data() # Only grad data\n",
    "    X = epochs.get_data()  # Both mag and grad\n",
    "    y = [len(word) for word in epochs.metadata.word]\n",
    "    R = decod(X, y)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=[6, 6])\n",
    "    dec = plt.fill_between(epochs.times, R)\n",
    "    # plt.show()\n",
    "    report.add_evokeds(evo, titles=f\"Evoked for sub {subject} \")\n",
    "    report.add_figure(fig, title=f\"decoding for subject {subject}\")\n",
    "    # report.add_figure(dec, subject, tags=\"word\")\n",
    "    report.save(\"./figures/decoding_raw_word_length.html\", open_browser=False, overwrite=True)\n",
    "\n",
    "    print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e611de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m epochs\u001b[38;5;241m.\u001b[39mget_data()  \u001b[38;5;66;03m# Both mag and grad\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m epochs\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mword]\n\u001b[0;32m---> 20\u001b[0m R \u001b[38;5;241m=\u001b[39m decod(X, y)\n\u001b[1;32m     22\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m     23\u001b[0m dec \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfill_between(epochs\u001b[38;5;241m.\u001b[39mtimes, R)\n",
      "Cell \u001b[0;32mIn [4], line 126\u001b[0m, in \u001b[0;36mdecod\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(model, X[:, :, t], y, cv\u001b[38;5;241m=\u001b[39mcv)\n\u001b[0;32m--> 126\u001b[0m     R[t] \u001b[38;5;241m=\u001b[39m \u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m R\n",
      "Cell \u001b[0;32mIn [4], line 132\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelate\u001b[39m(X, Y):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    133\u001b[0m         X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "# Get the evoked potential averaged on all epochs for each channel\n",
    "evo = epochs.average(method=\"median\")\n",
    "evo.plot(spatial_colors=True)\n",
    "\n",
    "# Handling the data structure\n",
    "epochs.metadata[\"kind\"] = epochs.metadata.trial_type.apply(\n",
    "    lambda s: eval(s)[\"kind\"]\n",
    ")\n",
    "epochs.metadata[\"word\"] = epochs.metadata.trial_type.apply(\n",
    "    lambda s: eval(s)[\"word\"]\n",
    ")\n",
    "\n",
    "# Run a linear regression between MEG signals\n",
    "# and word frequency classification\n",
    "# X = epochs.get_data() # Regular data: mag & grad\n",
    "# X = epochs.copy().pick_types(meg='mag').get_data()  # Only mag data\n",
    "# X = epochs.copy().pick_types(meg='grad').get_data() # Only grad data\n",
    "X = epochs.get_data()  # Both mag and grad\n",
    "y = [len(word) for word in epochs.metadata.word]\n",
    "R = decod(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=[6, 6])\n",
    "dec = plt.fill_between(epochs.times, R)\n",
    "# plt.show()\n",
    "report.add_evokeds(evo, titles=f\"Evoked for sub {subject} \")\n",
    "report.add_figure(fig, title=f\"decoding for subject {subject}\")\n",
    "# report.add_figure(dec, subject, tags=\"word\")\n",
    "report.save(\"./figures/decoding_raw_word_length.html\", open_browser=False, overwrite=True)\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d24fb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = epochs.metadata.word.apply(lambda w: zipf_frequency(w, \"fr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53461fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = np.asarray([len(word) for word in epochs.metadata.word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e6e202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f826597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
