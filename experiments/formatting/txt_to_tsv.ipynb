{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194613b6",
   "metadata": {},
   "source": [
    "# Formatting the LPP txt files\n",
    "\n",
    "In this notebook, we'll go from the raw LPP txt files, to a word-based csv file, doing the following steps:\n",
    "- Tokenizing the natural language by words\n",
    "- Remove the blank space between a word and :\n",
    "- Adding capital letters at the beginning of a sentence\n",
    "- Remove the blank space between - and the following word (dialogue) \n",
    "\n",
    "Different versions will be built:\n",
    "\n",
    "- A first one with 300 ms words + 50 ms black screen. End of sentence delay of 200 ms\n",
    "\n",
    "- A second one with 250 ms words + 50 ms black screen. End of sentence delay of 500 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b09fbd",
   "metadata": {},
   "source": [
    "### Bash commands preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For :\n",
    "!perl -pi.bak -e 's/ :/:/g' *.txt\n",
    "\n",
    "# For dash\n",
    "!perl -pi.bak -e 's/- /-/g' *.txt\n",
    "\n",
    "# Word tokenizing\n",
    "!for f in `seq 1 9` ; do sed 's/ /\\n/g' text_french_run$f.txt | awk 'length($0) > 0 ' > new_test_run$f.txt; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43dd9b",
   "metadata": {},
   "source": [
    "### Python commands tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b56b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb761f",
   "metadata": {},
   "source": [
    "## First version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3bdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_screen = 0.05\n",
    "word_duration = 0.30\n",
    "word_bs = black_screen + word_duration\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    with open(f'./text_lpp/new_test_run{i}.txt') as temp_file:\n",
    "\n",
    "        lpp = temp_file.read().splitlines() \n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lpp)\n",
    "    next_cap = False\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # First word\n",
    "        if index == 0:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if next_cap == True:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if str(row).__contains__('.') or str(row).__contains__('?') or str(row).__contains__('!'):\n",
    "            next_cap = True\n",
    "        else:\n",
    "            next_cap = False\n",
    "\n",
    "    df.columns = ['word']\n",
    "    end = (df.shape[0] * word_bs) + 0.7\n",
    "    df['onset'] = np.arange(0.7, end, word_bs)\n",
    "    df['duration'] = np.ones(df.shape[0]) * word_duration\n",
    "    \n",
    "    df.to_csv(f'./txt_clean/run{i}_clean.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    \n",
    "    # Create a dataframe where the duration of the black screen after the end of the sentence is longer.\n",
    "\n",
    "    df_sentence_end = pd.DataFrame(columns = df.columns, data = copy.deepcopy(df.values))\n",
    "    end_of_sentence_delay = 0.2\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if str(row.word).__contains__('.') or str(row.word).__contains__('?') or str(row.word).__contains__('!'):\n",
    "            # df_sentence_end.at[index, 'onset'] = row.onset + end_of_sentence_delay # Add the delay from this line\n",
    "            # And for every next onset\n",
    "            for j in np.arange(index+1, df.shape[0]):\n",
    "                df_sentence_end.at[j, 'onset'] = df_sentence_end.at[j, 'onset'] + end_of_sentence_delay\n",
    "                ww = df_sentence_end.at[j, 'word']\n",
    "\n",
    "    \n",
    "    df_sentence_end.to_csv(f'./v1/run{i}_v1_word_0.3_end_sentence_0.2.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92562f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create for decoding adding a dict\n",
    "for i in np.arange(1,10):\n",
    "    df_clean = pd.read_csv(f'./txt_clean/run{i}_clean.tsv',sep='\\t')\n",
    "    df_clean['trial_type'] = [{} for i in np.arange(df_clean.shape[0])]\n",
    "    for index, row in df_clean.iterrows():\n",
    "        clean_word = str(row.word).translate(str.maketrans('', '', string.punctuation))\n",
    "        dict_word =  {'kind':'word','word':clean_word}\n",
    "        df_clean.at[index, 'trial_type'] = dict_word\n",
    "    df_clean.to_csv(f'./decoding_tsv_v1/run{i}_v1.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf25101",
   "metadata": {},
   "source": [
    "## Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc5e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_screen = 0.05\n",
    "word_duration = 0.25\n",
    "end_of_sentence_delay = 0.5\n",
    "word_bs = black_screen + word_duration\n",
    "end_of_chapter_duration = 2\n",
    "\n",
    "dict_end_chapter = {\n",
    "    1:[433,1087],\n",
    "    2:[737,1400],\n",
    "    3:[710,1345],\n",
    "    4:[1090,1357],\n",
    "    5:[753],\n",
    "    6:[716,951,1271,1555],\n",
    "    7:[200,1278],\n",
    "    8:[95,703],\n",
    "    9:[1357],\n",
    "}\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    with open(f'./text_lpp/new_test_run{i}.txt') as temp_file:\n",
    "\n",
    "        lpp = temp_file.read().splitlines() \n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lpp)\n",
    "    next_cap = False\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # First word\n",
    "        if index == 0:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if next_cap == True:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if str(row).__contains__('.') or str(row).__contains__('?') or str(row).__contains__('!'):\n",
    "            next_cap = True\n",
    "        else:\n",
    "            next_cap = False\n",
    "\n",
    "    df.columns = ['word']\n",
    "    end = (df.shape[0] * word_bs) + 0.7\n",
    "    df['onset'] = np.arange(0.7, end, word_bs)\n",
    "    df['duration'] = np.ones(df.shape[0]) * word_duration\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.to_csv(f'./txt_clean/run{i}_clean.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    \n",
    "    # Create a dataframe where the duration of the black screen after the end of the sentence is longer.\n",
    "\n",
    "    df_sentence_end = pd.DataFrame(columns = df.columns, data = copy.deepcopy(df.values))\n",
    "    for index, row in df.iterrows():\n",
    "        if str(row.word).__contains__('.') or str(row.word).__contains__('?') or str(row.word).__contains__('!'):\n",
    "            # df_sentence_end.at[index, 'onset'] = row.onset + end_of_sentence_delay # Add the delay from this line\n",
    "            # And for every next onset\n",
    "            for j in np.arange(index+1, df.shape[0]):\n",
    "                df_sentence_end.at[j, 'onset'] = df_sentence_end.at[j, 'onset'] + end_of_sentence_delay\n",
    "                ww = df_sentence_end.at[j, 'word']\n",
    "        if index+2 in dict_end_chapter[i]:\n",
    "            print(f'Adding 2s after the word {row.word} \\n')\n",
    "            for j in np.arange(index+1, df.shape[0]):\n",
    "                df_sentence_end.at[j, 'onset'] = df_sentence_end.at[j, 'onset'] + end_of_chapter_duration\n",
    "                ww = df_sentence_end.at[j, 'word']\n",
    "\n",
    "    \n",
    "    df_sentence_end.to_csv(f'./v2/run{i}_v2_0.25_0.5.tsv',sep='\\t',index=False)\n",
    "    \n",
    "# Create for decoding adding a dict\n",
    "for i in np.arange(1,10):\n",
    "    df_clean = pd.read_csv(f'./v2/run{i}_v2_0.25_0.5.tsv',sep='\\t')\n",
    "    df_clean['trial_type'] = [{} for i in np.arange(df_clean.shape[0])]\n",
    "    for index, row in df_clean.iterrows():\n",
    "        clean_word = str(row.word).translate(str.maketrans('', '', string.punctuation))\n",
    "        dict_word =  {'kind':'word','word':clean_word}\n",
    "        df_clean.at[index, 'trial_type'] = dict_word\n",
    "    df_clean.to_csv(f'./decoding_tsv_v2/run{i}_v2.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb07936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2s after the word raisonnable... \n",
      "\n",
      "Adding 2s after the word prince. \n",
      "\n",
      "Adding 2s after the word vieillir. \n",
      "\n",
      "Adding 2s after the word l'urgence. \n",
      "\n",
      "Adding 2s after the word larmes! \n",
      "\n",
      "Adding 2s after the word l'aimer.\" \n",
      "\n",
      "Adding 2s after the word voyage. \n",
      "\n",
      "Adding 2s after the word voyage. \n",
      "\n",
      "Adding 2s after the word voyage. \n",
      "\n",
      "Adding 2s after the word fleur. \n",
      "\n",
      "Adding 2s after the word an. \n",
      "\n",
      "Adding 2s after the word turent. \n",
      "\n",
      "Adding 2s after the word fleur. \n",
      "\n",
      "Adding 2s after the word pleura. \n",
      "\n",
      "Adding 2s after the word souvenir. \n",
      "\n",
      "Adding 2s after the word fontaine...\" \n",
      "\n",
      "Adding 2s after the word jour. \n",
      "\n",
      "Adding 2s after the word sable. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "black_screen = 0.05\n",
    "word_duration = 0.25\n",
    "end_of_sentence_delay = 0.5\n",
    "word_bs = black_screen + word_duration\n",
    "end_of_chapter_duration = 2\n",
    "\n",
    "dict_end_chapter = {\n",
    "    1:[433,1087],\n",
    "    2:[737,1400],\n",
    "    3:[710,1345],\n",
    "    4:[1090,1357],\n",
    "    5:[753],\n",
    "    6:[716,951,1271,1555],\n",
    "    7:[200,1278],\n",
    "    8:[95,703],\n",
    "    9:[1357]\n",
    "}\n",
    "\n",
    "for i in np.arange(1,10):\n",
    "    with open(f'./text_lpp/new_test_run{i}.txt') as temp_file:\n",
    "\n",
    "        lpp = temp_file.read().splitlines() \n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lpp)\n",
    "    next_cap = False\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # First word\n",
    "        if index == 0:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if next_cap == True:\n",
    "            df.at[index,0] = str(row.str.capitalize()[0])\n",
    "        if str(row).__contains__('.') or str(row).__contains__('?') or str(row).__contains__('!'):\n",
    "            next_cap = True\n",
    "        else:\n",
    "            next_cap = False\n",
    "\n",
    "    df.columns = ['word']\n",
    "    end = (df.shape[0] * word_bs) + 0.7\n",
    "    df['onset'] = np.arange(0.7, end, word_bs)\n",
    "    df['duration'] = np.ones(df.shape[0]) * word_duration\n",
    "    \n",
    "    df_sentence_end = pd.DataFrame(columns = df.columns, data = copy.deepcopy(df.values))\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "                \n",
    "        if index+2 in dict_end_chapter[i]:\n",
    "            print(f'Adding 2s after the word {row.word} \\n')\n",
    "            for j in np.arange(index+1, df.shape[0]):\n",
    "                df_sentence_end.at[j, 'onset'] = df_sentence_end.at[j, 'onset'] + end_of_chapter_duration\n",
    "                ww = df_sentence_end.at[j, 'word']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bd7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7bdaf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>de</td>\n",
       "      <td>488.7</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>bruit,</td>\n",
       "      <td>489.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>à</td>\n",
       "      <td>489.3</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>cause</td>\n",
       "      <td>489.6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>du</td>\n",
       "      <td>489.9</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>sable.</td>\n",
       "      <td>490.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>Et</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>maintenant</td>\n",
       "      <td>493.3</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>bien</td>\n",
       "      <td>493.6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>sûr,</td>\n",
       "      <td>493.9</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>ça</td>\n",
       "      <td>494.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>fait</td>\n",
       "      <td>494.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>six</td>\n",
       "      <td>494.8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>ans</td>\n",
       "      <td>495.1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>déjà...</td>\n",
       "      <td>495.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Je</td>\n",
       "      <td>496.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>n'ai</td>\n",
       "      <td>496.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>jamais</td>\n",
       "      <td>496.8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>encore</td>\n",
       "      <td>497.1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>raconté</td>\n",
       "      <td>497.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>cette</td>\n",
       "      <td>497.7</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>histoire.</td>\n",
       "      <td>498.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Les</td>\n",
       "      <td>498.8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>camarades</td>\n",
       "      <td>499.1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>qui</td>\n",
       "      <td>499.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>m'ont</td>\n",
       "      <td>499.7</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>revu</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ont</td>\n",
       "      <td>500.3</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>été</td>\n",
       "      <td>500.6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>bien</td>\n",
       "      <td>500.9</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>contents</td>\n",
       "      <td>501.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>de</td>\n",
       "      <td>501.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>me</td>\n",
       "      <td>501.8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>revoir</td>\n",
       "      <td>502.1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>vivant.</td>\n",
       "      <td>502.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>J'étais</td>\n",
       "      <td>503.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>triste</td>\n",
       "      <td>503.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>mais</td>\n",
       "      <td>503.8</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>je</td>\n",
       "      <td>504.1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>leur</td>\n",
       "      <td>504.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>disais:</td>\n",
       "      <td>504.7</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>\"c'est</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>la</td>\n",
       "      <td>505.3</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>fatigue...\"</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Maintenant</td>\n",
       "      <td>506.4</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>je</td>\n",
       "      <td>506.7</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>me</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>suis</td>\n",
       "      <td>507.3</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>un</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>peu</td>\n",
       "      <td>507.9</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  onset duration\n",
       "1350           de  488.7     0.25\n",
       "1351       bruit,  489.0     0.25\n",
       "1352            à  489.3     0.25\n",
       "1353        cause  489.6     0.25\n",
       "1354           du  489.9     0.25\n",
       "1355       sable.  490.2     0.25\n",
       "1356           Et  493.0     0.25\n",
       "1357   maintenant  493.3     0.25\n",
       "1358         bien  493.6     0.25\n",
       "1359         sûr,  493.9     0.25\n",
       "1360           ça  494.2     0.25\n",
       "1361         fait  494.5     0.25\n",
       "1362          six  494.8     0.25\n",
       "1363          ans  495.1     0.25\n",
       "1364      déjà...  495.4     0.25\n",
       "1365           Je  496.2     0.25\n",
       "1366         n'ai  496.5     0.25\n",
       "1367       jamais  496.8     0.25\n",
       "1368       encore  497.1     0.25\n",
       "1369      raconté  497.4     0.25\n",
       "1370        cette  497.7     0.25\n",
       "1371    histoire.  498.0     0.25\n",
       "1372          Les  498.8     0.25\n",
       "1373    camarades  499.1     0.25\n",
       "1374          qui  499.4     0.25\n",
       "1375        m'ont  499.7     0.25\n",
       "1376         revu  500.0     0.25\n",
       "1377          ont  500.3     0.25\n",
       "1378          été  500.6     0.25\n",
       "1379         bien  500.9     0.25\n",
       "1380     contents  501.2     0.25\n",
       "1381           de  501.5     0.25\n",
       "1382           me  501.8     0.25\n",
       "1383       revoir  502.1     0.25\n",
       "1384      vivant.  502.4     0.25\n",
       "1385      J'étais  503.2     0.25\n",
       "1386       triste  503.5     0.25\n",
       "1387         mais  503.8     0.25\n",
       "1388           je  504.1     0.25\n",
       "1389         leur  504.4     0.25\n",
       "1390      disais:  504.7     0.25\n",
       "1391       \"c'est  505.0     0.25\n",
       "1392           la  505.3     0.25\n",
       "1393  fatigue...\"  505.6     0.25\n",
       "1394   Maintenant  506.4     0.25\n",
       "1395           je  506.7     0.25\n",
       "1396           me  507.0     0.25\n",
       "1397         suis  507.3     0.25\n",
       "1398           un  507.6     0.25\n",
       "1399          peu  507.9     0.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence_end[1350:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820815a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
